{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dec5e8",
   "metadata": {},
   "source": [
    "1. cleaning up compiled data from Nico \n",
    "- starting w/ one file for now = convnext.csv\n",
    "- clean up columns w/ less than 10 data points and rows w/o data in \"permanent\" column\n",
    "- \"permanent\" column = final diagnoses\n",
    "- want to delete 128+ columns so Nico can add more image features \n",
    "(max # of columns readable by models we will use later = 500)\n",
    "- want to separate the data via diagnoses to see what diagnoses works w/ what data\n",
    "\n",
    "*preliminary data cleaning via chatgpt shows:\n",
    "OG: 522 rows x 407 columns\n",
    "cleaned: 510 rows x 241 columns\n",
    "dropped columns: 166\n",
    "dropped rows: 12\n",
    "dx groups created: 220\n",
    "\n",
    "*too many different dx\n",
    "check top 10 most common dx\n",
    "generate table of dx counts listing all 222 dx groups w/ row counts \n",
    "- easier to filter/sort by row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d75690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4db128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/joi263/Documents/MultimodalTabData/data\n",
      "✅ Cleaned data saved (grouped by diagnosis): /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\n",
      "✅ Dropped info saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_dropped_info.csv\n",
      "{'original_shape': (522, 480), 'cleaned_shape': (510, 244), 'columns_dropped': 236, 'rows_dropped': 12}\n"
     ]
    }
   ],
   "source": [
    "#cleaning up master data + creating dropped rows/columns file\n",
    "# ✅ 1. Check current working directory (just to confirm)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# ✅ 2. Helper function: Standardize ALL text entries\n",
    "def standardize_text(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(\"\\xa0\", \" \")          # replace non-breaking spaces\n",
    "        value = re.sub(r\"\\s+\", \" \", value).strip()  # collapse multiple spaces & trim\n",
    "        value = value.lower()                       # lowercase everything\n",
    "        value = re.sub(r\"^[-–]+\", \"\", value).strip() # remove leading dashes or en-dashes\n",
    "    return value\n",
    "\n",
    "# ✅ 3. Cleaning & Standardizing Function\n",
    "def clean_and_standardize_all(df, filename_prefix, save_path=\"./\"):\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # --- Standardize text in all object columns ---\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].apply(standardize_text)\n",
    "\n",
    "   # --- Drop rows with no permanent diagnosis (NaN or empty) ---\n",
    "    rows_before = df.shape[0]\n",
    "    df_cleaned = df[df[\"permanent\"].notna() & (df[\"permanent\"].str.strip() != \"\")]\n",
    "\n",
    "    # --- Track dropped rows ---\n",
    "    rows_missing_dx = df[~df.index.isin(df_cleaned.index)].copy()\n",
    "    rows_missing_dx[\"drop_reason\"] = \"No permanent diagnosis\"\n",
    "\n",
    "   # --- Drop columns with <10 non-null entries ---\n",
    "    cols_to_drop = [col for col in df_cleaned.columns if df_cleaned[col].notna().sum() < 10]\n",
    "    dropped_cols_info = pd.DataFrame({\n",
    "        \"column\": cols_to_drop,\n",
    "        \"non_null_count\": [df_cleaned[c].notna().sum() for c in cols_to_drop],\n",
    "        \"drop_reason\": \"Fewer than 10 non-null entries\"\n",
    "    })\n",
    "    df_cleaned = df_cleaned.drop(columns=cols_to_drop)\n",
    "\n",
    "    # ✅ Explicitly drop any unnamed/blank columns (just in case)\n",
    "    unnamed_cols = [c for c in df_cleaned.columns if \"Unnamed\" in c or c.strip() == \"\"]\n",
    "    if unnamed_cols:\n",
    "        df_cleaned = df_cleaned.drop(columns=unnamed_cols)\n",
    "\n",
    "    # --- ✅ Sort/group by permanent diagnosis ---\n",
    "    df_cleaned = df_cleaned.sort_values(by=\"permanent\").reset_index(drop=True)\n",
    "\n",
    "    # --- Save Cleaned Master CSV ---\n",
    "    cleaned_file = os.path.join(save_path, f\"{filename_prefix}_cleaned_master.csv\")\n",
    "    df_cleaned.to_csv(cleaned_file, index=False)\n",
    "    print(f\"✅ Cleaned data saved (grouped by diagnosis): {cleaned_file}\")\n",
    "\n",
    "    # --- Save dropped info CSV ---\n",
    "    dropped_cols_info[\"row_index\"] = \"N/A\"\n",
    "    rows_missing_dx[\"column\"] = \"N/A\"\n",
    "    rows_missing_dx[\"non_null_count\"] = \"N/A\"\n",
    "    dropped_info_combined = pd.concat([dropped_cols_info, rows_missing_dx], ignore_index=True)\n",
    "    dropped_file = os.path.join(save_path, f\"{filename_prefix}_dropped_info.csv\")\n",
    "    dropped_info_combined.to_csv(dropped_file, index=False)\n",
    "    print(f\"✅ Dropped info saved: {dropped_file}\")\n",
    "\n",
    "    return {\n",
    "        \"original_shape\": original_shape,\n",
    "        \"cleaned_shape\": df_cleaned.shape,\n",
    "        \"columns_dropped\": len(cols_to_drop),\n",
    "        \"rows_dropped\": rows_before - df_cleaned.shape[0]\n",
    "    }\n",
    "\n",
    "# ✅ 4. Example Run for ConvNeXt (change filename_prefix for others)\n",
    "data_path = \"/Users/joi263/Documents/MultimodalTabData/data/OG_data_csv/convnext_new.csv\"\n",
    "save_path = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data\"\n",
    "\n",
    "df_convnext = pd.read_csv(data_path)\n",
    "summary = clean_and_standardize_all(df_convnext, \"convnext\", save_path=save_path)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84322456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned & resaved: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\n",
      "✅ Columns now: 228\n"
     ]
    }
   ],
   "source": [
    "#quick one liner fix for unnamed/blank columns - didn't want to resave master csv and manually delete again\n",
    "file_path = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ✅ Drop any unnamed/blank columns and resave\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\") & (df.columns.str.strip() != \"\")]\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"✅ Cleaned & resaved: {file_path}\")\n",
    "print(f\"✅ Columns now: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The cleaned master CSV has 228 columns.\n"
     ]
    }
   ],
   "source": [
    "#checking how many columns master csv now has - need to calculate how many were manually dropped\n",
    "# Load your cleaned master CSV\n",
    "df_cleaned = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")\n",
    "\n",
    "# Check the number of columns\n",
    "num_columns = df_cleaned.shape[1]\n",
    "print(f\"✅ The cleaned master CSV has {num_columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d381e8",
   "metadata": {},
   "source": [
    "2. cleaned convnext_new.csv (Jack's updated version w/ demographics) \n",
    "-went from 480 columns to 228 (252 columns dropped)\n",
    "-manually deleted some columns using MasterDirectory for things I didn't think we'd need\n",
    "(236 columns dropped via cleaning; 16 dropped manually)\n",
    "\n",
    "3. now generate diagnosis count\n",
    "\n",
    "4. also generate new csv that only has diagnoses w/ key words \"glioma\", \"glioblastoma\", and \"meningioma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diagnosis counts saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_diagnosis_counts.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permanent</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>glioblastoma, cns who grade 4</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>glioblastoma who grade iv</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>pituitary adenoma</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>glioblastoma</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>meningioma</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>metastatic carcinoma</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>oligodendroglioma, cns who grade 3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>diffuse large b-cell lymphoma</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>lymphoma</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>pilocytic astrocytoma</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              permanent  row_count\n",
       "83        glioblastoma, cns who grade 4         71\n",
       "82            glioblastoma who grade iv         40\n",
       "177                   pituitary adenoma         26\n",
       "79                         glioblastoma         20\n",
       "129                          meningioma         19\n",
       "139                metastatic carcinoma         16\n",
       "163  oligodendroglioma, cns who grade 3          7\n",
       "55        diffuse large b-cell lymphoma          7\n",
       "124                            lymphoma          7\n",
       "172               pilocytic astrocytoma          6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#diagnosis counts\n",
    "\n",
    "def generate_diagnosis_counts(df, filename_prefix, save_path=\"./\"):\n",
    "    diagnosis_counts = (\n",
    "        df.groupby(\"permanent\")\n",
    "        .size()\n",
    "        .reset_index(name=\"row_count\")\n",
    "        .sort_values(by=\"row_count\", ascending=False)\n",
    "    )\n",
    "    counts_file = os.path.join(save_path, f\"{filename_prefix}_diagnosis_counts.csv\")\n",
    "    diagnosis_counts.to_csv(counts_file, index=False)\n",
    "    print(f\"✅ Diagnosis counts saved: {counts_file}\")\n",
    "    return diagnosis_counts\n",
    "\n",
    "# ✅ Example Run (after cleaning)\n",
    "df_cleaned = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")\n",
    "diagnosis_counts = generate_diagnosis_counts(df_cleaned, \"convnext\", save_path=\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data\")\n",
    "diagnosis_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2029d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered CSV saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_omas_only.csv\n",
      "✅ Shape: (273, 228) (rows, columns)\n"
     ]
    }
   ],
   "source": [
    "#generate new file w/ key word diagnoses only - glioma, glioblastoma, meningioma\n",
    "\n",
    "# Load the cleaned master CSV\n",
    "master_path = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "df_master = pd.read_csv(master_path)\n",
    "\n",
    "# ✅ Filter rows where \"permanent\" contains glioma, glioblastoma, or meningioma (case-insensitive)\n",
    "keywords = [\"glioma\", \"glioblastoma\", \"meningioma\"]\n",
    "pattern = \"|\".join(keywords)  # creates \"glioma|glioblastoma|meningioma\"\n",
    "\n",
    "df_filtered = df_master[df_master[\"permanent\"].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# ✅ Save the filtered CSV\n",
    "save_path = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_omas_only.csv\"\n",
    "df_filtered.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"✅ Filtered CSV saved: {save_path}\")\n",
    "print(f\"✅ Shape: {df_filtered.shape} (rows, columns)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
