{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff0d38d",
   "metadata": {},
   "source": [
    "okay so have to clean up the data a bit more (post talk w/ MJ)\n",
    "1. need to make all categorical values binary, and one-hot the diagnosis data (permanent) so DLMs can read it properly\n",
    "-one-hot encoding creates new columns—one per category—and fills them with 0/1 flags\n",
    "-drop_first=True: you can drop one column (e.g. oligodendroglioma) to avoid perfect multicollinearity\n",
    "2. also need to plot data to visualize it so we can see if there's an even spread and just see it\n",
    "3. stratify the y-axis avoid performance artifacts and ensures your model is evaluated on a realistic class balance\n",
    "-stratify=y tells train_test_split to preserve the same proportion of each class (0 vs. 1) in both the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59348447",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Still have non-numeric columns!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(\n\u001b[1;32m     26\u001b[0m     df,\n\u001b[1;32m     27\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermanent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m   \u001b[38;5;66;03m#drop 1st column = k-1, if you want to keep all dummies set drop_first=False\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# ── 7) (Optional) verify no remaining object cols ──\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStill have non-numeric columns!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ── 8) Save the fully-numeric DataFrame ──\u001b[39;00m\n\u001b[1;32m     37\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(out_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Still have non-numeric columns!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# ── 1) Paths ──\n",
    "in_csv  = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "out_csv = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input.csv\"\n",
    "\n",
    "# ── 2) Load ──\n",
    "df = pd.read_csv(in_csv)\n",
    "\n",
    "# ── 3) Identify all object/categorical columns ──\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "\n",
    "# ── 4) Find the ones that are truly binary (2 unique non-null values) ──\n",
    "binary_cols = [c for c in cat_cols if df[c].nunique(dropna=True)==2]\n",
    "\n",
    "# ── 5) Label-encode those binaries to 0/1 ──\n",
    "le = LabelEncoder()\n",
    "for c in binary_cols:\n",
    "    df[c] = le.fit_transform(df[c].astype(str))\n",
    "\n",
    "# ── 6) Now one-hot encode ONLY the 'permanent' diagnosis column ──\n",
    "#     (you can add more multi-class cols here if needed)\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"permanent\"],\n",
    "    prefix=\"diag\",\n",
    "    prefix_sep=\"_\",\n",
    "    drop_first=True   #drop 1st column = k-1, if you want to keep all dummies set drop_first=False\n",
    ")\n",
    "\n",
    "# ── 7) (Optional) verify no remaining object cols ──\n",
    "assert df.select_dtypes(include=[\"object\",\"category\"]).shape[1] == 0, \"Still have non-numeric columns!\"\n",
    "\n",
    "# ── 8) Save the fully-numeric DataFrame ──\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Saved model-ready CSV: {out_csv}\")\n",
    "print(f\"   → shape = {df.shape}  (rows, columns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e316f8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All columns are now numeric.\n",
      "✅ Saved model-ready CSV to: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input.csv\n",
      "   → Shape: (510, 1200) (rows, columns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# ── User-provided file path ──\n",
    "in_csv  = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "out_csv = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input.csv\"\n",
    "\n",
    "# ── Load the DataFrame ──\n",
    "df = pd.read_csv(in_csv)\n",
    "\n",
    "# ── Identify all object/categorical columns ──\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# ── Process each categorical column ──\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    n_unique = df[col].nunique(dropna=True)\n",
    "    if n_unique == 2:\n",
    "        # Binary: encode to 0/1\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    else:\n",
    "        # Multi-class: one-hot encode, drop first to avoid collinearity\n",
    "        df = pd.get_dummies(df, columns=[col], prefix=col, drop_first=True)\n",
    "\n",
    "# ── Verify no remaining non-numeric columns ──\n",
    "non_numeric = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "if non_numeric:\n",
    "    print(\"⚠️ Still non-numeric columns:\", non_numeric)\n",
    "else:\n",
    "    print(\"✅ All columns are now numeric.\")\n",
    "\n",
    "# ── Save the numeric DataFrame ──\n",
    "os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Saved model-ready CSV to: {out_csv}\")\n",
    "print(f\"   → Shape: {df.shape} (rows, columns)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1900df9",
   "metadata": {},
   "source": [
    "too many columns (1200+, excel can only output 1000 max)\n",
    "subset first, then one-hot (only permanent column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bf6b12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['chemotherapy_any', 'mortality_1yr'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m diag_col         \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermanent\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# the one multi-class\u001b[39;00m\n\u001b[1;32m     12\u001b[0m wanted \u001b[38;5;241m=\u001b[39m imaging_cols \u001b[38;5;241m+\u001b[39m keep_clinical \u001b[38;5;241m+\u001b[39m keep_molecular \u001b[38;5;241m+\u001b[39m [diag_col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmortality_1yr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m df_sub \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwanted\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Encode \u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#  a) Binary columns\u001b[39;00m\n\u001b[1;32m     17\u001b[0m binary_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m keep_clinical\u001b[38;5;241m+\u001b[39mkeep_molecular \u001b[38;5;28;01mif\u001b[39;00m df_sub[c]\u001b[38;5;241m.\u001b[39mnunique(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['chemotherapy_any', 'mortality_1yr'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")\n",
    "\n",
    "# 2. Define what you actually want (≥ 40 % complete)\n",
    "imaging_cols     = [c for c in df if c.startswith(\"feature_\")]\n",
    "keep_clinical    = [\"age\",\"sex\",\"chemotherapy_any\"]\n",
    "keep_molecular   = [\"mgmt_pyro\",\"methylation_class\",\"ki_67\"]\n",
    "diag_col         = \"permanent\"    # the one multi-class\n",
    "\n",
    "wanted = imaging_cols + keep_clinical + keep_molecular + [diag_col, \"mortality_1yr\"]\n",
    "df_sub = df[wanted].copy()\n",
    "\n",
    "# 3. Encode \n",
    "#  a) Binary columns\n",
    "binary_cols = [c for c in keep_clinical+keep_molecular if df_sub[c].nunique(dropna=True)==2]\n",
    "for c in binary_cols:\n",
    "    df_sub[c] = df_sub[c].map({df_sub[c].dropna().unique()[0]:0,\n",
    "                                df_sub[c].dropna().unique()[1]:1})\n",
    "\n",
    "#  b) One-hot the diagnosis\n",
    "df_out = pd.get_dummies(df_sub, columns=[diag_col], drop_first=True)\n",
    "\n",
    "# 4. Save\n",
    "df_out.to_csv(\"convnext_model_input_trimmed.csv\", index=False)\n",
    "print(\"→ final shape\", df_out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28c370",
   "metadata": {},
   "source": [
    "Created chemotherapy_any by OR’ing all chemotherapy___* columns\n",
    "\n",
    "Derived mortality_1yr from survival and patient_status\n",
    "\n",
    "Subselected only the imaging, clinical, molecular, diagnosis, and target columns\n",
    "\n",
    "Label‐encoded binary features and one‐hot encoded permanent\n",
    "\n",
    "Saved a trimmed, fully numeric CSV at /mnt/data/convnext_model_input_trimmed.csv (510 rows × 345 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989aeaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trimmed model input saved at: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\n",
      "   Final shape (rows, columns): (510, 345)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ── Paths ──\n",
    "in_csv  = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "out_csv = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\"\n",
    "\n",
    "# ── Load ──\n",
    "df = pd.read_csv(in_csv)\n",
    "\n",
    "# ── 1) Create 'chemotherapy_any' flag ──\n",
    "chemo_cols = [c for c in df.columns if c.startswith(\"chemotherapy___\")]\n",
    "if chemo_cols:\n",
    "    df[\"chemotherapy_any\"] = (df[chemo_cols].sum(axis=1) > 0).astype(int)\n",
    "else:\n",
    "    df[\"chemotherapy_any\"] = 0  # or drop if not present\n",
    "\n",
    "# ── 2) Create 1-year mortality flag 'mortality_1yr' ──\n",
    "# Assuming 'survival' (months) and 'patient_status' (2=dead) from earlier\n",
    "df[\"mortality_1yr\"] = np.where(\n",
    "    (df[\"survival\"] <= 12) & (df[\"patient_status\"] == 2.0),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# ── 3) Define columns to keep ──\n",
    "# Imaging features\n",
    "imaging_cols   = [c for c in df.columns if c.startswith(\"feature_\")]\n",
    "# Clinical/demographic\n",
    "keep_clinical  = [\"age\", \"sex\", \"chemotherapy_any\"]\n",
    "# Molecular (≥40% complete as decided)\n",
    "keep_molecular = [\"mgmt_pyro\", \"methylation_class\", \"ki_67\"]\n",
    "# Diagnosis and target\n",
    "diag_col       = \"permanent\"\n",
    "target_col     = \"mortality_1yr\"\n",
    "\n",
    "wanted = imaging_cols + keep_clinical + keep_molecular + [diag_col, target_col]\n",
    "df_sub = df[wanted].copy()\n",
    "\n",
    "# ── 4) Encode categorical ──\n",
    "# Binary columns\n",
    "binary_cols = [c for c in keep_clinical+keep_molecular if df_sub[c].nunique(dropna=True)==2]\n",
    "for c in binary_cols:\n",
    "    df_sub[c] = df_sub[c].astype(str).map(\n",
    "        {df_sub[c].dropna().unique()[0]:0,\n",
    "         df_sub[c].dropna().unique()[1]:1}\n",
    "    )\n",
    "\n",
    "# One-hot for diagnosis\n",
    "df_out = pd.get_dummies(df_sub, columns=[diag_col], drop_first=True)\n",
    "\n",
    "# ── 5) Save ──\n",
    "df_out.to_csv(out_csv, index=False)\n",
    "print(\"✅ Trimmed model input saved at:\", out_csv)\n",
    "print(\"   Final shape (rows, columns):\", df_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895457f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a7c5ed",
   "metadata": {},
   "source": [
    "trying to figure out 1 and 2 yr mortality rates\n",
    "see a big class imbalance --> greater than the recommended 3:7 (97.4:100)\n",
    "consider looking at 6 mo and 9 mo and overall survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef95431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1‑year mortality: 38/39 = 97.4%\n",
      "2‑year mortality: 70/70 = 100.0%\n",
      "✅ Saved per‑diagnosis mortality rates to: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_mortality_rates_by_diagnosis.csv\n",
      "                                                   1yr_n  1yr_deaths  \\\n",
      "permanent                                                              \n",
      "anaplastic astrocytoma                               1.0         1.0   \n",
      "anaplastic astrocytoma who grade iii                 NaN         NaN   \n",
      "anaplastic diffuse glioma, at least who grade iii    1.0         1.0   \n",
      "astrocytoma, idh-mutant, cns who grade 4             1.0         1.0   \n",
      "burkitt lymphoma                                     1.0         1.0   \n",
      "glioblastoma                                         2.0         2.0   \n",
      "glioblastoma who grade iv                           15.0        14.0   \n",
      "glioblastoma, cns who grade 4                       13.0        13.0   \n",
      "glioblastoma, cns who grade 4,                       1.0         1.0   \n",
      "glioblastoma, idh wildtype                           NaN         NaN   \n",
      "\n",
      "                                                     1yr_rate  2yr_n  \\\n",
      "permanent                                                              \n",
      "anaplastic astrocytoma                             100.000000      1   \n",
      "anaplastic astrocytoma who grade iii                      NaN      2   \n",
      "anaplastic diffuse glioma, at least who grade iii  100.000000      1   \n",
      "astrocytoma, idh-mutant, cns who grade 4           100.000000      1   \n",
      "burkitt lymphoma                                   100.000000      1   \n",
      "glioblastoma                                       100.000000     10   \n",
      "glioblastoma who grade iv                           93.333333     22   \n",
      "glioblastoma, cns who grade 4                      100.000000     18   \n",
      "glioblastoma, cns who grade 4,                     100.000000      2   \n",
      "glioblastoma, idh wildtype                                NaN      1   \n",
      "\n",
      "                                                   2yr_deaths  2yr_rate  \n",
      "permanent                                                                \n",
      "anaplastic astrocytoma                                      1     100.0  \n",
      "anaplastic astrocytoma who grade iii                        2     100.0  \n",
      "anaplastic diffuse glioma, at least who grade iii           1     100.0  \n",
      "astrocytoma, idh-mutant, cns who grade 4                    1     100.0  \n",
      "burkitt lymphoma                                            1     100.0  \n",
      "glioblastoma                                               10     100.0  \n",
      "glioblastoma who grade iv                                  22     100.0  \n",
      "glioblastoma, cns who grade 4                              18     100.0  \n",
      "glioblastoma, cns who grade 4,                              2     100.0  \n",
      "glioblastoma, idh wildtype                                  1     100.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ── 1) Load your cleaned master CSV ──\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")\n",
    "\n",
    "# ── 2) Derive 1‑year and 2‑year raw labels with proper censoring ──\n",
    "df[\"mortality_1yr_raw\"] = np.where(\n",
    "    (df[\"survival\"] <= 12) & (df[\"patient_status\"] == 2.0), 1,\n",
    "    np.where((df[\"survival\"] >= 12) & (df[\"patient_status\"] == 1.0), 0, np.nan)\n",
    ")\n",
    "df[\"mortality_2yr_raw\"] = np.where(\n",
    "    (df[\"survival\"] <= 24) & (df[\"patient_status\"] == 2.0), 1,\n",
    "    np.where((df[\"survival\"] >= 24) & (df[\"patient_status\"] == 1.0), 0, np.nan)\n",
    ")\n",
    "\n",
    "# ── 3) Subset to fully labeled cohorts ──\n",
    "df_1yr = df[df[\"mortality_1yr_raw\"].notna()].copy()\n",
    "df_2yr = df[df[\"mortality_2yr_raw\"].notna()].copy()\n",
    "df_1yr[\"mortality_1yr\"] = df_1yr[\"mortality_1yr_raw\"].astype(int)\n",
    "df_2yr[\"mortality_2yr\"] = df_2yr[\"mortality_2yr_raw\"].astype(int)\n",
    "\n",
    "# ── 4) Calculate overall rates ──\n",
    "n1, d1 = len(df_1yr), df_1yr[\"mortality_1yr\"].sum()\n",
    "n2, d2 = len(df_2yr), df_2yr[\"mortality_2yr\"].sum()\n",
    "print(f\"1‑year mortality: {d1}/{n1} = {d1/n1*100:.1f}%\")\n",
    "print(f\"2‑year mortality: {d2}/{n2} = {d2/n2*100:.1f}%\")\n",
    "\n",
    "# ── 5) Mortality rates by diagnosis ──\n",
    "summary = pd.DataFrame({\n",
    "    \"1yr_n\":     df_1yr.groupby(\"permanent\").size(),\n",
    "    \"1yr_deaths\":df_1yr.groupby(\"permanent\")[\"mortality_1yr\"].sum(),\n",
    "    \"1yr_rate\":  df_1yr.groupby(\"permanent\")[\"mortality_1yr\"].mean()*100,\n",
    "    \"2yr_n\":     df_2yr.groupby(\"permanent\").size(),\n",
    "    \"2yr_deaths\":df_2yr.groupby(\"permanent\")[\"mortality_2yr\"].sum(),\n",
    "    \"2yr_rate\":  df_2yr.groupby(\"permanent\")[\"mortality_2yr\"].mean()*100\n",
    "})\n",
    "out_path = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_mortality_rates_by_diagnosis.csv\"\n",
    "summary.to_csv(out_path)\n",
    "print(\"✅ Saved per‑diagnosis mortality rates to:\", out_path)\n",
    "print(summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77ea648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m mortality: 19/22 = 86.4% positive\n",
      "  → Saved per-diagnosis 6m-m summary to /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_mortality_6m_by_dx.csv\n",
      "9m mortality: 28/31 = 90.3% positive\n",
      "  → Saved per-diagnosis 9m-m summary to /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_mortality_9m_by_dx.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1) Load your cleaned master CSV\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")\n",
    "\n",
    "# 2) Derive 6- and 9-month raw labels, properly censoring those without enough follow-up\n",
    "def make_binary_label(df, months, event_col=\"patient_status\", time_col=\"survival\"):\n",
    "    # 1 = died on or before `months`; 0 = alive at or beyond `months`; NaN = censored before `months`\n",
    "    return np.where(\n",
    "        (df[time_col] <= months) & (df[event_col] == 2.0), 1,\n",
    "    np.where(\n",
    "        (df[time_col] >= months) & (df[event_col] == 1.0), 0,\n",
    "        np.nan\n",
    "    ))\n",
    "\n",
    "df[\"mortality_6m_raw\"] = make_binary_label(df, 6)\n",
    "df[\"mortality_9m_raw\"] = make_binary_label(df, 9)\n",
    "\n",
    "# 3) Subset to fully labeled patients\n",
    "df6 = df[df[\"mortality_6m_raw\"].notna()].copy()\n",
    "df9 = df[df[\"mortality_9m_raw\"].notna()].copy()\n",
    "df6[\"mortality_6m\"] = df6[\"mortality_6m_raw\"].astype(int)\n",
    "df9[\"mortality_9m\"] = df9[\"mortality_9m_raw\"].astype(int)\n",
    "\n",
    "# 4) Compute and save class‐balance summaries\n",
    "for label, subdf in [(\"6m\", df6), (\"9m\", df9)]:\n",
    "    n = len(subdf)\n",
    "    d = subdf[f\"mortality_{label}\"].sum()\n",
    "    pct = d/n*100\n",
    "    print(f\"{label} mortality: {d}/{n} = {pct:.1f}% positive\")\n",
    "    # Optionally save per-diagnosis breakdown:\n",
    "    summary = (\n",
    "        subdf.groupby(\"permanent\")[f\"mortality_{label}\"]\n",
    "             .agg(n=\"size\", deaths=\"sum\")\n",
    "             .assign(rate=lambda x: x[\"deaths\"]/x[\"n\"]*100)\n",
    "    )\n",
    "    out = f\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_mortality_{label}_by_dx.csv\"\n",
    "    summary.to_csv(out)\n",
    "    print(f\"  → Saved per-diagnosis {label}-m summary to {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f5794b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'patient_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'patient_status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 2) Build the structured survival array via from_arrays\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#    event = True if patient_status == 2.0 (dead), False otherwise\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#    time  = survival time in months\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatient_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m     15\u001b[0m time  \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurvival\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m surv  \u001b[38;5;241m=\u001b[39m Surv\u001b[38;5;241m.\u001b[39mfrom_arrays(event, time)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'patient_status'"
     ]
    }
   ],
   "source": [
    "# overall survival \n",
    "\n",
    "import pandas as pd\n",
    "from sksurv.util import Surv\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# 1) Load your cleaned master CSV\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\")\n",
    "\n",
    "# 2) Build the structured survival array via from_arrays\n",
    "#    event = True if patient_status == 2.0 (dead), False otherwise\n",
    "#    time  = survival time in months\n",
    "event = df[\"patient_status\"] == 2.0\n",
    "time  = df[\"survival\"]\n",
    "surv  = Surv.from_arrays(event, time)\n",
    "\n",
    "# 3) Select your feature matrix X\n",
    "image_feats     = [c for c in df.columns if c.startswith(\"feature_\")]\n",
    "non_image_feats = [\"age\",\"sex\",\"mgmt_pyro\",\"methylation_class\",\"ki_67\"]\n",
    "X = df[non_image_feats + image_feats]\n",
    "\n",
    "# 4) Fit the Cox model\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X, surv)\n",
    "\n",
    "# 5) Evaluate via concordance index (higher ↑ is better; 0.5 = random)\n",
    "cindex = concordance_index_censored(\n",
    "    surv[\"event\"], surv[\"time\"], cox.predict(X)\n",
    ")[0]\n",
    "print(f\"CoxPH concordance index (C-index): {cindex:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae8c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved trimmed model input with IDs: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\n",
      "   Shape: (39, 479) (rows, columns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# ── Paths ──\n",
    "in_csv  = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\"\n",
    "out_csv = \"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\"\n",
    "\n",
    "# ── Load original cleaned master ──\n",
    "df = pd.read_csv(in_csv)\n",
    "\n",
    "# ── 1) Preserve patient IDs ──\n",
    "case_id_col = \"case_number\"\n",
    "\n",
    "# ── 2) Create 'chemotherapy_any' flag ──\n",
    "chemo_cols = [c for c in df.columns if c.startswith(\"chemotherapy___\")]\n",
    "df[\"chemotherapy_any\"] = (df[chemo_cols].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# ── 3) Create 1-year mortality flag 'mortality_1yr' with censoring ──\n",
    "df[\"mortality_1yr\"] = np.where(\n",
    "    (df[\"survival\"] <= 12) & (df[\"patient_status\"] == 2.0), 1,\n",
    "    np.where((df[\"survival\"] >= 12) & (df[\"patient_status\"] == 1.0), 0, np.nan)\n",
    ")\n",
    "\n",
    "# ── 4) Select desired columns ──\n",
    "imaging_cols   = [c for c in df.columns if c.startswith(\"feature_\")]\n",
    "keep_clinical  = [\"age\", \"sex\", \"chemotherapy_any\"]\n",
    "keep_molecular = [\"mgmt_pyro\", \"methylation_class\", \"ki_67\"]\n",
    "diag_col       = \"permanent\"\n",
    "target_col     = \"mortality_1yr\"\n",
    "\n",
    "wanted = [case_id_col] + imaging_cols + keep_clinical + keep_molecular + [diag_col, target_col]\n",
    "df_sub = df[wanted].copy()\n",
    "\n",
    "# ── 5) Encode categorical columns ──\n",
    "le = LabelEncoder()\n",
    "cat_cols = df_sub.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    unique_vals = df_sub[col].dropna().unique()\n",
    "    if len(unique_vals) == 2:\n",
    "        # Binary: map two categories to 0/1\n",
    "        df_sub[col] = le.fit_transform(df_sub[col].astype(str))\n",
    "    else:\n",
    "        # Multi-class: one-hot encode, drop first level\n",
    "        df_sub = pd.get_dummies(df_sub, columns=[col], prefix=col, drop_first=True)\n",
    "\n",
    "# ── 6) Drop rows still censored before 1 year ──\n",
    "df_sub = df_sub[df_sub[target_col].notna()].copy()\n",
    "\n",
    "# ── 7) Save trimmed with ID ──\n",
    "os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "df_sub.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Saved trimmed model input with IDs: {out_csv}\")\n",
    "print(f\"   Shape: {df_sub.shape} (rows, columns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "606a539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoxPH C-index (L2, α=1.0): 0.820\n"
     ]
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "# … after imputing X_imp and building surv …\n",
    "\n",
    "# Use an alpha > 0 to penalize collinearity\n",
    "cox = CoxPHSurvivalAnalysis(alpha=1.0)  \n",
    "cox.fit(X_imp, surv)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    surv[\"event\"], surv[\"time\"], cox.predict(X_imp)\n",
    ")[0]\n",
    "print(f\"CoxPH C-index (L2, α=1.0): {cindex:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d09ad87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nCoxPHSurvivalAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Now X contains only numeric predictors: imaging features, clinical flags, one-hot columns, etc.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# ── 5) Fit CoxPH and compute C-index ──\u001b[39;00m\n\u001b[1;32m     35\u001b[0m cox \u001b[38;5;241m=\u001b[39m CoxPHSurvivalAnalysis()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mcox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m cindex \u001b[38;5;241m=\u001b[39m concordance_index_censored(\n\u001b[1;32m     39\u001b[0m     surv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m], surv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m], cox\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     40\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ CoxPH concordance index (C-index): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcindex\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:416\u001b[0m, in \u001b[0;36mCoxPHSurvivalAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize negative partial log-likelihood for provided data.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 416\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m event, time \u001b[38;5;241m=\u001b[39m check_array_survival(X, y)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha, numbers\u001b[38;5;241m.\u001b[39mReal \u001b[38;5;241m|\u001b[39m numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nCoxPHSurvivalAnalysis does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sksurv.util import Surv\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# ── 1) Load the two CSVs ──\n",
    "df_master     = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")                 # has survival & patient_status\n",
    "df_preds      = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\")    # numeric predictors + case_number\n",
    "\n",
    "# ── 2) Merge to bring back time/event ──\n",
    "df = df_preds.merge(\n",
    "    df_master[[\"case_number\",\"patient_status\",\"survival\"]],\n",
    "    on=\"case_number\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ── 3) Build the survival array ──\n",
    "#    event: True when patient_status == 2 (dead)\n",
    "#    time:  months in df[\"survival\"]\n",
    "event = df[\"patient_status\"] == 2.0\n",
    "time  = df[\"survival\"]\n",
    "surv  = Surv.from_arrays(event, time)\n",
    "\n",
    "# ── 4) Drop non-predictors to form X ──\n",
    "#    Remove ID, the two survival columns, plus any explicit binary target if present\n",
    "drop_cols = [\"case_number\", \"patient_status\", \"survival\"]\n",
    "# If your trimmed file also has mortality_1yr, you can drop it here:\n",
    "if \"mortality_1yr\" in df.columns:\n",
    "    drop_cols.append(\"mortality_1yr\")\n",
    "X = df.drop(columns=drop_cols)\n",
    "\n",
    "# Now X contains only numeric predictors: imaging features, clinical flags, one-hot columns, etc.\n",
    "\n",
    "# ── 5) Fit CoxPH and compute C-index ──\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X, surv)\n",
    "\n",
    "cindex = concordance_index_censored(\n",
    "    surv[\"event\"], surv[\"time\"], cox.predict(X)\n",
    ")[0]\n",
    "print(f\"✅ CoxPH concordance index (C-index): {cindex:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0994d351",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 5) Fit CoxPH on the imputed data\u001b[39;00m\n\u001b[1;32m     35\u001b[0m cox \u001b[38;5;241m=\u001b[39m CoxPHSurvivalAnalysis()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mcox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_imp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 6) Evaluate via concordance index\u001b[39;00m\n\u001b[1;32m     39\u001b[0m cindex \u001b[38;5;241m=\u001b[39m concordance_index_censored(\n\u001b[1;32m     40\u001b[0m     surv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m], surv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m], cox\u001b[38;5;241m.\u001b[39mpredict(X_imp)\n\u001b[1;32m     41\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/sksurv/linear_model/coxph.py:449\u001b[0m, in \u001b[0;36mCoxPHSurvivalAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    448\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate(w)\n\u001b[0;32m--> 449\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(delta)):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch direction contains NaN or infinite values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/scipy/linalg/_basic.py:290\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b, lower, overwrite_a, overwrite_b, check_finite, assume_a, transposed)\u001b[0m\n\u001b[1;32m    285\u001b[0m     lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(sysv_lw, n, lower)\n\u001b[1;32m    286\u001b[0m     lu, ipvt, x, info \u001b[38;5;241m=\u001b[39m sysv(a1, b1, lwork\u001b[38;5;241m=\u001b[39mlwork,\n\u001b[1;32m    287\u001b[0m                              lower\u001b[38;5;241m=\u001b[39mlower,\n\u001b[1;32m    288\u001b[0m                              overwrite_a\u001b[38;5;241m=\u001b[39moverwrite_a,\n\u001b[1;32m    289\u001b[0m                              overwrite_b\u001b[38;5;241m=\u001b[39moverwrite_b)\n\u001b[0;32m--> 290\u001b[0m     \u001b[43m_solve_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     rcond, info \u001b[38;5;241m=\u001b[39m sycon(lu, ipvt, anorm)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Diagonal case\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/scipy/linalg/_basic.py:42\u001b[0m, in \u001b[0;36m_solve_check\u001b[0;34m(n, info, lamch, rcond)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAPACK reported an illegal value in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-th argument.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m info:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatrix is singular.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lamch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Matrix is singular."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sksurv.util import Surv\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1) Load your merged DataFrame (preds + survival)\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_model_input_trimmed.csv\") \\\n",
    "       .merge(\n",
    "         pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\")[[\"case_number\",\"patient_status\",\"survival\"]],\n",
    "         on=\"case_number\", how=\"left\"\n",
    "       )\n",
    "\n",
    "# 2) Build the survival array\n",
    "event = df[\"patient_status\"] == 2.0\n",
    "time  = df[\"survival\"]\n",
    "surv  = Surv.from_arrays(event, time)\n",
    "\n",
    "# 3) Prepare your feature matrix X\n",
    "#    Drop ID, survival/time, event/status, and the explicit target if present\n",
    "drop_cols = [\"case_number\",\"patient_status\",\"survival\"]\n",
    "if \"mortality_1yr\" in df.columns:\n",
    "    drop_cols.append(\"mortality_1yr\")\n",
    "X = df.drop(columns=drop_cols)\n",
    "\n",
    "# 4) Median‐impute any remaining NaNs\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_imp = pd.DataFrame(\n",
    "    imp.fit_transform(X),\n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# 5) Fit CoxPH on the imputed data\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_imp, surv)\n",
    "\n",
    "# 6) Evaluate via concordance index\n",
    "cindex = concordance_index_censored(\n",
    "    surv[\"event\"], surv[\"time\"], cox.predict(X_imp)\n",
    ")[0]\n",
    "print(f\"CoxPH C-index after median imputation: {cindex:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
