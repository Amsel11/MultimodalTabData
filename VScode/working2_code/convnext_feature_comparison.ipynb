{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db1cbce",
   "metadata": {},
   "source": [
    "focusing code on 1 algorithm (tabnet) + 1 baseline (svm) + 1 cnn (pretrained convnext)\n",
    "- still running all same tasks\n",
    "- running the 4 different convnext datasets (based off # of features + SD info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb29951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dataset paths found.\n",
      "Report will be written to: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_tabnet_svm_report.txt\n",
      "TabNet available: True\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 — config & smoke test\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATASETS = {\n",
    "    'ConvNext_128d': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_128d.csv',\n",
    "    'ConvNext_256d': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_256d.csv',\n",
    "    'ConvNext_Sep_128d': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_separate_128d.csv',\n",
    "    'ConvNext_Sep_256d': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_separate_256d.csv'\n",
    "}\n",
    "\n",
    "REPORT_DIR = Path(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_data\")\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_PATH = REPORT_DIR / \"convnext_tabnet_svm_report.txt\"\n",
    "\n",
    "# Check dataset paths exist\n",
    "for name, p in DATASETS.items():\n",
    "    pth = Path(p)\n",
    "    if not pth.exists():\n",
    "        raise FileNotFoundError(f\"{name} not found at: {pth}\")\n",
    "\n",
    "# Optional TabNet check\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier  # noqa\n",
    "    TABNET_AVAILABLE = True\n",
    "except Exception:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"TabNet not available. You can still run SVM. To add TabNet: pip install pytorch-tabnet torch\")\n",
    "\n",
    "print(\"All dataset paths found.\")\n",
    "print(f\"Report will be written to: {REPORT_PATH}\")\n",
    "print(f\"TabNet available: {TABNET_AVAILABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf676864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset shape: (532, 232)\n",
      "Num tasks found: 6\n",
      " Mortality_6mo -> n=86, pos_rate=0.221\n",
      "Mortality_12mo -> n=84, pos_rate=0.452\n",
      "Mortality_24mo -> n=83, pos_rate=0.843\n",
      "     HighGrade -> n=532, pos_rate=0.242\n",
      "       IDH_mut -> n=196, pos_rate=0.786\n",
      "     MGMT_meth -> n=212, pos_rate=0.396\n",
      "Num features selected: 141\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 — loaders, targets, and features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MORTALITY_WINDOWS = [6, 12, 24]\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV into a DataFrame.\"\"\"\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def build_targets(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return dict: task_name -> (row_index, y_array)\n",
    "    - Mortality at 6/12/24 months using survival (months) and patient_status (2=dead).\n",
    "    - High-grade via methylation_class text.\n",
    "    - IDH: idh_1_r132h (1=neg, 2=mut).\n",
    "    - MGMT: mgmt (1=methylated, 2=unmethylated).\n",
    "    \"\"\"\n",
    "    targets = {}\n",
    "\n",
    "   # Mortality (landmark at 6/12/24 months), using your status codes:\n",
    "# 1 = Alive, 2 = Deceased (date known), 3 = Deceased: Date Unknown (exclude)\n",
    "    if {'survival', 'patient_status'}.issubset(df.columns):\n",
    "     has_time = df['survival'].notna()\n",
    "     status = df['patient_status']\n",
    "    known_status = status.isin([1, 2])  # exclude 3\n",
    "\n",
    "    for m in MORTALITY_WINDOWS:\n",
    "        # Eligible if: known time, known status, and either died (any time) OR observed at least m months\n",
    "        eligible = has_time & known_status & ((status == 2) | (df['survival'] >= m))\n",
    "        idx = df.index[eligible]\n",
    "\n",
    "        # Positive = died by m months with known death date\n",
    "        y = ((status.loc[idx] == 2) & (df.loc[idx, 'survival'] <= m)).astype(int).to_numpy()\n",
    "        targets[f\"Mortality_{m}mo\"] = (idx, y)\n",
    "\n",
    "    # High-grade tumor via methylation_class\n",
    "    if 'methylation_class' in df.columns:\n",
    "        cls = df['methylation_class'].astype(str).str.lower()\n",
    "        hg_mask = cls.notna()\n",
    "        hg_idx = df.index[hg_mask]\n",
    "        high_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'gbm']\n",
    "        y = cls.loc[hg_idx].str.contains('|'.join(high_terms), na=False).astype(int).to_numpy()\n",
    "        targets[\"HighGrade\"] = (hg_idx, y)\n",
    "\n",
    "    # IDH mutation\n",
    "    if 'idh_1_r132h' in df.columns:\n",
    "        idh_mask = df['idh_1_r132h'].isin([1, 2])\n",
    "        idh_idx = df.index[idh_mask]\n",
    "        y = (df.loc[idh_idx, 'idh_1_r132h'] == 2).astype(int).to_numpy()\n",
    "        targets[\"IDH_mut\"] = (idh_idx, y)\n",
    "\n",
    "    # MGMT methylation\n",
    "    if 'mgmt' in df.columns:\n",
    "        mgmt_mask = df['mgmt'].isin([1, 2])\n",
    "        mgmt_idx = df.index[mgmt_mask]\n",
    "        y = (df.loc[mgmt_idx, 'mgmt'] == 1).astype(int).to_numpy()\n",
    "        targets[\"MGMT_meth\"] = (df.index[mgmt_mask], y)\n",
    "\n",
    "    return targets\n",
    "\n",
    "def select_features(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Collect available features: clinical + molecular + image features.\n",
    "    We’ll drop target-leaky columns per task later.\n",
    "    \"\"\"\n",
    "    clinical = [c for c in ['age', 'sex', 'race', 'ethnicity', 'gtr'] if c in df.columns]\n",
    "\n",
    "    # Image features (two possible schemas)\n",
    "    if any(c.startswith('mean_feature_') for c in df.columns):\n",
    "        image = [c for c in df.columns if c.startswith(('mean_feature_', 'std_feature_'))]\n",
    "    else:\n",
    "        image = [c for c in df.columns if c.startswith('feature_')]\n",
    "\n",
    "    molecular = [c for c in ['mgmt_pyro', 'atrx', 'p53', 'braf_v600', 'h3k27m', 'gfap',\n",
    "                             'idh_1_r132h', 'mgmt'] if c in df.columns]\n",
    "\n",
    "    feats = clinical + molecular + image\n",
    "    return feats\n",
    "\n",
    "# Quick smoke test on one dataset\n",
    "_first_path = next(iter(DATASETS.values()))\n",
    "_df0 = load_dataset(_first_path)\n",
    "_tgts0 = build_targets(_df0)\n",
    "_feats0 = select_features(_df0)\n",
    "\n",
    "print(\"Sample dataset shape:\", _df0.shape)\n",
    "print(\"Num tasks found:\", len(_tgts0))\n",
    "for name, (idx, y) in _tgts0.items():\n",
    "    print(f\"{name:>14} -> n={len(idx)}, pos_rate={y.mean():.3f}\")\n",
    "print(\"Num features selected:\", len(_feats0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dabef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 — evaluation loop + report (SVM + optional TabNet) with AP (PR-AUC)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, average_precision_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TabNet optional\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    TABNET_AVAILABLE = True\n",
    "except Exception:\n",
    "    TABNET_AVAILABLE = False\n",
    "\n",
    "# -------- helpers\n",
    "\n",
    "def drop_leaky_features(feat_cols, task_name):\n",
    "    f = feat_cols.copy()\n",
    "    tl = task_name.lower()\n",
    "    if 'idh' in tl:\n",
    "        f = [c for c in f if 'idh' not in c.lower()]\n",
    "    if 'mgmt' in tl:\n",
    "        f = [c for c in f if 'mgmt' not in c.lower() and 'mgmt_pyro' not in c.lower()]\n",
    "    f = [c for c in f if c != 'methylation_class']\n",
    "    return f\n",
    "\n",
    "def prep_svm(df, feat_cols, idx, y):\n",
    "    Xdf = df.loc[idx, feat_cols].copy()\n",
    "    cat_cols = [c for c in Xdf.columns if Xdf[c].dtype == 'object' or str(Xdf[c].dtype).startswith('category')]\n",
    "    cat_cols += [c for c in Xdf.columns if Xdf[c].dtype == 'bool' and c not in cat_cols]\n",
    "    cat_cols = list(dict.fromkeys(cat_cols))\n",
    "    num_cols = [c for c in Xdf.columns if c not in cat_cols]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler())\n",
    "            ]), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        n_jobs=None\n",
    "    )\n",
    "    return Xdf, y, preprocessor\n",
    "\n",
    "def train_eval_svm(Xdf, y, preprocessor, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Xdf, y, test_size=0.25, stratify=y, random_state=random_state\n",
    "    )\n",
    "    svm_clf = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", SVC(probability=True, class_weight=\"balanced\", random_state=random_state))\n",
    "    ])\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    y_proba = svm_clf.predict_proba(X_test)[:, 1]\n",
    "    y_hat = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    test_auc = roc_auc_score(y_test, y_proba)\n",
    "    test_ap  = average_precision_score(y_test, y_proba)\n",
    "    test_acc = accuracy_score(y_test, y_hat)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    cv_auc = cross_val_score(svm_clf, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
    "    return test_auc, test_ap, test_acc, cv_auc.mean(), cv_auc.std()\n",
    "\n",
    "def prep_tabnet(df, feat_cols, idx, y):\n",
    "    X = df.loc[idx, feat_cols].copy()\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == 'object' or str(X[c].dtype).startswith('category') or X[c].dtype == 'bool']\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    for c in num_cols:\n",
    "        X[c] = X[c].astype(float)\n",
    "        if X[c].isna().any():\n",
    "            X[c] = X[c].fillna(X[c].median())\n",
    "\n",
    "    cat_idxs, cat_dims = [], []\n",
    "    for i, c in enumerate(X.columns):\n",
    "        if c in cat_cols:\n",
    "            codes, uniques = pd.factorize(X[c].astype(str), sort=True)\n",
    "            X[c] = codes\n",
    "            cat_idxs.append(i)\n",
    "            cat_dims.append(len(uniques))\n",
    "        else:\n",
    "            X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(X[c].median())\n",
    "\n",
    "    X_np = X.to_numpy().astype(np.float32)\n",
    "    y_np = np.asarray(y).astype(int)\n",
    "    return X_np, y_np, cat_idxs, cat_dims\n",
    "\n",
    "def train_eval_tabnet(X, y, cat_idxs, cat_dims, random_state=42):\n",
    "    X_train, X_test,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545e9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAG START\n",
      "REPORT_PATH: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_tabnet_svm_report.txt\n",
      "Report folder exists?: True\n",
      "File write: OK\n",
      "Will process: ConvNext_128d\n",
      "  rows/cols: (532, 232) | tasks: ['Mortality_6mo', 'Mortality_12mo', 'Mortality_24mo', 'HighGrade', 'IDH_mut', 'MGMT_meth']\n",
      "Will process: ConvNext_256d\n",
      "  rows/cols: (532, 356) | tasks: ['Mortality_6mo', 'Mortality_12mo', 'Mortality_24mo', 'HighGrade', 'IDH_mut', 'MGMT_meth']\n",
      "Will process: ConvNext_Sep_128d\n",
      "  rows/cols: (532, 228) | tasks: ['Mortality_6mo', 'Mortality_12mo', 'Mortality_24mo', 'HighGrade', 'IDH_mut', 'MGMT_meth']\n",
      "Will process: ConvNext_Sep_256d\n",
      "  rows/cols: (532, 356) | tasks: ['Mortality_6mo', 'Mortality_12mo', 'Mortality_24mo', 'HighGrade', 'IDH_mut', 'MGMT_meth']\n",
      "DIAG END\n"
     ]
    }
   ],
   "source": [
    "# DIAG 3a — file write + loop smoke test\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"DIAG START\")\n",
    "print(\"REPORT_PATH:\", REPORT_PATH)\n",
    "print(\"Report folder exists?:\", REPORT_PATH.parent.exists())\n",
    "\n",
    "# Try writing a tiny file right away\n",
    "try:\n",
    "    with open(REPORT_PATH, \"w\") as f:\n",
    "        f.write(\"diagnostic write\\n\")\n",
    "    print(\"File write: OK\")\n",
    "except Exception as e:\n",
    "    print(\"File write: FAILED ->\", repr(e))\n",
    "\n",
    "# Check the training loop would iterate\n",
    "for ds_name, ds_path in DATASETS.items():\n",
    "    print(\"Will process:\", ds_name)\n",
    "    try:\n",
    "        df = load_dataset(ds_path)\n",
    "        tgts = build_targets(df)\n",
    "        print(\"  rows/cols:\", df.shape, \"| tasks:\", [k for k in tgts.keys()])\n",
    "    except Exception as e:\n",
    "        print(\"  ERROR ->\", repr(e))\n",
    "\n",
    "print(\"DIAG END\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
