{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebdcaca",
   "metadata": {},
   "source": [
    "focusing on the comprehensive analaysis script that worked before\n",
    "will fix specific aspects like class imbalance later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46399cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE NEUROSURGICAL AI ANALYSIS SYSTEM\n",
      "======================================================================\n",
      "GOAL: Comprehensive evaluation of CNN architectures and ML algorithms\n",
      "SCOPE: 5 CNNs √ó Multiple Algorithms √ó 6 Clinical Tasks\n",
      "OUTPUT: Clinical-ready recommendations for your team and PI\n",
      "======================================================================\n",
      "CHECKING DATA FILE PATHS:\n",
      "==================================================\n",
      "ConvNext            : EXISTS\n",
      "ViT                 : EXISTS\n",
      "ResNet50_Pretrained : EXISTS\n",
      "ResNet50_ImageNet   : EXISTS\n",
      "EfficientNet        : EXISTS\n",
      "==================================================\n",
      "\n",
      "Found 5/5 data files\n",
      "SUCCESS: All data files found!\n",
      "\n",
      "COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\n",
      "======================================================================\n",
      "Testing 5 CNNs √ó Multiple ML Algorithms √ó 6 Clinical Tasks\n",
      "Target: Clinical-grade performance (AUC >= 0.80)\n",
      "======================================================================\n",
      "\n",
      "AVAILABLE ALGORITHMS (6):\n",
      "   TabPFN: Transformer-based Few-Shot Learning\n",
      "   XGBoost: Optimized Gradient Boosting\n",
      "   TabNet: Optimized Attention-based Neural Network\n",
      "   RandomForest: Optimized Ensemble Decision Trees\n",
      "   LogisticRegression: Regularized Linear Model with ElasticNet\n",
      "   SVM: Support Vector Machine with RBF Kernel\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ConvNext DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ConvNext\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv\n",
      "Dataset shape: (510, 228)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 141\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.692 (95% CI: 0.670-0.714)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       GOOD performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.788\n",
      "   CROSS-VAL: AUC=0.713 (95% CI: 0.657-0.770)\n",
      "   STABILITY: STABLE\n",
      "       GOOD performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 45 and best_val_0_auc = 0.71765\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.625\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.48077\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.90385\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.94231\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.718\n",
      "   CROSS-VAL: AUC=0.762 (95% CI: 0.540-0.984)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.826 (95% CI: 0.752-0.901)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.612\n",
      "   CROSS-VAL: AUC=0.614 (95% CI: 0.508-0.721)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.224\n",
      "   CROSS-VAL: AUC=0.553 (95% CI: 0.230-0.875)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.742\n",
      "   CROSS-VAL: AUC=0.681 (95% CI: 0.532-0.831)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.717\n",
      "   CROSS-VAL: AUC=0.756 (95% CI: 0.598-0.915)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_auc = 0.81667\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.8625\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.84722\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.65714\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.64286\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.817\n",
      "   CROSS-VAL: AUC=0.758 (95% CI: 0.643-0.872)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.667\n",
      "   CROSS-VAL: AUC=0.724 (95% CI: 0.519-0.928)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.607 (95% CI: 0.429-0.784)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.717\n",
      "   CROSS-VAL: AUC=0.425 (95% CI: 0.219-0.632)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.486\n",
      "   CROSS-VAL: AUC=0.650 (95% CI: 0.497-0.803)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.667\n",
      "   CROSS-VAL: AUC=0.689 (95% CI: 0.552-0.826)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.97619\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.90476\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_val_0_auc = 1.0\n",
      "   HOLDOUT: Accuracy=0.864, AUC=0.875\n",
      "   CROSS-VAL: AUC=0.912 (95% CI: 0.827-0.996)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.681\n",
      "   CROSS-VAL: AUC=0.733 (95% CI: 0.598-0.869)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.653\n",
      "   CROSS-VAL: AUC=0.407 (95% CI: 0.101-0.713)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.444\n",
      "   CROSS-VAL: AUC=0.314 (95% CI: 0.108-0.520)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.836, AUC=0.891\n",
      "   CROSS-VAL: AUC=0.881 (95% CI: 0.822-0.941)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.889\n",
      "   CROSS-VAL: AUC=0.861 (95% CI: 0.803-0.919)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.74134\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.71572\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_val_0_auc = 0.78783\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.68182\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.72727\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 40 and best_val_0_auc = 0.81119\n",
      "   HOLDOUT: Accuracy=0.639, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.745 (95% CI: 0.686-0.804)\n",
      "   STABILITY: STABLE\n",
      "       GOOD performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.864\n",
      "   CROSS-VAL: AUC=0.843 (95% CI: 0.765-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.888 (95% CI: 0.825-0.952)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.738, AUC=0.842\n",
      "   CROSS-VAL: AUC=0.785 (95% CI: 0.719-0.851)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.864\n",
      "   CROSS-VAL: AUC=0.731 (95% CI: 0.617-0.845)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.864\n",
      "   CROSS-VAL: AUC=0.752 (95% CI: 0.623-0.882)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_auc = 0.9053\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.62286\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.86857\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_val_0_auc = 0.9\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.72941\n",
      "   HOLDOUT: Accuracy=0.900, AUC=0.905\n",
      "   CROSS-VAL: AUC=0.796 (95% CI: 0.666-0.925)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.867\n",
      "   CROSS-VAL: AUC=0.761 (95% CI: 0.654-0.868)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.800, AUC=0.807\n",
      "   CROSS-VAL: AUC=0.709 (95% CI: 0.544-0.874)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.833\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.598-0.743)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.726\n",
      "   CROSS-VAL: AUC=0.631 (95% CI: 0.526-0.735)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.623, AUC=0.716\n",
      "   CROSS-VAL: AUC=0.604 (95% CI: 0.515-0.693)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.64435\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.68778\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 39 and best_val_0_auc = 0.71041\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.63294\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.67059\n",
      "   HOLDOUT: Accuracy=0.415, AUC=0.644\n",
      "   CROSS-VAL: AUC=0.690 (95% CI: 0.642-0.739)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.732\n",
      "   CROSS-VAL: AUC=0.583 (95% CI: 0.499-0.668)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.547, AUC=0.629\n",
      "   CROSS-VAL: AUC=0.603 (95% CI: 0.519-0.687)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.547, AUC=0.589\n",
      "   CROSS-VAL: AUC=0.475 (95% CI: 0.397-0.553)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ConvNext: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ViT DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ViT\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/vit_base_data/vit_base_cleaned_master.csv\n",
      "Dataset shape: (510, 228)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 141\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.529\n",
      "   CROSS-VAL: AUC=0.632 (95% CI: 0.535-0.729)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.812\n",
      "   CROSS-VAL: AUC=0.789 (95% CI: 0.673-0.905)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.81176\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.88095\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_val_0_auc = 0.92308\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.71154\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.84615\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.812\n",
      "   CROSS-VAL: AUC=0.837 (95% CI: 0.748-0.925)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.800 (95% CI: 0.651-0.948)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.565\n",
      "   CROSS-VAL: AUC=0.560 (95% CI: 0.462-0.658)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.247\n",
      "   CROSS-VAL: AUC=0.366 (95% CI: 0.121-0.610)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.633\n",
      "   CROSS-VAL: AUC=0.779 (95% CI: 0.724-0.835)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.742\n",
      "   CROSS-VAL: AUC=0.776 (95% CI: 0.679-0.872)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.69167\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.7875\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61111\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.84722\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.64286\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.77143\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.692\n",
      "   CROSS-VAL: AUC=0.732 (95% CI: 0.620-0.844)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.750\n",
      "   CROSS-VAL: AUC=0.828 (95% CI: 0.743-0.912)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.650\n",
      "   CROSS-VAL: AUC=0.726 (95% CI: 0.598-0.855)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.675\n",
      "   CROSS-VAL: AUC=0.329 (95% CI: 0.032-0.626)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.806\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.399-0.801)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.847\n",
      "   CROSS-VAL: AUC=0.592 (95% CI: 0.383-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 40 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.66667\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_val_0_auc = 0.64286\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.944\n",
      "   CROSS-VAL: AUC=0.781 (95% CI: 0.637-0.925)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.847\n",
      "   CROSS-VAL: AUC=0.726 (95% CI: 0.444-1.000)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.569\n",
      "   CROSS-VAL: AUC=0.648 (95% CI: 0.442-0.854)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.250\n",
      "   CROSS-VAL: AUC=0.317 (95% CI: 0.006-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.874\n",
      "   CROSS-VAL: AUC=0.881 (95% CI: 0.819-0.944)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.868\n",
      "   CROSS-VAL: AUC=0.884 (95% CI: 0.820-0.948)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.8474\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.6689\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 65 and best_val_0_auc = 0.8487\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.86713\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 62 and best_val_0_auc = 0.87063\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_val_0_auc = 0.85315\n",
      "   HOLDOUT: Accuracy=0.639, AUC=0.847\n",
      "   CROSS-VAL: AUC=0.822 (95% CI: 0.726-0.917)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.834\n",
      "   CROSS-VAL: AUC=0.854 (95% CI: 0.797-0.911)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.902\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.782-0.939)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.738, AUC=0.826\n",
      "   CROSS-VAL: AUC=0.812 (95% CI: 0.726-0.897)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.840, AUC=0.867\n",
      "   CROSS-VAL: AUC=0.806 (95% CI: 0.688-0.924)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.826\n",
      "   CROSS-VAL: AUC=0.817 (95% CI: 0.712-0.922)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.74621\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.86286\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.77143\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.86857\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.65\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.66471\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.746\n",
      "   CROSS-VAL: AUC=0.764 (95% CI: 0.648-0.879)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.716\n",
      "   CROSS-VAL: AUC=0.713 (95% CI: 0.641-0.786)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.780, AUC=0.769\n",
      "   CROSS-VAL: AUC=0.685 (95% CI: 0.617-0.754)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.723\n",
      "   CROSS-VAL: AUC=0.663 (95% CI: 0.560-0.766)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.488\n",
      "   CROSS-VAL: AUC=0.459 (95% CI: 0.419-0.499)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.585, AUC=0.545\n",
      "   CROSS-VAL: AUC=0.420 (95% CI: 0.361-0.479)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.65476\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.70814\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.71267\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_val_0_auc = 0.67067\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.71294\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.64941\n",
      "   HOLDOUT: Accuracy=0.660, AUC=0.655\n",
      "   CROSS-VAL: AUC=0.691 (95% CI: 0.658-0.723)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       GOOD performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.623, AUC=0.637\n",
      "   CROSS-VAL: AUC=0.485 (95% CI: 0.405-0.565)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.472, AUC=0.504\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.441-0.533)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.491, AUC=0.472\n",
      "   CROSS-VAL: AUC=0.495 (95% CI: 0.438-0.551)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ViT: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ResNet50_Pretrained DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ResNet50_Pretrained\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/pretrained_resnet50_data/pretrained_resnet50_cleaned_master.csv\n",
      "Dataset shape: (510, 228)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 141\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.659\n",
      "   CROSS-VAL: AUC=0.595 (95% CI: 0.441-0.749)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.553\n",
      "   CROSS-VAL: AUC=0.547 (95% CI: 0.328-0.766)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.50588\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.61538\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.61538\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.506\n",
      "   CROSS-VAL: AUC=0.752 (95% CI: 0.591-0.914)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.635\n",
      "   CROSS-VAL: AUC=0.623 (95% CI: 0.418-0.828)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.400\n",
      "   CROSS-VAL: AUC=0.465 (95% CI: 0.396-0.535)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.235\n",
      "   CROSS-VAL: AUC=0.532 (95% CI: 0.261-0.804)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.775\n",
      "   CROSS-VAL: AUC=0.734 (95% CI: 0.582-0.886)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.455, AUC=0.558\n",
      "   CROSS-VAL: AUC=0.697 (95% CI: 0.572-0.821)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.8\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_auc = 0.8625\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.58333\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.91429\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.8\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.800\n",
      "   CROSS-VAL: AUC=0.807 (95% CI: 0.661-0.953)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.650\n",
      "   CROSS-VAL: AUC=0.738 (95% CI: 0.617-0.858)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.522 (95% CI: 0.400-0.643)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.783\n",
      "   CROSS-VAL: AUC=0.362 (95% CI: 0.093-0.631)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.611\n",
      "   CROSS-VAL: AUC=0.644 (95% CI: 0.539-0.749)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.570 (95% CI: 0.425-0.715)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 55 and best_val_0_auc = 0.79167\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.864, AUC=0.792\n",
      "   CROSS-VAL: AUC=0.811 (95% CI: 0.772-0.849)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.847\n",
      "   CROSS-VAL: AUC=0.605 (95% CI: 0.409-0.801)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.625\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.391-0.609)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.639\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.223-0.972)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.915\n",
      "   CROSS-VAL: AUC=0.892 (95% CI: 0.849-0.935)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.770, AUC=0.828\n",
      "   CROSS-VAL: AUC=0.858 (95% CI: 0.785-0.930)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 50 and best_val_0_auc = 0.84524\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_auc = 0.85117\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.81913\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_auc = 0.86014\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.76399\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_0_auc = 0.7535\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.845\n",
      "   CROSS-VAL: AUC=0.810 (95% CI: 0.755-0.864)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.835\n",
      "   CROSS-VAL: AUC=0.856 (95% CI: 0.799-0.912)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.906\n",
      "   CROSS-VAL: AUC=0.880 (95% CI: 0.812-0.949)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.879\n",
      "   CROSS-VAL: AUC=0.829 (95% CI: 0.767-0.892)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.900, AUC=0.833\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.724-0.782)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.818 (95% CI: 0.758-0.877)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.68182\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.70286\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.81143\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.82286\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_auc = 0.73571\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_val_0_auc = 0.77647\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.682\n",
      "   CROSS-VAL: AUC=0.770 (95% CI: 0.714-0.826)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.814\n",
      "   CROSS-VAL: AUC=0.820 (95% CI: 0.745-0.896)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.780, AUC=0.754\n",
      "   CROSS-VAL: AUC=0.674 (95% CI: 0.584-0.763)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.754\n",
      "   CROSS-VAL: AUC=0.721 (95% CI: 0.633-0.808)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.623, AUC=0.603\n",
      "   CROSS-VAL: AUC=0.604 (95% CI: 0.502-0.706)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.671\n",
      "   CROSS-VAL: AUC=0.578 (95% CI: 0.496-0.661)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.64435\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.75339\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.51357\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.71875\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.63294\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.64471\n",
      "   HOLDOUT: Accuracy=0.679, AUC=0.644\n",
      "   CROSS-VAL: AUC=0.653 (95% CI: 0.550-0.756)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.698\n",
      "   CROSS-VAL: AUC=0.603 (95% CI: 0.536-0.669)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.396, AUC=0.432\n",
      "   CROSS-VAL: AUC=0.517 (95% CI: 0.427-0.607)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.547, AUC=0.571\n",
      "   CROSS-VAL: AUC=0.517 (95% CI: 0.365-0.669)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ResNet50_Pretrained: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ResNet50_ImageNet DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ResNet50_ImageNet\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/imagenet_resnet50_data/imagenet_resnet50_cleaned_master.csv\n",
      "Dataset shape: (510, 228)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 141\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.659\n",
      "   CROSS-VAL: AUC=0.595 (95% CI: 0.441-0.749)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.553\n",
      "   CROSS-VAL: AUC=0.547 (95% CI: 0.328-0.766)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.50588\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.61538\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.61538\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.506\n",
      "   CROSS-VAL: AUC=0.752 (95% CI: 0.591-0.914)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.635\n",
      "   CROSS-VAL: AUC=0.623 (95% CI: 0.418-0.828)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.400\n",
      "   CROSS-VAL: AUC=0.465 (95% CI: 0.396-0.535)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.235\n",
      "   CROSS-VAL: AUC=0.532 (95% CI: 0.261-0.804)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.775\n",
      "   CROSS-VAL: AUC=0.734 (95% CI: 0.582-0.886)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.455, AUC=0.558\n",
      "   CROSS-VAL: AUC=0.697 (95% CI: 0.572-0.821)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.8\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_auc = 0.8625\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.58333\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.91429\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.8\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.800\n",
      "   CROSS-VAL: AUC=0.807 (95% CI: 0.661-0.953)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.650\n",
      "   CROSS-VAL: AUC=0.738 (95% CI: 0.617-0.858)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.522 (95% CI: 0.400-0.643)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.783\n",
      "   CROSS-VAL: AUC=0.362 (95% CI: 0.093-0.631)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.611\n",
      "   CROSS-VAL: AUC=0.644 (95% CI: 0.539-0.749)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.570 (95% CI: 0.425-0.715)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 55 and best_val_0_auc = 0.79167\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.864, AUC=0.792\n",
      "   CROSS-VAL: AUC=0.811 (95% CI: 0.772-0.849)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.847\n",
      "   CROSS-VAL: AUC=0.605 (95% CI: 0.409-0.801)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.625\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.391-0.609)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.639\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.223-0.972)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.915\n",
      "   CROSS-VAL: AUC=0.892 (95% CI: 0.849-0.935)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.770, AUC=0.828\n",
      "   CROSS-VAL: AUC=0.858 (95% CI: 0.785-0.930)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 50 and best_val_0_auc = 0.84524\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_val_0_auc = 0.85117\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.81913\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_auc = 0.86014\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.76399\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_0_auc = 0.7535\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.845\n",
      "   CROSS-VAL: AUC=0.810 (95% CI: 0.755-0.864)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.835\n",
      "   CROSS-VAL: AUC=0.856 (95% CI: 0.799-0.912)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.852, AUC=0.906\n",
      "   CROSS-VAL: AUC=0.880 (95% CI: 0.812-0.949)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.879\n",
      "   CROSS-VAL: AUC=0.829 (95% CI: 0.767-0.892)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.900, AUC=0.833\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.724-0.782)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.818 (95% CI: 0.758-0.877)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.68182\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.70286\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.81143\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.82286\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_auc = 0.73571\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_val_0_auc = 0.77647\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.682\n",
      "   CROSS-VAL: AUC=0.770 (95% CI: 0.714-0.826)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.814\n",
      "   CROSS-VAL: AUC=0.820 (95% CI: 0.745-0.896)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.780, AUC=0.754\n",
      "   CROSS-VAL: AUC=0.674 (95% CI: 0.584-0.763)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.754\n",
      "   CROSS-VAL: AUC=0.721 (95% CI: 0.633-0.808)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.623, AUC=0.603\n",
      "   CROSS-VAL: AUC=0.604 (95% CI: 0.502-0.706)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.671\n",
      "   CROSS-VAL: AUC=0.578 (95% CI: 0.496-0.661)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.64435\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.75339\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.51357\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.71875\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.63294\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.64471\n",
      "   HOLDOUT: Accuracy=0.679, AUC=0.644\n",
      "   CROSS-VAL: AUC=0.653 (95% CI: 0.550-0.756)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.698\n",
      "   CROSS-VAL: AUC=0.603 (95% CI: 0.536-0.669)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.396, AUC=0.432\n",
      "   CROSS-VAL: AUC=0.517 (95% CI: 0.427-0.607)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.547, AUC=0.571\n",
      "   CROSS-VAL: AUC=0.517 (95% CI: 0.365-0.669)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ResNet50_ImageNet: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING EfficientNet DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR EfficientNet\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/efficientnet_data/efficientnet_cleaned_master.csv\n",
      "Dataset shape: (510, 228)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 141\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.635\n",
      "   CROSS-VAL: AUC=0.660 (95% CI: 0.599-0.720)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.894\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.723-0.923)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.69412\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.61905\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82692\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.78846\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.76923\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.744 (95% CI: 0.654-0.833)\n",
      "   STABILITY: STABLE\n",
      "       GOOD performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.753\n",
      "   CROSS-VAL: AUC=0.771 (95% CI: 0.565-0.977)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.553\n",
      "   CROSS-VAL: AUC=0.571 (95% CI: 0.453-0.688)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.318\n",
      "   CROSS-VAL: AUC=0.521 (95% CI: 0.355-0.688)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.550\n",
      "   CROSS-VAL: AUC=0.679 (95% CI: 0.518-0.839)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.508\n",
      "   CROSS-VAL: AUC=0.742 (95% CI: 0.636-0.848)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.775\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.95\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.84286\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.775\n",
      "   CROSS-VAL: AUC=0.821 (95% CI: 0.702-0.940)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.650\n",
      "   CROSS-VAL: AUC=0.762 (95% CI: 0.606-0.918)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.614 (95% CI: 0.452-0.775)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.636, AUC=0.700\n",
      "   CROSS-VAL: AUC=0.430 (95% CI: 0.103-0.756)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.687 (95% CI: 0.344-1.000)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.410-0.726)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.76389\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.83333\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.764\n",
      "   CROSS-VAL: AUC=0.782 (95% CI: 0.701-0.864)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.806\n",
      "   CROSS-VAL: AUC=0.656 (95% CI: 0.498-0.814)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.750\n",
      "   CROSS-VAL: AUC=0.746 (95% CI: 0.532-0.961)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.319\n",
      "   CROSS-VAL: AUC=0.350 (95% CI: 0.029-0.671)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.878 (95% CI: 0.807-0.949)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.770, AUC=0.834\n",
      "   CROSS-VAL: AUC=0.847 (95% CI: 0.761-0.933)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.89935\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 89 and best_val_0_auc = 0.8612\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.75826\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_val_0_auc = 0.73951\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.66434\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.789 (95% CI: 0.676-0.901)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.721, AUC=0.835\n",
      "   CROSS-VAL: AUC=0.829 (95% CI: 0.744-0.915)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.904\n",
      "   CROSS-VAL: AUC=0.876 (95% CI: 0.799-0.952)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.721, AUC=0.806\n",
      "   CROSS-VAL: AUC=0.783 (95% CI: 0.696-0.871)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.860, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.768 (95% CI: 0.644-0.891)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.811\n",
      "   CROSS-VAL: AUC=0.746 (95% CI: 0.595-0.898)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.89773\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.89714\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70286\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.78857\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.85\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.92941\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.898\n",
      "   CROSS-VAL: AUC=0.834 (95% CI: 0.733-0.934)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.765 (95% CI: 0.571-0.959)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.780, AUC=0.610\n",
      "   CROSS-VAL: AUC=0.570 (95% CI: 0.371-0.769)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.840, AUC=0.784\n",
      "   CROSS-VAL: AUC=0.729 (95% CI: 0.586-0.872)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.491, AUC=0.561\n",
      "   CROSS-VAL: AUC=0.563 (95% CI: 0.512-0.613)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.585, AUC=0.510\n",
      "   CROSS-VAL: AUC=0.539 (95% CI: 0.476-0.602)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.55506\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.69005\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.59729\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.72837\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.71059\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.61882\n",
      "   HOLDOUT: Accuracy=0.491, AUC=0.555\n",
      "   CROSS-VAL: AUC=0.669 (95% CI: 0.605-0.733)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.623, AUC=0.612\n",
      "   CROSS-VAL: AUC=0.563 (95% CI: 0.541-0.584)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.472, AUC=0.488\n",
      "   CROSS-VAL: AUC=0.458 (95% CI: 0.407-0.508)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.491, AUC=0.565\n",
      "   CROSS-VAL: AUC=0.475 (95% CI: 0.366-0.584)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS EfficientNet: 6 tasks completed successfully\n",
      "\n",
      "================================================================================\n",
      "üìä COMPREHENSIVE ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "üéØ EXECUTIVE SUMMARY\n",
      "==================================================\n",
      " PERFORMANCE OVERVIEW:\n",
      "   Total algorithm-task combinations: 180\n",
      "   Mean AUC across all tests: 0.699\n",
      "   Best AUC achieved: 0.944\n",
      "   Excellent performance (AUC ‚â• 0.85): 26/180 (14.4%)\n",
      "   Good+ performance (AUC ‚â• 0.75): 79/180 (43.9%)\n",
      "   üöÄ CLINICAL DEPLOYMENT: 26 combinations ready for validation\n",
      "   üèÜ PUBLICATION READY: Exceptional results achieved\n",
      "\n",
      "üìã DETAILED RESULTS TABLE\n",
      "==================================================\n",
      "CNN                  Task                      Algorithm       AUC      Acc      Sens     Spec     Status         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ConvNext             6-Month Mortality         TabPFN          0.694    0.727    0.200    0.882    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         XGBoost         0.788    0.727    0.000    0.941    ‚úÖ STRONG       \n",
      "ConvNext             6-Month Mortality         TabNet          0.718    0.682    0.000    0.882    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         RandomForest    0.741    0.773    0.000    1.000    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         LogisticRegression 0.612    0.636    0.000    0.824    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             6-Month Mortality         SVM             0.224    0.773    0.200    0.941    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          TabPFN          0.742    0.682    0.700    0.667    üìà GOOD         \n",
      "ConvNext             1-Year Mortality          XGBoost         0.717    0.682    0.600    0.750    üìà GOOD         \n",
      "ConvNext             1-Year Mortality          TabNet          0.817    0.727    0.600    0.833    ‚úÖ STRONG       \n",
      "ConvNext             1-Year Mortality          RandomForest    0.667    0.682    0.500    0.833    üìà GOOD         \n",
      "ConvNext             1-Year Mortality          LogisticRegression 0.708    0.682    0.600    0.750    üìà GOOD         \n",
      "ConvNext             1-Year Mortality          SVM             0.717    0.591    0.500    0.667    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          TabPFN          0.486    0.818    1.000    0.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             2-Year Mortality          XGBoost         0.667    0.773    0.944    0.000    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          TabNet          0.875    0.864    1.000    0.250    üèÜ EXCELLENT    \n",
      "ConvNext             2-Year Mortality          RandomForest    0.681    0.818    1.000    0.000    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          LogisticRegression 0.653    0.636    0.722    0.250    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          SVM             0.444    0.727    0.889    0.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             High-Grade vs Low-Grade   TabPFN          0.891    0.836    0.848    0.821    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   XGBoost         0.889    0.820    0.879    0.750    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   TabNet          0.741    0.639    1.000    0.214    üìà GOOD         \n",
      "ConvNext             High-Grade vs Low-Grade   RandomForest    0.864    0.754    0.788    0.714    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   LogisticRegression 0.897    0.852    0.909    0.786    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   SVM             0.842    0.738    0.758    0.714    ‚úÖ STRONG       \n",
      "ConvNext             IDH Mutation Status       TabPFN          0.864    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       XGBoost         0.864    0.860    0.977    0.000    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       TabNet          0.905    0.900    1.000    0.167    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       RandomForest    0.867    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       LogisticRegression 0.807    0.800    0.818    0.667    ‚úÖ STRONG       \n",
      "ConvNext             IDH Mutation Status       SVM             0.833    0.880    0.977    0.167    ‚úÖ STRONG       \n",
      "ConvNext             MGMT Promoter Methylation TabPFN          0.726    0.642    0.429    0.781    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation XGBoost         0.716    0.623    0.381    0.781    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation TabNet          0.644    0.415    0.952    0.062    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             MGMT Promoter Methylation RandomForest    0.732    0.642    0.286    0.875    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation LogisticRegression 0.629    0.547    0.667    0.469    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             MGMT Promoter Methylation SVM             0.589    0.547    0.667    0.469    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  6-Month Mortality         TabPFN          0.529    0.682    0.000    0.882    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  6-Month Mortality         XGBoost         0.812    0.682    0.000    0.882    ‚úÖ STRONG       \n",
      "ViT                  6-Month Mortality         TabNet          0.812    0.818    0.200    1.000    ‚úÖ STRONG       \n",
      "ViT                  6-Month Mortality         RandomForest    0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "ViT                  6-Month Mortality         LogisticRegression 0.565    0.682    0.200    0.824    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  6-Month Mortality         SVM             0.247    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          TabPFN          0.633    0.500    0.500    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          XGBoost         0.742    0.727    0.700    0.750    üìà GOOD         \n",
      "ViT                  1-Year Mortality          TabNet          0.692    0.591    0.100    1.000    üìà GOOD         \n",
      "ViT                  1-Year Mortality          RandomForest    0.750    0.682    0.600    0.750    ‚úÖ STRONG       \n",
      "ViT                  1-Year Mortality          LogisticRegression 0.650    0.682    0.600    0.750    üìà GOOD         \n",
      "ViT                  1-Year Mortality          SVM             0.675    0.636    0.600    0.667    üìà GOOD         \n",
      "ViT                  2-Year Mortality          TabPFN          0.806    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "ViT                  2-Year Mortality          XGBoost         0.847    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "ViT                  2-Year Mortality          TabNet          0.944    0.818    0.944    0.250    üèÜ EXCELLENT    \n",
      "ViT                  2-Year Mortality          RandomForest    0.847    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "ViT                  2-Year Mortality          LogisticRegression 0.569    0.591    0.722    0.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  2-Year Mortality          SVM             0.250    0.818    0.889    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  High-Grade vs Low-Grade   TabPFN          0.874    0.820    0.909    0.714    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   XGBoost         0.868    0.787    0.909    0.643    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   TabNet          0.847    0.639    0.939    0.286    ‚úÖ STRONG       \n",
      "ViT                  High-Grade vs Low-Grade   RandomForest    0.834    0.787    0.879    0.679    ‚úÖ STRONG       \n",
      "ViT                  High-Grade vs Low-Grade   LogisticRegression 0.902    0.852    0.939    0.750    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   SVM             0.826    0.738    0.758    0.714    ‚úÖ STRONG       \n",
      "ViT                  IDH Mutation Status       TabPFN          0.867    0.840    0.932    0.167    üèÜ EXCELLENT    \n",
      "ViT                  IDH Mutation Status       XGBoost         0.826    0.880    0.977    0.167    ‚úÖ STRONG       \n",
      "ViT                  IDH Mutation Status       TabNet          0.746    0.880    1.000    0.000    üìà GOOD         \n",
      "ViT                  IDH Mutation Status       RandomForest    0.716    0.880    1.000    0.000    üìà GOOD         \n",
      "ViT                  IDH Mutation Status       LogisticRegression 0.769    0.780    0.818    0.500    ‚úÖ STRONG       \n",
      "ViT                  IDH Mutation Status       SVM             0.723    0.860    0.955    0.167    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation TabPFN          0.488    0.604    0.095    0.938    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation XGBoost         0.545    0.585    0.238    0.812    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation TabNet          0.655    0.660    0.143    1.000    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation RandomForest    0.637    0.623    0.190    0.906    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation LogisticRegression 0.504    0.472    0.381    0.531    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation SVM             0.472    0.491    0.857    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         TabPFN          0.659    0.773    0.200    0.941    üìà GOOD         \n",
      "ResNet50_Pretrained  6-Month Mortality         XGBoost         0.553    0.773    0.200    0.941    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         TabNet          0.506    0.818    0.200    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         RandomForest    0.635    0.818    0.200    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         LogisticRegression 0.400    0.636    0.000    0.824    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         SVM             0.235    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          TabPFN          0.775    0.682    0.900    0.500    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  1-Year Mortality          XGBoost         0.558    0.455    0.500    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          TabNet          0.800    0.682    0.400    0.917    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  1-Year Mortality          RandomForest    0.650    0.545    0.600    0.500    üìà GOOD         \n",
      "ResNet50_Pretrained  1-Year Mortality          LogisticRegression 0.542    0.591    0.500    0.667    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          SVM             0.783    0.727    0.400    1.000    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  2-Year Mortality          TabPFN          0.611    0.727    0.833    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  2-Year Mortality          XGBoost         0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          TabNet          0.792    0.864    0.944    0.500    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  2-Year Mortality          RandomForest    0.847    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  2-Year Mortality          LogisticRegression 0.625    0.682    0.722    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  2-Year Mortality          SVM             0.639    0.682    0.778    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   TabPFN          0.915    0.852    0.879    0.821    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   XGBoost         0.828    0.770    0.879    0.643    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   TabNet          0.845    0.754    0.848    0.643    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   RandomForest    0.835    0.787    0.848    0.714    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   LogisticRegression 0.906    0.852    0.909    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   SVM             0.879    0.787    0.788    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  IDH Mutation Status       TabPFN          0.833    0.900    0.977    0.333    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       XGBoost         0.830    0.860    0.977    0.000    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       TabNet          0.682    0.860    0.977    0.000    üìà GOOD         \n",
      "ResNet50_Pretrained  IDH Mutation Status       RandomForest    0.814    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       LogisticRegression 0.754    0.780    0.818    0.500    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       SVM             0.754    0.860    0.932    0.333    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation TabPFN          0.603    0.623    0.238    0.875    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation XGBoost         0.671    0.642    0.429    0.781    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation TabNet          0.644    0.679    0.286    0.938    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation RandomForest    0.698    0.604    0.190    0.875    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation LogisticRegression 0.432    0.396    0.333    0.438    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation SVM             0.571    0.547    0.571    0.531    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         TabPFN          0.659    0.773    0.200    0.941    üìà GOOD         \n",
      "ResNet50_ImageNet    6-Month Mortality         XGBoost         0.553    0.773    0.200    0.941    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         TabNet          0.506    0.818    0.200    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         RandomForest    0.635    0.818    0.200    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         LogisticRegression 0.400    0.636    0.000    0.824    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         SVM             0.235    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          TabPFN          0.775    0.682    0.900    0.500    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    1-Year Mortality          XGBoost         0.558    0.455    0.500    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          TabNet          0.800    0.682    0.400    0.917    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    1-Year Mortality          RandomForest    0.650    0.545    0.600    0.500    üìà GOOD         \n",
      "ResNet50_ImageNet    1-Year Mortality          LogisticRegression 0.542    0.591    0.500    0.667    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          SVM             0.783    0.727    0.400    1.000    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    2-Year Mortality          TabPFN          0.611    0.727    0.833    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    2-Year Mortality          XGBoost         0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          TabNet          0.792    0.864    0.944    0.500    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    2-Year Mortality          RandomForest    0.847    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    2-Year Mortality          LogisticRegression 0.625    0.682    0.722    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    2-Year Mortality          SVM             0.639    0.682    0.778    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   TabPFN          0.915    0.852    0.879    0.821    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   XGBoost         0.828    0.770    0.879    0.643    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   TabNet          0.845    0.754    0.848    0.643    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   RandomForest    0.835    0.787    0.848    0.714    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   LogisticRegression 0.906    0.852    0.909    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   SVM             0.879    0.787    0.788    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    IDH Mutation Status       TabPFN          0.833    0.900    0.977    0.333    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       XGBoost         0.830    0.860    0.977    0.000    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       TabNet          0.682    0.860    0.977    0.000    üìà GOOD         \n",
      "ResNet50_ImageNet    IDH Mutation Status       RandomForest    0.814    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       LogisticRegression 0.754    0.780    0.818    0.500    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       SVM             0.754    0.860    0.932    0.333    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation TabPFN          0.603    0.623    0.238    0.875    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation XGBoost         0.671    0.642    0.429    0.781    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation TabNet          0.644    0.679    0.286    0.938    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation RandomForest    0.698    0.604    0.190    0.875    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation LogisticRegression 0.432    0.396    0.333    0.438    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation SVM             0.571    0.547    0.571    0.531    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         6-Month Mortality         TabPFN          0.635    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         6-Month Mortality         XGBoost         0.894    0.773    0.000    1.000    üèÜ EXCELLENT    \n",
      "EfficientNet         6-Month Mortality         TabNet          0.694    0.818    0.200    1.000    üìà GOOD         \n",
      "EfficientNet         6-Month Mortality         RandomForest    0.753    0.818    0.200    1.000    ‚úÖ STRONG       \n",
      "EfficientNet         6-Month Mortality         LogisticRegression 0.553    0.636    0.400    0.706    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         6-Month Mortality         SVM             0.318    0.818    0.200    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          TabPFN          0.550    0.591    0.400    0.750    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          XGBoost         0.508    0.591    0.400    0.750    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          TabNet          0.775    0.636    0.200    1.000    ‚úÖ STRONG       \n",
      "EfficientNet         1-Year Mortality          RandomForest    0.650    0.636    0.400    0.833    üìà GOOD         \n",
      "EfficientNet         1-Year Mortality          LogisticRegression 0.500    0.636    0.400    0.833    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          SVM             0.700    0.636    0.200    1.000    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          TabPFN          0.708    0.773    0.889    0.250    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          XGBoost         0.736    0.818    1.000    0.000    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          TabNet          0.764    0.773    0.889    0.250    ‚úÖ STRONG       \n",
      "EfficientNet         2-Year Mortality          RandomForest    0.806    0.818    1.000    0.000    ‚úÖ STRONG       \n",
      "EfficientNet         2-Year Mortality          LogisticRegression 0.750    0.682    0.667    0.750    ‚úÖ STRONG       \n",
      "EfficientNet         2-Year Mortality          SVM             0.319    0.682    0.833    0.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         High-Grade vs Low-Grade   TabPFN          0.860    0.787    0.909    0.643    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   XGBoost         0.834    0.770    0.909    0.607    ‚úÖ STRONG       \n",
      "EfficientNet         High-Grade vs Low-Grade   TabNet          0.899    0.787    0.970    0.571    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   RandomForest    0.835    0.721    0.909    0.500    ‚úÖ STRONG       \n",
      "EfficientNet         High-Grade vs Low-Grade   LogisticRegression 0.904    0.820    0.909    0.714    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   SVM             0.806    0.721    0.879    0.536    ‚úÖ STRONG       \n",
      "EfficientNet         IDH Mutation Status       TabPFN          0.822    0.860    0.955    0.167    ‚úÖ STRONG       \n",
      "EfficientNet         IDH Mutation Status       XGBoost         0.811    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "EfficientNet         IDH Mutation Status       TabNet          0.898    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       RandomForest    0.860    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       LogisticRegression 0.610    0.780    0.841    0.333    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         IDH Mutation Status       SVM             0.784    0.840    0.932    0.167    ‚úÖ STRONG       \n",
      "EfficientNet         MGMT Promoter Methylation TabPFN          0.561    0.491    0.381    0.562    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation XGBoost         0.510    0.585    0.476    0.656    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation TabNet          0.555    0.491    0.810    0.281    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation RandomForest    0.612    0.623    0.333    0.812    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation LogisticRegression 0.488    0.472    0.571    0.406    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation SVM             0.565    0.491    0.524    0.469    ‚ö†Ô∏è MODERATE    \n",
      "\n",
      "üèÜ BEST PERFORMERS BY TASK\n",
      "==================================================\n",
      "6-Month Mortality             : EfficientNet + XGBoost (AUC = 0.894) üöÄ DEPLOYMENT READY\n",
      "1-Year Mortality              : ConvNext + TabNet (AUC = 0.817) üìà PROMISING\n",
      "2-Year Mortality              : ViT + TabNet (AUC = 0.944) üöÄ DEPLOYMENT READY\n",
      "High-Grade vs Low-Grade       : ResNet50_Pretrained + TabPFN (AUC = 0.915) üöÄ DEPLOYMENT READY\n",
      "IDH Mutation Status           : ConvNext + TabNet (AUC = 0.905) üöÄ DEPLOYMENT READY\n",
      "MGMT Promoter Methylation     : ConvNext + RandomForest (AUC = 0.732) ‚ö†Ô∏è NEEDS WORK\n",
      "\n",
      "VALIDATION SUMMARY\n",
      "==================================================\n",
      "CNN                  Overall    Data       Balance    Features   Samples   \n",
      "---------------------------------------------------------------------------\n",
      "ConvNext             PASS       PASS       PASS       PASS       PASS      \n",
      "ViT                  PASS       PASS       PASS       PASS       PASS      \n",
      "ResNet50_Pretrained  PASS       PASS       PASS       PASS       PASS      \n",
      "ResNet50_ImageNet    PASS       PASS       PASS       PASS       PASS      \n",
      "EfficientNet         PASS       PASS       PASS       PASS       PASS      \n",
      "\n",
      "CLINICAL RECOMMENDATIONS\n",
      "==================================================\n",
      "ALGORITHM PERFORMANCE RANKING:\n",
      "   TabNet: 0.751 mean AUC, 0.944 max AUC (30 tests)\n",
      "   RandomForest: 0.750 mean AUC, 0.867 max AUC (30 tests)\n",
      "   XGBoost: 0.730 mean AUC, 0.894 max AUC (30 tests)\n",
      "   TabPFN: 0.718 mean AUC, 0.915 max AUC (30 tests)\n",
      "   LogisticRegression: 0.646 mean AUC, 0.906 max AUC (30 tests)\n",
      "   SVM: 0.602 mean AUC, 0.879 max AUC (30 tests)\n",
      "\n",
      "CNN ARCHITECTURE RANKING:\n",
      "   ConvNext: 0.729 mean AUC, 0.905 max AUC (36 tests)\n",
      "   ViT: 0.699 mean AUC, 0.944 max AUC (36 tests)\n",
      "   EfficientNet: 0.690 mean AUC, 0.904 max AUC (36 tests)\n",
      "   ResNet50_Pretrained: 0.690 mean AUC, 0.915 max AUC (36 tests)\n",
      "   ResNet50_ImageNet: 0.690 mean AUC, 0.915 max AUC (36 tests)\n",
      "\n",
      "IMPLEMENTATION RECOMMENDATIONS:\n",
      "   61 CNN-algorithm combinations ready for clinical validation\n",
      "   Priority implementation: 2-Year Mortality using ViT + TabNet\n",
      "   Expected performance: 94.4% discrimination accuracy\n",
      "\n",
      "PUBLICATION STRATEGY\n",
      "==================================================\n",
      "\n",
      "Publication document generated successfully!\n",
      "Filename: neurosurgical_ai_analysis_report_20250724_124403.txt\n",
      "Lines written: 421\n",
      "File size: 29253 characters\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "ANALYSIS SUMMARY:\n",
      "   ‚Ä¢ 5 CNN architectures analyzed\n",
      "   ‚Ä¢ 30 clinical tasks evaluated\n",
      "   ‚Ä¢ 180 algorithm-task combinations tested\n",
      "   ‚Ä¢ Comprehensive validation and recommendations generated\n",
      "   ‚Ä¢ Publication-ready document created\n"
     ]
    }
   ],
   "source": [
    "def _generate_executive_summary(self):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        print(\"\\nEXECUTIVE SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        \n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            print(f\"PERFORMANCE OVERVIEW:\")\n",
    "            print(f\"   Total algorithm-task combinations: {total_tests}\")\n",
    "            print(f\"   Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            print(f\"   Best AUC achieved: {max_auc:.3f}\")\n",
    "            print(f\"   Excellent performance (AUC >= 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            print(f\"   Good+ performance (AUC >= 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            \n",
    "            # Clinical readiness assessment\n",
    "            if excellent_tests > 0:\n",
    "                print(f\"   CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                print(f\"   PUBLICATION READY: Exceptional results achieved\")\n",
    "            elif max_auc >= 0.80:\n",
    "                print(f\"   PUBLICATION READY: Strong results achieved\")\n",
    "\n",
    "def _generate_detailed_results_table(self):\n",
    "        \"\"\"Generate detailed results table\"\"\"\n",
    "        print(f\"\\nDETAILED RESULTS TABLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Header\n",
    "        print(f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Acc':<8} {'Sens':<8} {'Spec':<8} {'Status':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"GOOD\"\n",
    "                    else:\n",
    "                        status = \"MODERATE\"\n",
    "                    \n",
    "                    print(f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<8.3f} {sens:<8.3f} {spec:<8.3f} {status:<15}\")\n",
    "\n",
    "def _generate_best_performers_analysis(self):\n",
    "        \"\"\"Generate best performers analysis\"\"\"\n",
    "        print(f\"\\nBEST PERFORMERS BY TASK\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Find best performer for each task across all CNNs\n",
    "        task_best = {}\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            status = \"DEPLOYMENT READY\" if auc >= 0.85 else \"PROMISING\" if auc >= 0.75 else \"NEEDS WORK\"\n",
    "            print(f\"{task_name:<30}: {best['cnn']} + {best['algorithm']} (AUC = {auc:.3f}) {status}\")\n",
    "\n",
    "def _generate_validation_summary(self):\n",
    "        \"\"\"Generate validation summary\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                           accuracy_score, roc_curve, precision_recall_curve, auc)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for optional dependencies\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import torch\n",
    "    TABNET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è TabNet not available. Install with: pip install pytorch-tabnet torch\")\n",
    "\n",
    "class NeurosurgicalAIAnalyzer:\n",
    "    \"\"\"Comprehensive AI analysis system for neurosurgical outcome prediction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Updated paths to match your actual file names\n",
    "        self.datasets = {\n",
    "            'ConvNext': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv',\n",
    "            'ViT': '/Users/joi263/Documents/MultimodalTabData/data/vit_base_data/vit_base_cleaned_master.csv',\n",
    "            'ResNet50_Pretrained': '/Users/joi263/Documents/MultimodalTabData/data/pretrained_resnet50_data/pretrained_resnet50_cleaned_master.csv',\n",
    "            'ResNet50_ImageNet': '/Users/joi263/Documents/MultimodalTabData/data/imagenet_resnet50_data/imagenet_resnet50_cleaned_master.csv',\n",
    "            'EfficientNet': '/Users/joi263/Documents/MultimodalTabData/data/efficientnet_data/efficientnet_cleaned_master.csv'\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.validation_results = {}\n",
    "        \n",
    "        # Print file paths for verification\n",
    "        print(\"CHECKING DATA FILE PATHS:\")\n",
    "        print(\"=\"*50)\n",
    "        import os\n",
    "        for cnn_name, file_path in self.datasets.items():\n",
    "            exists = os.path.exists(file_path)\n",
    "            status = \"EXISTS\" if exists else \"NOT FOUND\"\n",
    "            print(f\"{cnn_name:<20}: {status}\")\n",
    "            if not exists:\n",
    "                print(f\"  Expected: {file_path}\")\n",
    "        print(\"=\"*50)\n",
    "        print()\n",
    "        \n",
    "        # Count how many files exist\n",
    "        existing_files = sum(1 for path in self.datasets.values() if os.path.exists(path))\n",
    "        print(f\"Found {existing_files}/{len(self.datasets)} data files\")\n",
    "        \n",
    "        if existing_files == 0:\n",
    "            print(\"ERROR: No data files found!\")\n",
    "            print(\"Please verify the file paths match your actual file locations.\")\n",
    "        elif existing_files < len(self.datasets):\n",
    "            print(f\"WARNING: Only {existing_files} out of {len(self.datasets)} files found.\")\n",
    "            print(\"Analysis will proceed with available datasets.\")\n",
    "        else:\n",
    "            print(\"SUCCESS: All data files found!\")\n",
    "        print()\n",
    "        \n",
    "    def get_ml_algorithms(self):\n",
    "        \"\"\"Initialize all available ML algorithms with optimized parameters\"\"\"\n",
    "        algorithms = {}\n",
    "        \n",
    "        # 1. TabPFN (always available) - Optimized for small biomedical datasets\n",
    "        algorithms['TabPFN'] = {\n",
    "            'model': TabPFNClassifier(device='cpu'),  # Only use valid parameters\n",
    "            'needs_scaling': False,\n",
    "            'description': 'Transformer-based Few-Shot Learning'\n",
    "        }\n",
    "        \n",
    "        # 2. XGBoost (if available) - Tuned for biomedical data\n",
    "        if XGBOOST_AVAILABLE:\n",
    "            algorithms['XGBoost'] = {\n",
    "                'model': xgb.XGBClassifier(\n",
    "                    n_estimators=300,  # Increased for better performance\n",
    "                    max_depth=4,       # Reduced to prevent overfitting on small datasets\n",
    "                    learning_rate=0.05, # Lower for better generalization\n",
    "                    subsample=0.8,     # Add regularization\n",
    "                    colsample_bytree=0.8,\n",
    "                    min_child_weight=3, # Prevent overfitting\n",
    "                    reg_alpha=1,       # L1 regularization\n",
    "                    reg_lambda=1,      # L2 regularization\n",
    "                    random_state=42,\n",
    "                    eval_metric='logloss',\n",
    "                    use_label_encoder=False  # Suppress warnings\n",
    "                ),\n",
    "                'needs_scaling': False,\n",
    "                'description': 'Optimized Gradient Boosting'\n",
    "            }\n",
    "        \n",
    "        # 3. TabNet (if available) - Tuned for tabular biomedical data\n",
    "        if TABNET_AVAILABLE:\n",
    "            algorithms['TabNet'] = {\n",
    "                'model': TabNetClassifier(\n",
    "                    n_d=64, n_a=64,    # Increased capacity\n",
    "                    n_steps=5,         # More decision steps\n",
    "                    gamma=1.5,         # Stronger feature selection\n",
    "                    lambda_sparse=1e-4, # Lighter sparsity penalty\n",
    "                    optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=0.01, weight_decay=1e-5),\n",
    "                    mask_type=\"entmax\",\n",
    "                    scheduler_params={\"step_size\": 20, \"gamma\": 0.8},\n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    verbose=0,\n",
    "                    seed=42\n",
    "                ),\n",
    "                'needs_scaling': True,  # TabNet benefits from scaling\n",
    "                'description': 'Optimized Attention-based Neural Network'\n",
    "            }\n",
    "        \n",
    "        # 4. Random Forest (always available) - Tuned for biomedical features\n",
    "        algorithms['RandomForest'] = {\n",
    "            'model': RandomForestClassifier(\n",
    "                n_estimators=500,   # Increased for stability\n",
    "                max_depth=8,        # Moderate depth to prevent overfitting\n",
    "                min_samples_split=10, # Higher to prevent overfitting\n",
    "                min_samples_leaf=5,   # Higher to ensure leaf reliability\n",
    "                max_features='sqrt',  # Good default for classification\n",
    "                bootstrap=True,\n",
    "                oob_score=True,     # Out-of-bag validation\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1           # Use all cores\n",
    "            ),\n",
    "            'needs_scaling': False,\n",
    "            'description': 'Optimized Ensemble Decision Trees'\n",
    "        }\n",
    "        \n",
    "        # 5. Logistic Regression (always available) - Tuned with regularization\n",
    "        algorithms['LogisticRegression'] = {\n",
    "            'model': LogisticRegression(\n",
    "                penalty='elasticnet',  # Combines L1 and L2 regularization\n",
    "                l1_ratio=0.5,         # Balance between L1 and L2\n",
    "                C=0.1,                # Strong regularization for small datasets\n",
    "                solver='saga',        # Supports elasticnet\n",
    "                max_iter=2000,        # More iterations for convergence\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'needs_scaling': True,  # CRITICAL for logistic regression\n",
    "            'description': 'Regularized Linear Model with ElasticNet'\n",
    "        }\n",
    "        \n",
    "        # 6. Support Vector Machine - Added as bonus strong performer\n",
    "        algorithms['SVM'] = {\n",
    "            'model': SVC(\n",
    "                kernel='rbf',\n",
    "                C=1.0,                # Balanced regularization\n",
    "                gamma='scale',        # Adaptive gamma\n",
    "                probability=True,     # Enable probability estimates\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            'needs_scaling': True,    # CRITICAL for SVM\n",
    "            'description': 'Support Vector Machine with RBF Kernel'\n",
    "        }\n",
    "        \n",
    "        return algorithms\n",
    "\n",
    "    def create_all_targets(self, df):\n",
    "        \"\"\"Create all prediction targets: mortality, tumor classification, IDH, MGMT\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"CREATING ALL PREDICTION TARGETS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        targets_data = {}\n",
    "        \n",
    "        # ============================================================\n",
    "        # MORTALITY TARGETS\n",
    "        # ============================================================\n",
    "        print(\"MORTALITY TARGETS:\")\n",
    "        survival_data = df[df['survival'].notna() & df['patient_status'].notna()].copy()\n",
    "        \n",
    "        if len(survival_data) > 0:\n",
    "            survival_data['mortality_6mo'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 6)).astype(int)\n",
    "            survival_data['mortality_1yr'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 12)).astype(int)\n",
    "            survival_data['mortality_2yr'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 24)).astype(int)\n",
    "            \n",
    "            targets_data['mortality'] = {\n",
    "                'data': survival_data,\n",
    "                'targets': ['mortality_6mo', 'mortality_1yr', 'mortality_2yr'],\n",
    "                'descriptions': ['6-Month Mortality', '1-Year Mortality', '2-Year Mortality']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(survival_data)}\")\n",
    "            print(f\"   6-month: {survival_data['mortality_6mo'].sum()}/{len(survival_data)} ({survival_data['mortality_6mo'].mean()*100:.1f}%)\")\n",
    "            print(f\"   1-year: {survival_data['mortality_1yr'].sum()}/{len(survival_data)} ({survival_data['mortality_1yr'].mean()*100:.1f}%)\")\n",
    "            print(f\"   2-year: {survival_data['mortality_2yr'].sum()}/{len(survival_data)} ({survival_data['mortality_2yr'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # TUMOR CLASSIFICATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nTUMOR CLASSIFICATION TARGETS:\")\n",
    "        tumor_data = df[df['methylation_class'].notna()].copy()\n",
    "        \n",
    "        if len(tumor_data) > 0:\n",
    "            # Binary high-grade vs low-grade\n",
    "            high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "            tumor_data['high_grade'] = tumor_data['methylation_class'].str.lower().str.contains(\n",
    "                '|'.join(high_grade_terms), na=False\n",
    "            ).astype(int)\n",
    "            \n",
    "            targets_data['tumor'] = {\n",
    "                'data': tumor_data,\n",
    "                'targets': ['high_grade'],\n",
    "                'descriptions': ['High-Grade vs Low-Grade']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(tumor_data)}\")\n",
    "            print(f\"   High-grade: {tumor_data['high_grade'].sum()}/{len(tumor_data)} ({tumor_data['high_grade'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # IDH MUTATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nIDH MUTATION TARGETS:\")\n",
    "        idh_data = self._create_idh_targets(df)\n",
    "        \n",
    "        if idh_data is not None and len(idh_data) > 0:\n",
    "            targets_data['idh'] = {\n",
    "                'data': idh_data,\n",
    "                'targets': ['idh_binary'],\n",
    "                'descriptions': ['IDH Mutation Status']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(idh_data)}\")\n",
    "            print(f\"   IDH Mutant: {idh_data['idh_binary'].sum()}/{len(idh_data)} ({idh_data['idh_binary'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # MGMT METHYLATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nMGMT METHYLATION TARGETS:\")\n",
    "        mgmt_data = self._create_mgmt_targets(df)\n",
    "        \n",
    "        if mgmt_data is not None and len(mgmt_data) > 0:\n",
    "            targets_data['mgmt'] = {\n",
    "                'data': mgmt_data,\n",
    "                'targets': ['mgmt_binary'],\n",
    "                'descriptions': ['MGMT Promoter Methylation']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(mgmt_data)}\")\n",
    "            print(f\"   MGMT Methylated: {mgmt_data['mgmt_binary'].sum()}/{len(mgmt_data)} ({mgmt_data['mgmt_binary'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        return targets_data\n",
    "\n",
    "    def _create_idh_targets(self, df):\n",
    "        \"\"\"Create IDH mutation targets with proper decoding\"\"\"\n",
    "        if 'idh_1_r132h' not in df.columns:\n",
    "            return None\n",
    "            \n",
    "        idh_data = df.copy()\n",
    "        idh_data['idh_binary'] = np.nan\n",
    "        \n",
    "        # Cross-reference with text data if available\n",
    "        if 'idh1' in df.columns:\n",
    "            text_idh = df['idh1'].astype(str).str.lower()\n",
    "            mutant_patterns = ['r132h', 'r132s', 'arg132his', 'arg132ser', 'missense', 'p.arg132']\n",
    "            is_mutant_text = text_idh.str.contains('|'.join(mutant_patterns), na=False)\n",
    "            idh_data.loc[is_mutant_text, 'idh_binary'] = 1  # Mutant\n",
    "        \n",
    "        # Apply numerical encoding (2 = mutant based on cross-reference analysis)\n",
    "        remaining_mask = idh_data['idh_binary'].isna() & idh_data['idh_1_r132h'].notna()\n",
    "        idh_data.loc[remaining_mask & (idh_data['idh_1_r132h'] == 2), 'idh_binary'] = 1  # Mutant\n",
    "        idh_data.loc[remaining_mask & (idh_data['idh_1_r132h'] == 1), 'idh_binary'] = 0  # Wildtype\n",
    "        \n",
    "        # Exclude unknown cases\n",
    "        idh_data.loc[idh_data['idh_1_r132h'] == 3, 'idh_binary'] = np.nan\n",
    "        \n",
    "        return idh_data[idh_data['idh_binary'].notna()].copy()\n",
    "\n",
    "    def _create_mgmt_targets(self, df):\n",
    "        \"\"\"Create MGMT methylation targets with correct encoding\"\"\"\n",
    "        if 'mgmt' not in df.columns:\n",
    "            return None\n",
    "            \n",
    "        mgmt_data = df[df['mgmt'].notna()].copy()\n",
    "        \n",
    "        if len(mgmt_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Correct encoding based on data dictionary:\n",
    "        # 1 = Positive (methylated), 2 = Negative (unmethylated), 3 = Non-informative\n",
    "        mgmt_data['mgmt_binary'] = np.nan\n",
    "        \n",
    "        # Set methylated cases (value = 1)\n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 1, 'mgmt_binary'] = 1  # Methylated\n",
    "        \n",
    "        # Set unmethylated cases (value = 2) \n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 2, 'mgmt_binary'] = 0  # Unmethylated\n",
    "        \n",
    "        # Exclude non-informative cases (value = 3)\n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 3, 'mgmt_binary'] = np.nan\n",
    "        \n",
    "        # Return only cases with definitive results\n",
    "        return mgmt_data[mgmt_data['mgmt_binary'].notna()].copy()\n",
    "\n",
    "    def select_features(self, df):\n",
    "        \"\"\"Select comprehensive feature set\"\"\"\n",
    "        # Clinical features\n",
    "        clinical_features = ['age', 'sex', 'race', 'ethnicity', 'gtr']\n",
    "        \n",
    "        # Molecular features (exclude target variables to prevent leakage)\n",
    "        molecular_features = ['mgmt_pyro', 'atrx', 'p53', 'braf_v600', 'h3k27m', 'gfap', 'tumor', 'hg_glioma']\n",
    "        \n",
    "        # CNN-extracted imaging features\n",
    "        image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "        \n",
    "        # Combine all features\n",
    "        all_features = clinical_features + molecular_features + image_features\n",
    "        available_features = [f for f in all_features if f in df.columns]\n",
    "        \n",
    "        return available_features\n",
    "\n",
    "    def preprocess_data(self, df, features, target_col):\n",
    "        \"\"\"Advanced preprocessing for multiple ML algorithms\"\"\"\n",
    "        data = df[features + [target_col]].copy()\n",
    "        data = data[data[target_col].notna()]\n",
    "        \n",
    "        if len(data) < 15:  # Minimum viable sample size\n",
    "            return None, None, f\"Insufficient data: {len(data)} samples\"\n",
    "        \n",
    "        # Handle categorical features\n",
    "        categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "        if target_col in categorical_features:\n",
    "            categorical_features.remove(target_col)\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in features:\n",
    "                le = LabelEncoder()\n",
    "                data[col] = data[col].astype(str)\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "        \n",
    "        # Handle missing values\n",
    "        numerical_features = [f for f in features if f in data.select_dtypes(include=[np.number]).columns]\n",
    "        \n",
    "        for col in numerical_features:\n",
    "            if data[col].isnull().sum() > 0:\n",
    "                if col.startswith('feature_'):\n",
    "                    data[col] = data[col].fillna(data[col].mean())\n",
    "                else:\n",
    "                    data[col] = data[col].fillna(data[col].median())\n",
    "        \n",
    "        # Remove features with >50% missing\n",
    "        missing_pct = data[features].isnull().mean()\n",
    "        good_features = missing_pct[missing_pct <= 0.5].index.tolist()\n",
    "        \n",
    "        if len(good_features) < len(features):\n",
    "            features = good_features\n",
    "            data = data[features + [target_col]]\n",
    "        \n",
    "        # Feature selection for computational efficiency\n",
    "        X = data[features].values\n",
    "        y = data[target_col].values\n",
    "        \n",
    "        # Check class balance\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        min_class_size = min(class_counts)\n",
    "        \n",
    "        if min_class_size < 3:\n",
    "            return None, None, f\"Class too small: minimum class has {min_class_size} samples\"\n",
    "        \n",
    "        # Feature selection (limit to 100 for computational efficiency)\n",
    "        if X.shape[1] > 100:\n",
    "            selector = SelectKBest(score_func=f_classif, k=100)\n",
    "            X = selector.fit_transform(X, y)\n",
    "        \n",
    "        return X, y, None\n",
    "\n",
    "    def train_and_evaluate_algorithm(self, X_train, X_test, y_train, y_test, algorithm_name, algorithm_config):\n",
    "        \"\"\"Train and evaluate a single algorithm with optimized preprocessing\"\"\"\n",
    "        try:\n",
    "            model = algorithm_config['model']\n",
    "            needs_scaling = algorithm_config['needs_scaling']\n",
    "            \n",
    "            # Apply robust scaling if needed\n",
    "            if needs_scaling:\n",
    "                # Use RobustScaler for biomedical data (handles outliers better than StandardScaler)\n",
    "                from sklearn.preprocessing import RobustScaler\n",
    "                scaler = RobustScaler(quantile_range=(10.0, 90.0))  # Less sensitive to outliers\n",
    "                X_train_processed = scaler.fit_transform(X_train)\n",
    "                X_test_processed = scaler.transform(X_test)\n",
    "                \n",
    "                # Handle potential scaling issues\n",
    "                if np.any(np.isnan(X_train_processed)) or np.any(np.isnan(X_test_processed)):\n",
    "                    # Fallback to StandardScaler if RobustScaler fails\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_processed = scaler.fit_transform(X_train)\n",
    "                    X_test_processed = scaler.transform(X_test)\n",
    "            else:\n",
    "                X_train_processed = X_train\n",
    "                X_test_processed = X_test\n",
    "            \n",
    "            # Special handling for different algorithms\n",
    "            if algorithm_name == 'TabNet' and TABNET_AVAILABLE:\n",
    "                # TabNet needs special training procedure\n",
    "                model.fit(\n",
    "                    X_train_processed, y_train,\n",
    "                    eval_set=[(X_test_processed, y_test)],\n",
    "                    patience=20,        # Increased patience for better convergence\n",
    "                    max_epochs=100,     # More epochs for biomedical data\n",
    "                    eval_metric=['auc'],\n",
    "                    batch_size=min(256, len(X_train)//4)  # Adaptive batch size\n",
    "                )\n",
    "                y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "                \n",
    "            elif algorithm_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "                # XGBoost with standard training (early stopping varies by version)\n",
    "                try:\n",
    "                    # Try with early stopping if supported\n",
    "                    eval_set = [(X_test_processed, y_test)]\n",
    "                    model.fit(\n",
    "                        X_train_processed, y_train,\n",
    "                        eval_set=eval_set,\n",
    "                        verbose=False\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    # Fallback to standard training if early stopping not supported\n",
    "                    model.fit(X_train_processed, y_train)\n",
    "                \n",
    "                y_pred = model.predict(X_test_processed)\n",
    "                y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                \n",
    "            else:\n",
    "                # Standard scikit-learn interface\n",
    "                model.fit(X_train_processed, y_train)\n",
    "                y_pred = model.predict(X_test_processed)\n",
    "                \n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                else:\n",
    "                    y_pred_proba = y_pred.astype(float)\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Robust AUC calculation\n",
    "            try:\n",
    "                auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            except ValueError:\n",
    "                # Handle edge cases (e.g., all one class in test set)\n",
    "                auc = 0.5\n",
    "            \n",
    "            # Confusion matrix and clinical metrics\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Clinical metrics for binary classification\n",
    "            if cm.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "            else:\n",
    "                sensitivity = specificity = ppv = npv = 0\n",
    "            \n",
    "            # Additional metrics for model comparison\n",
    "            balanced_accuracy = (sensitivity + specificity) / 2\n",
    "            f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'balanced_accuracy': balanced_accuracy,\n",
    "                'auc': auc,\n",
    "                'sensitivity': sensitivity,\n",
    "                'specificity': specificity,\n",
    "                'ppv': ppv,\n",
    "                'npv': npv,\n",
    "                'f1_score': f1_score,\n",
    "                'confusion_matrix': cm,\n",
    "                'n_test': len(y_test),\n",
    "                'scaling_used': needs_scaling\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {algorithm_name} failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def run_prediction_task(self, X, y, task_name, cnn_name, algorithms):\n",
    "        \"\"\"Run prediction task with cross-validation and single holdout validation\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{task_name} - {cnn_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Single holdout split for detailed analysis\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.25, random_state=42, stratify=y\n",
    "            )\n",
    "        except:\n",
    "            # If stratification fails, try without it\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.25, random_state=42\n",
    "            )\n",
    "        \n",
    "        print(f\"DATA SPLIT:\")\n",
    "        print(f\"   Training: {len(X_train)} samples\")\n",
    "        print(f\"   Testing: {len(X_test)} samples\")\n",
    "        print(f\"   Positive rate: {y_train.mean()*100:.1f}% (train), {y_test.mean()*100:.1f}% (test)\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Test each algorithm with both holdout and cross-validation\n",
    "        for alg_name, alg_config in algorithms.items():\n",
    "            print(f\"\\nTESTING {alg_name}...\")\n",
    "            \n",
    "            # Single holdout result (for detailed metrics)\n",
    "            holdout_result = self.train_and_evaluate_algorithm(X_train, X_test, y_train, y_test, alg_name, alg_config)\n",
    "            \n",
    "            if holdout_result is None:\n",
    "                print(f\"   ERROR {alg_name}: FAILED\")\n",
    "                continue\n",
    "            \n",
    "            # Cross-validation for robustness\n",
    "            cv_result = self.cross_validate_algorithm(X, y, alg_name, alg_config)\n",
    "            \n",
    "            if cv_result is None:\n",
    "                print(f\"   WARNING {alg_name}: Cross-validation failed, using holdout only\")\n",
    "                cv_result = {\n",
    "                    'cv_auc_mean': holdout_result['auc'],\n",
    "                    'cv_auc_std': 0.0,\n",
    "                    'cv_auc_ci_lower': holdout_result['auc'],\n",
    "                    'cv_auc_ci_upper': holdout_result['auc'],\n",
    "                    'cv_accuracy_mean': holdout_result['accuracy'],\n",
    "                    'cv_accuracy_std': 0.0,\n",
    "                    'cv_folds': 1,\n",
    "                    'cv_stability': 'SINGLE_SPLIT'\n",
    "                }\n",
    "            \n",
    "            # Combine holdout and CV results\n",
    "            combined_result = {**holdout_result, **cv_result}\n",
    "            results[alg_name] = combined_result\n",
    "            \n",
    "            # Enhanced reporting with confidence intervals\n",
    "            auc_mean = cv_result['cv_auc_mean']\n",
    "            auc_std = cv_result['cv_auc_std']\n",
    "            auc_ci_lower = cv_result['cv_auc_ci_lower']\n",
    "            auc_ci_upper = cv_result['cv_auc_ci_upper']\n",
    "            stability = cv_result['cv_stability']\n",
    "            \n",
    "            print(f\"   HOLDOUT: Accuracy={holdout_result['accuracy']:.3f}, AUC={holdout_result['auc']:.3f}\")\n",
    "            print(f\"   CROSS-VAL: AUC={auc_mean:.3f} (95% CI: {auc_ci_lower:.3f}-{auc_ci_upper:.3f})\")\n",
    "            print(f\"   STABILITY: {stability}\")\n",
    "            \n",
    "            # Clinical interpretation with confidence intervals\n",
    "            if auc_ci_lower >= 0.85:\n",
    "                print(f\"       EXCELLENT clinical performance (robust across CV)\")\n",
    "            elif auc_mean >= 0.85 and auc_ci_lower >= 0.75:\n",
    "                print(f\"       EXCELLENT clinical performance (some variability)\")\n",
    "            elif auc_ci_lower >= 0.75:\n",
    "                print(f\"       STRONG clinical performance (robust across CV)\")\n",
    "            elif auc_mean >= 0.75 and auc_ci_lower >= 0.65:\n",
    "                print(f\"       STRONG clinical performance (some variability)\")\n",
    "            elif auc_ci_lower >= 0.65:\n",
    "                print(f\"       GOOD performance (robust across CV)\")\n",
    "            else:\n",
    "                print(f\"       MODERATE performance (consider more data/optimization)\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def cross_validate_algorithm(self, X, y, algorithm_name, algorithm_config, cv_folds=5):\n",
    "        \"\"\"Perform stratified cross-validation with confidence intervals\"\"\"\n",
    "        try:\n",
    "            # Create stratified k-fold\n",
    "            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "            \n",
    "            # Storage for CV results\n",
    "            cv_aucs = []\n",
    "            cv_accuracies = []\n",
    "            cv_sensitivities = []\n",
    "            cv_specificities = []\n",
    "            \n",
    "            fold_num = 0\n",
    "            for train_idx, val_idx in cv.split(X, y):\n",
    "                fold_num += 1\n",
    "                X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "                y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "                \n",
    "                # Train and evaluate on this fold\n",
    "                fold_result = self.train_and_evaluate_algorithm(\n",
    "                    X_train_cv, X_val_cv, y_train_cv, y_val_cv, \n",
    "                    algorithm_name, algorithm_config\n",
    "                )\n",
    "                \n",
    "                if fold_result is not None:\n",
    "                    cv_aucs.append(fold_result['auc'])\n",
    "                    cv_accuracies.append(fold_result['accuracy'])\n",
    "                    cv_sensitivities.append(fold_result['sensitivity'])\n",
    "                    cv_specificities.append(fold_result['specificity'])\n",
    "                else:\n",
    "                    # If a fold fails, record it but continue\n",
    "                    cv_aucs.append(0.5)  # Random performance\n",
    "                    cv_accuracies.append(0.5)\n",
    "                    cv_sensitivities.append(0.5)\n",
    "                    cv_specificities.append(0.5)\n",
    "            \n",
    "            # Calculate CV statistics\n",
    "            cv_aucs = np.array(cv_aucs)\n",
    "            cv_accuracies = np.array(cv_accuracies)\n",
    "            \n",
    "            # Mean and standard deviation\n",
    "            auc_mean = np.mean(cv_aucs)\n",
    "            auc_std = np.std(cv_aucs)\n",
    "            acc_mean = np.mean(cv_accuracies)\n",
    "            acc_std = np.std(cv_accuracies)\n",
    "            \n",
    "            # 95% Confidence intervals (using t-distribution for small samples)\n",
    "            from scipy import stats\n",
    "            t_critical = stats.t.ppf(0.975, df=len(cv_aucs)-1)  # 95% CI\n",
    "            auc_margin = t_critical * (auc_std / np.sqrt(len(cv_aucs)))\n",
    "            \n",
    "            auc_ci_lower = max(0.0, auc_mean - auc_margin)\n",
    "            auc_ci_upper = min(1.0, auc_mean + auc_margin)\n",
    "            \n",
    "            # Stability assessment\n",
    "            cv_of_variation = auc_std / auc_mean if auc_mean > 0 else 1.0\n",
    "            \n",
    "            if cv_of_variation < 0.05:\n",
    "                stability = \"HIGHLY STABLE\"\n",
    "            elif cv_of_variation < 0.10:\n",
    "                stability = \"STABLE\"\n",
    "            elif cv_of_variation < 0.15:\n",
    "                stability = \"MODERATE VARIABILITY\"\n",
    "            else:\n",
    "                stability = \"HIGH VARIABILITY\"\n",
    "            \n",
    "            return {\n",
    "                'cv_auc_mean': auc_mean,\n",
    "                'cv_auc_std': auc_std,\n",
    "                'cv_auc_ci_lower': auc_ci_lower,\n",
    "                'cv_auc_ci_upper': auc_ci_upper,\n",
    "                'cv_accuracy_mean': acc_mean,\n",
    "                'cv_accuracy_std': acc_std,\n",
    "                'cv_sensitivity_mean': np.mean(cv_sensitivities),\n",
    "                'cv_specificity_mean': np.mean(cv_specificities),\n",
    "                'cv_folds': cv_folds,\n",
    "                'cv_stability': stability,\n",
    "                'cv_coefficient_variation': cv_of_variation,\n",
    "                'cv_individual_aucs': cv_aucs.tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Cross-validation failed for {algorithm_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _check_feature_quality(self, df):\n",
    "        \"\"\"Check feature quality and completeness\"\"\"\n",
    "        try:\n",
    "            image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "            clinical_features = ['age', 'sex', 'race', 'ethnicity']\n",
    "            \n",
    "            image_quality = len(image_features) >= 50  # Sufficient image features\n",
    "            clinical_completeness = sum(col in df.columns for col in clinical_features) >= 2\n",
    "            \n",
    "            score = (image_quality + clinical_completeness) / 2\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.5 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Image features: {len(image_features)}, Clinical completeness: {clinical_completeness}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Feature quality check failed'}\n",
    "\n",
    "    def run_validation_checks(self, cnn_name, file_path):\n",
    "        \"\"\"Run comprehensive validation checks\"\"\"\n",
    "        print(f\"\\nüîç VALIDATION CHECKS FOR {cnn_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            validation = {\n",
    "                'data_integrity': self._check_data_integrity(df),\n",
    "                'class_balance': self._check_class_balance(df),\n",
    "                'feature_quality': self._check_feature_quality(df),\n",
    "                'sample_size': self._check_sample_size(df)\n",
    "            }\n",
    "            \n",
    "            # Overall assessment\n",
    "            passed_checks = sum(1 for check in validation.values() if check['status'] == 'PASS')\n",
    "            total_checks = len(validation)\n",
    "            \n",
    "            validation['overall'] = {\n",
    "                'status': 'PASS' if passed_checks >= 3 else 'WARN',\n",
    "                'score': passed_checks / total_checks,\n",
    "                'summary': f\"{passed_checks}/{total_checks} validation checks passed\"\n",
    "            }\n",
    "            \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "    def _check_data_integrity(self, df):\n",
    "        \"\"\"Check basic data integrity\"\"\"\n",
    "        try:\n",
    "            has_survival = df['survival'].notna().sum() > 10\n",
    "            has_molecular = any(col in df.columns for col in ['mgmt', 'idh_1_r132h', 'methylation_class'])\n",
    "            has_images = any(col.startswith('feature_') for col in df.columns)\n",
    "            \n",
    "            score = sum([has_survival, has_molecular, has_images]) / 3\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.67 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Survival: {has_survival}, Molecular: {has_molecular}, Images: {has_images}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Data integrity check failed'}\n",
    "\n",
    "    def _check_class_balance(self, df):\n",
    "        \"\"\"Check class balance across targets\"\"\"\n",
    "        try:\n",
    "            balances = []\n",
    "            \n",
    "            # Check mortality balance\n",
    "            if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                survival_data = df[df['survival'].notna() & df['patient_status'].notna()]\n",
    "                if len(survival_data) > 0:\n",
    "                    mortality_1yr = ((survival_data['patient_status'] == 2) & \n",
    "                                   (survival_data['survival'] <= 12)).mean()\n",
    "                    balances.append(min(mortality_1yr, 1-mortality_1yr))\n",
    "            \n",
    "            # Check tumor grade balance\n",
    "            if 'methylation_class' in df.columns:\n",
    "                tumor_data = df[df['methylation_class'].notna()]\n",
    "                if len(tumor_data) > 0:\n",
    "                    high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "                    high_grade_rate = tumor_data['methylation_class'].str.lower().str.contains(\n",
    "                        '|'.join(high_grade_terms), na=False\n",
    "                    ).mean()\n",
    "                    balances.append(min(high_grade_rate, 1-high_grade_rate))\n",
    "            \n",
    "            avg_balance = np.mean(balances) if balances else 0\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if avg_balance >= 0.15 else 'WARN',\n",
    "                'score': avg_balance,\n",
    "                'details': f\"Average minority class rate: {avg_balance:.3f}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Class balance check failed'}\n",
    "\n",
    "    def _check_confounding_factors(self, df):\n",
    "        \"\"\"Check for potential confounding factors in clinical predictions\"\"\"\n",
    "        try:\n",
    "            confounding_issues = []\n",
    "            severity_scores = []\n",
    "            \n",
    "            # Check for age-outcome confounding\n",
    "            age_confounding = self._check_age_confounding(df)\n",
    "            if age_confounding['severity'] > 0:\n",
    "                confounding_issues.append(age_confounding)\n",
    "                severity_scores.append(age_confounding['severity'])\n",
    "            \n",
    "            # Check for center/batch effects (if institutional data available)\n",
    "            batch_confounding = self._check_batch_effects(df)\n",
    "            if batch_confounding['severity'] > 0:\n",
    "                confounding_issues.append(batch_confounding)\n",
    "                severity_scores.append(batch_confounding['severity'])\n",
    "            \n",
    "            # Check for molecular marker interdependence\n",
    "            molecular_confounding = self._check_molecular_confounding(df)\n",
    "            if molecular_confounding['severity'] > 0:\n",
    "                confounding_issues.append(molecular_confounding)\n",
    "                severity_scores.append(molecular_confounding['severity'])\n",
    "            \n",
    "            # Check for survival bias in molecular markers\n",
    "            survival_bias = self._check_survival_bias(df)\n",
    "            if survival_bias['severity'] > 0:\n",
    "                confounding_issues.append(survival_bias) \n",
    "                severity_scores.append(survival_bias['severity'])\n",
    "            \n",
    "            # Overall assessment\n",
    "            if not severity_scores:\n",
    "                status = 'PASS'\n",
    "                score = 1.0\n",
    "                details = \"No major confounding factors detected\"\n",
    "            else:\n",
    "                max_severity = max(severity_scores)\n",
    "                if max_severity >= 0.8:\n",
    "                    status = 'FAIL'\n",
    "                    score = 0.2\n",
    "                    details = f\"Critical confounding detected: {len(confounding_issues)} issues\"\n",
    "                elif max_severity >= 0.5:\n",
    "                    status = 'WARN'\n",
    "                    score = 0.6\n",
    "                    details = f\"Moderate confounding detected: {len(confounding_issues)} issues\"\n",
    "                else:\n",
    "                    status = 'PASS'\n",
    "                    score = 0.8\n",
    "                    details = f\"Minor confounding detected: {len(confounding_issues)} issues\"\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'score': score,\n",
    "                'details': details,\n",
    "                'confounding_issues': confounding_issues,\n",
    "                'n_issues': len(confounding_issues)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'WARN',\n",
    "                'score': 0.5,\n",
    "                'details': f'Confounding check incomplete: {str(e)}',\n",
    "                'confounding_issues': [],\n",
    "                'n_issues': 0\n",
    "            }\n",
    "\n",
    "    def _check_age_confounding(self, df):\n",
    "        \"\"\"Check if age is confounded with outcomes\"\"\"\n",
    "        try:\n",
    "            if 'age' not in df.columns:\n",
    "                return {'type': 'age', 'severity': 0, 'description': 'Age data not available'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            # Check age-mortality confounding\n",
    "            if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                survival_data = df[df['survival'].notna() & df['patient_status'].notna() & df['age'].notna()]\n",
    "                if len(survival_data) > 10:\n",
    "                    deceased = survival_data[survival_data['patient_status'] == 2]['age']\n",
    "                    alive = survival_data[survival_data['patient_status'] != 2]['age']\n",
    "                    \n",
    "                    if len(deceased) > 5 and len(alive) > 5:\n",
    "                        age_diff = abs(deceased.mean() - alive.mean())\n",
    "                        pooled_std = np.sqrt(((deceased.std()**2 + alive.std()**2) / 2))\n",
    "                        effect_size = age_diff / pooled_std if pooled_std > 0 else 0\n",
    "                        \n",
    "                        if effect_size > 0.8:  # Large effect\n",
    "                            severity = 0.9\n",
    "                            issues.append(f\"Large age difference between deceased ({deceased.mean():.1f}) and alive ({alive.mean():.1f})\")\n",
    "                        elif effect_size > 0.5:  # Medium effect\n",
    "                            severity = 0.6\n",
    "                            issues.append(f\"Moderate age difference between outcomes\")\n",
    "                        \n",
    "                        max_severity = max(max_severity, severity if 'severity' in locals() else 0)\n",
    "            \n",
    "            # Check age-tumor grade confounding  \n",
    "            if 'methylation_class' in df.columns:\n",
    "                tumor_data = df[df['methylation_class'].notna() & df['age'].notna()]\n",
    "                if len(tumor_data) > 10:\n",
    "                    high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "                    high_grade_mask = tumor_data['methylation_class'].str.lower().str.contains('|'.join(high_grade_terms), na=False)\n",
    "                    \n",
    "                    high_grade_ages = tumor_data[high_grade_mask]['age']\n",
    "                    low_grade_ages = tumor_data[~high_grade_mask]['age']\n",
    "                    \n",
    "                    if len(high_grade_ages) > 5 and len(low_grade_ages) > 5:\n",
    "                        age_diff = abs(high_grade_ages.mean() - low_grade_ages.mean())\n",
    "                        pooled_std = np.sqrt(((high_grade_ages.std()**2 + low_grade_ages.std()**2) / 2))\n",
    "                        effect_size = age_diff / pooled_std if pooled_std > 0 else 0\n",
    "                        \n",
    "                        if effect_size > 0.8:\n",
    "                            severity = 0.7  # Slightly less critical than mortality\n",
    "                            issues.append(f\"Age strongly associated with tumor grade\")\n",
    "                            max_severity = max(max_severity, severity)\n",
    "            \n",
    "            return {\n",
    "                'type': 'age_confounding',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant age confounding detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'age_confounding', 'severity': 0, 'description': 'Age confounding check failed'}\n",
    "\n",
    "    def _check_batch_effects(self, df):\n",
    "        \"\"\"Check for potential batch/center effects\"\"\"\n",
    "        try:\n",
    "            # Look for institutional or batch identifiers\n",
    "            batch_columns = [col for col in df.columns if any(term in col.lower() \n",
    "                           for term in ['institution', 'center', 'batch', 'site', 'hospital'])]\n",
    "            \n",
    "            if not batch_columns:\n",
    "                return {'type': 'batch_effects', 'severity': 0, 'description': 'No batch identifiers found'}\n",
    "            \n",
    "            # Check if outcomes vary significantly by batch\n",
    "            severity = 0\n",
    "            issues = []\n",
    "            \n",
    "            for batch_col in batch_columns:\n",
    "                unique_batches = df[batch_col].nunique()\n",
    "                if unique_batches > 1 and unique_batches < len(df) * 0.5:  # Reasonable number of batches\n",
    "                    # Check mortality rates by batch\n",
    "                    if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                        batch_mortality = df.groupby(batch_col).apply(\n",
    "                            lambda x: ((x['patient_status'] == 2) & (x['survival'] <= 12)).mean()\n",
    "                        )\n",
    "                        if batch_mortality.std() > 0.15:  # >15% variation in mortality rates\n",
    "                            severity = max(severity, 0.6)\n",
    "                            issues.append(f\"Mortality rates vary by {batch_col}\")\n",
    "            \n",
    "            return {\n",
    "                'type': 'batch_effects',\n",
    "                'severity': severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant batch effects detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'batch_effects', 'severity': 0, 'description': 'Batch effects check failed'}\n",
    "\n",
    "    def _check_molecular_confounding(self, df):\n",
    "        \"\"\"Check for confounding between molecular markers\"\"\"\n",
    "        try:\n",
    "            molecular_cols = ['mgmt', 'idh_1_r132h', 'atrx', 'p53']\n",
    "            available_molecular = [col for col in molecular_cols if col in df.columns]\n",
    "            \n",
    "            if len(available_molecular) < 2:\n",
    "                return {'type': 'molecular_confounding', 'severity': 0, 'description': 'Insufficient molecular data'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            # Check IDH-MGMT association (known biological confounding)\n",
    "            if 'idh_1_r132h' in df.columns and 'mgmt' in df.columns:\n",
    "                idh_mgmt_data = df[(df['idh_1_r132h'].isin([1, 2])) & (df['mgmt'].isin([1, 2]))]\n",
    "                \n",
    "                if len(idh_mgmt_data) > 20:\n",
    "                    # Create contingency table\n",
    "                    idh_mutant = (idh_mgmt_data['idh_1_r132h'] == 2)  # Assuming 2 = mutant\n",
    "                    mgmt_methylated = (idh_mgmt_data['mgmt'] == 1)  # 1 = methylated per data dictionary\n",
    "                    \n",
    "                    # Calculate association strength (Cram√©r's V)\n",
    "                    from scipy.stats import chi2_contingency\n",
    "                    try:\n",
    "                        contingency = pd.crosstab(idh_mutant, mgmt_methylated)\n",
    "                        chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "                        n = contingency.sum().sum()\n",
    "                        cramers_v = np.sqrt(chi2 / (n * (min(contingency.shape) - 1)))\n",
    "                        \n",
    "                        if cramers_v > 0.5 and p_value < 0.05:\n",
    "                            max_severity = 0.8\n",
    "                            issues.append(\"Strong IDH-MGMT association detected (biological confounding)\")\n",
    "                        elif cramers_v > 0.3 and p_value < 0.05:\n",
    "                            max_severity = 0.5\n",
    "                            issues.append(\"Moderate IDH-MGMT association detected\")\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            return {\n",
    "                'type': 'molecular_confounding',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant molecular confounding detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'molecular_confounding', 'severity': 0, 'description': 'Molecular confounding check failed'}\n",
    "\n",
    "    def _check_survival_bias(self, df):\n",
    "        \"\"\"Check for survival bias in molecular marker availability\"\"\"\n",
    "        try:\n",
    "            if not all(col in df.columns for col in ['survival', 'patient_status']):\n",
    "                return {'type': 'survival_bias', 'severity': 0, 'description': 'Survival data not available'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            molecular_cols = ['mgmt', 'idh_1_r132h', 'atrx', 'p53']\n",
    "            \n",
    "            for mol_col in molecular_cols:\n",
    "                if mol_col in df.columns:\n",
    "                    # Compare survival times between patients with/without molecular data\n",
    "                    has_molecular = df[df[mol_col].notna() & df['survival'].notna()]\n",
    "                    no_molecular = df[df[mol_col].isna() & df['survival'].notna()]\n",
    "                    \n",
    "                    if len(has_molecular) > 10 and len(no_molecular) > 10:\n",
    "                        survival_diff = abs(has_molecular['survival'].mean() - no_molecular['survival'].mean())\n",
    "                        pooled_std = np.sqrt((has_molecular['survival'].std()**2 + no_molecular['survival'].std()**2) / 2)\n",
    "                        \n",
    "                        if pooled_std > 0:\n",
    "                            effect_size = survival_diff / pooled_std\n",
    "                            \n",
    "                            if effect_size > 0.5:  # Medium to large effect\n",
    "                                severity = 0.6\n",
    "                                issues.append(f\"Survival bias detected for {mol_col} availability\")\n",
    "                                max_severity = max(max_severity, severity)\n",
    "            \n",
    "            return {\n",
    "                'type': 'survival_bias',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant survival bias detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'survival_bias', 'severity': 0, 'description': 'Survival bias check failed'}\n",
    "        \"\"\"Check feature quality and completeness\"\"\"\n",
    "        try:\n",
    "            image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "            clinical_features = ['age', 'sex', 'race', 'ethnicity']\n",
    "            \n",
    "            image_quality = len(image_features) >= 50  # Sufficient image features\n",
    "            clinical_completeness = sum(col in df.columns for col in clinical_features) >= 2\n",
    "            \n",
    "            score = (image_quality + clinical_completeness) / 2\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.5 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Image features: {len(image_features)}, Clinical completeness: {clinical_completeness}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Feature quality check failed'}\n",
    "\n",
    "    def _check_sample_size(self, df):\n",
    "        \"\"\"Check sample size adequacy\"\"\"\n",
    "        try:\n",
    "            total_samples = len(df)\n",
    "            \n",
    "            # Check samples for different tasks\n",
    "            survival_samples = df[df['survival'].notna() & df['patient_status'].notna()].shape[0]\n",
    "            tumor_samples = df[df['methylation_class'].notna()].shape[0]\n",
    "            \n",
    "            min_samples = min(survival_samples, tumor_samples) if tumor_samples > 0 else survival_samples\n",
    "            \n",
    "            if min_samples >= 50:\n",
    "                status = 'PASS'\n",
    "                score = 1.0\n",
    "            elif min_samples >= 30:\n",
    "                status = 'WARN'\n",
    "                score = 0.7\n",
    "            else:\n",
    "                status = 'FAIL'\n",
    "                score = 0.3\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'score': score,\n",
    "                'details': f\"Min task samples: {min_samples}, Total: {total_samples}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Sample size check failed'}\n",
    "\n",
    "    def generate_publication_document(self):\n",
    "        \"\"\"Generate a comprehensive publication-ready document\"\"\"\n",
    "        \n",
    "        if not self.results:\n",
    "            print(\"No results available for document generation\")\n",
    "            return\n",
    "        \n",
    "        # Create comprehensive document content\n",
    "        doc_content = []\n",
    "        \n",
    "        # Title and Header\n",
    "        doc_content.append(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"EXECUTIVE SUMMARY\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            doc_content.append(f\"Total algorithm-task combinations tested: {total_tests}\")\n",
    "            doc_content.append(f\"Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            doc_content.append(f\"Best AUC achieved: {max_auc:.3f}\")\n",
    "            doc_content.append(f\"Excellent performance (AUC >= 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            doc_content.append(f\"Good+ performance (AUC >= 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            if excellent_tests > 0:\n",
    "                doc_content.append(f\"CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                doc_content.append(\"PUBLICATION STATUS: Exceptional results achieved - ready for top-tier journals\")\n",
    "            elif max_auc >= 0.80:\n",
    "                doc_content.append(\"PUBLICATION STATUS: Strong results achieved - ready for clinical journals\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Detailed Results Table\n",
    "        doc_content.append(\"COMPREHENSIVE RESULTS TABLE\")\n",
    "        doc_content.append(\"-\" * 80)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Create detailed table\n",
    "        header = f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Accuracy':<9} {'Sensitivity':<11} {'Specificity':<11} {'Status':<15}\"\n",
    "        doc_content.append(header)\n",
    "        doc_content.append(\"-\" * len(header))\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC without emojis\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"GOOD\"\n",
    "                    else:\n",
    "                        status = \"MODERATE\"\n",
    "                    \n",
    "                    row = f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<9.3f} {sens:<11.3f} {spec:<11.3f} {status:<15}\"\n",
    "                    doc_content.append(row)\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Best Performers Analysis\n",
    "        doc_content.append(\"BEST PERFORMERS BY CLINICAL TASK\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Find best performer for each task\n",
    "        task_best = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            acc = best['result']['accuracy']\n",
    "            sens = best['result']['sensitivity']\n",
    "            spec = best['result']['specificity']\n",
    "            \n",
    "            status = \"DEPLOYMENT READY\" if auc >= 0.85 else \"PROMISING\" if auc >= 0.75 else \"NEEDS OPTIMIZATION\"\n",
    "            \n",
    "            doc_content.append(f\"Task: {task_name}\")\n",
    "            doc_content.append(f\"  Best Combination: {best['cnn']} + {best['algorithm']}\")\n",
    "            doc_content.append(f\"  Performance: AUC = {auc:.3f}, Accuracy = {acc:.3f}\")\n",
    "            doc_content.append(f\"  Clinical Metrics: Sensitivity = {sens:.3f}, Specificity = {spec:.3f}\")\n",
    "            doc_content.append(f\"  Status: {status}\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Algorithm Performance Ranking\n",
    "        doc_content.append(\"ALGORITHM PERFORMANCE RANKING\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        algorithm_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if alg_name not in algorithm_stats:\n",
    "                        algorithm_stats[alg_name] = []\n",
    "                    algorithm_stats[alg_name].append(result['auc'])\n",
    "        \n",
    "        if algorithm_stats:\n",
    "            sorted_algorithms = sorted(algorithm_stats.items(), key=lambda x: np.mean(x[1]), reverse=True)\n",
    "            \n",
    "            for i, (alg_name, aucs) in enumerate(sorted_algorithms, 1):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                std_auc = np.std(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                \n",
    "                doc_content.append(f\"{i}. {alg_name}\")\n",
    "                doc_content.append(f\"   Mean AUC: {mean_auc:.3f} (¬±{std_auc:.3f})\")\n",
    "                doc_content.append(f\"   Best AUC: {max_auc:.3f}\")\n",
    "                doc_content.append(f\"   Tests: {n_tests}\")\n",
    "                doc_content.append(\"\")\n",
    "        \n",
    "        # CNN Architecture Ranking\n",
    "        doc_content.append(\"CNN ARCHITECTURE RANKING\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        cnn_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            aucs = []\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    aucs.append(result['auc'])\n",
    "            if aucs:\n",
    "                cnn_stats[cnn_name] = aucs\n",
    "        \n",
    "        if cnn_stats:\n",
    "            sorted_cnns = sorted(cnn_stats.items(), key=lambda x: np.mean(x[1]), reverse=True)\n",
    "            \n",
    "            for i, (cnn_name, aucs) in enumerate(sorted_cnns, 1):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                std_auc = np.std(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                \n",
    "                doc_content.append(f\"{i}. {cnn_name}\")\n",
    "                doc_content.append(f\"   Mean AUC: {mean_auc:.3f} (¬±{std_auc:.3f})\")\n",
    "                doc_content.append(f\"   Best AUC: {max_auc:.3f}\")\n",
    "                doc_content.append(f\"   Tests: {n_tests}\")\n",
    "                doc_content.append(\"\")\n",
    "        \n",
    "        # Clinical Recommendations\n",
    "        doc_content.append(\"CLINICAL IMPLEMENTATION RECOMMENDATIONS\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Find deployment-ready combinations\n",
    "        deployment_ready = []\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.80:  # Clinical deployment threshold\n",
    "                        deployment_ready.append({\n",
    "                            'task': task_name,\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'auc': result['auc'],\n",
    "                            'accuracy': result['accuracy']\n",
    "                        })\n",
    "        \n",
    "        deployment_ready.sort(key=lambda x: x['auc'], reverse=True)\n",
    "        \n",
    "        if deployment_ready:\n",
    "            doc_content.append(f\"DEPLOYMENT-READY COMBINATIONS (AUC >= 0.80): {len(deployment_ready)}\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            for i, combo in enumerate(deployment_ready[:10], 1):  # Top 10\n",
    "                doc_content.append(f\"{i}. {combo['task']}\")\n",
    "                doc_content.append(f\"   Model: {combo['cnn']} + {combo['algorithm']}\")\n",
    "                doc_content.append(f\"   Performance: {combo['auc']:.1%} AUC, {combo['accuracy']:.1%} Accuracy\")\n",
    "                doc_content.append(\"\")\n",
    "                \n",
    "            doc_content.append(\"PRIORITY IMPLEMENTATION:\")\n",
    "            top_combo = deployment_ready[0]\n",
    "            doc_content.append(f\"Task: {top_combo['task']}\")\n",
    "            doc_content.append(f\"Architecture: {top_combo['cnn']} + {top_combo['algorithm']}\")\n",
    "            doc_content.append(f\"Expected Clinical Performance: {top_combo['auc']:.1%} discrimination accuracy\")\n",
    "            doc_content.append(\"\")\n",
    "        else:\n",
    "            doc_content.append(\"No combinations reached clinical deployment threshold (AUC >= 0.80)\")\n",
    "            doc_content.append(\"Focus on methodology optimization for best performing approaches\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Publication Strategy\n",
    "        doc_content.append(\"PUBLICATION STRATEGY\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Count publication-ready results\n",
    "        tier1_results = []  # AUC >= 0.85\n",
    "        tier2_results = []  # AUC >= 0.75\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.85:\n",
    "                        tier1_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "                    elif result['auc'] >= 0.75:\n",
    "                        tier2_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "        \n",
    "        doc_content.append(\"PUBLICATION READINESS ASSESSMENT:\")\n",
    "        doc_content.append(f\"Tier 1 Results (AUC >= 0.85): {len(tier1_results)} - Suitable for top-tier journals\")\n",
    "        doc_content.append(f\"Tier 2 Results (AUC >= 0.75): {len(tier2_results)} - Suitable for clinical journals\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        if tier1_results:\n",
    "            doc_content.append(\"TOP-TIER JOURNAL STRATEGY:\")\n",
    "            doc_content.append(\"Target Journals: Nature Medicine, Lancet Digital Health, Nature Biomedical Engineering\")\n",
    "            best_result = max(tier1_results, key=lambda x: x[3])\n",
    "            doc_content.append(f\"Lead Finding: {best_result[0]} ({best_result[1]} + {best_result[2]}, AUC = {best_result[3]:.3f})\")\n",
    "            doc_content.append(\"Narrative: 'Deep Learning Achieves Clinical-Grade Performance in Neurosurgical Prediction'\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "        if tier2_results:\n",
    "            doc_content.append(\"CLINICAL JOURNAL STRATEGY:\")\n",
    "            doc_content.append(\"Target Journals: Neuro-Oncology, Journal of Neurosurgery, Academic Radiology\")\n",
    "            doc_content.append(\"Focus: Clinical validation studies and comparative effectiveness research\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        doc_content.append(\"MANUSCRIPT DEVELOPMENT PRIORITIES:\")\n",
    "        doc_content.append(\"1. Primary Research Paper: Best performing clinical task for high-impact publication\")\n",
    "        doc_content.append(\"2. Methodology Paper: Comprehensive multi-architecture comparison study\")\n",
    "        doc_content.append(\"3. Clinical Implementation Paper: Validation study and cost-effectiveness analysis\")\n",
    "        doc_content.append(\"4. Technical Paper: Algorithm optimization and feature engineering methods\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Validation Summary\n",
    "        if self.validation_results:\n",
    "            doc_content.append(\"DATA VALIDATION SUMMARY\")\n",
    "            doc_content.append(\"-\" * 40)\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            validation_header = f\"{'CNN Architecture':<20} {'Overall Status':<15} {'Data Quality':<12} {'Class Balance':<12} {'Sample Size':<12}\"\n",
    "            doc_content.append(validation_header)\n",
    "            doc_content.append(\"-\" * len(validation_header))\n",
    "            \n",
    "            for cnn_name, validation in self.validation_results.items():\n",
    "                if 'error' in validation:\n",
    "                    doc_content.append(f\"{cnn_name:<20} {'ERROR':<15} {'N/A':<12} {'N/A':<12} {'N/A':<12}\")\n",
    "                else:\n",
    "                    overall = validation.get('overall', {}).get('status', 'FAIL')\n",
    "                    data_quality = validation.get('data_integrity', {}).get('status', 'FAIL')\n",
    "                    class_balance = validation.get('class_balance', {}).get('status', 'FAIL')\n",
    "                    sample_size = validation.get('sample_size', {}).get('status', 'FAIL')\n",
    "                    \n",
    "                    doc_content.append(f\"{cnn_name:<20} {overall:<15} {data_quality:<12} {class_balance:<12} {sample_size:<12}\")\n",
    "            \n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Technical Specifications\n",
    "        doc_content.append(\"TECHNICAL SPECIFICATIONS\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"Machine Learning Algorithms Tested:\")\n",
    "        \n",
    "        algorithms = self.get_ml_algorithms()\n",
    "        for i, (alg_name, alg_config) in enumerate(algorithms.items(), 1):\n",
    "            doc_content.append(f\"{i}. {alg_name}: {alg_config['description']}\")\n",
    "            doc_content.append(f\"   Preprocessing: {'Robust Scaling Applied' if alg_config['needs_scaling'] else 'No Scaling Required'}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"CNN Architectures Evaluated:\")\n",
    "        for i, cnn_name in enumerate(self.datasets.keys(), 1):\n",
    "            doc_content.append(f\"{i}. {cnn_name}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"Clinical Tasks Assessed:\")\n",
    "        tasks = set()\n",
    "        for cnn_results in self.results.values():\n",
    "            for task_data in cnn_results.values():\n",
    "                tasks.add(task_data['task_name'])\n",
    "        \n",
    "        for i, task in enumerate(sorted(tasks), 1):\n",
    "            doc_content.append(f\"{i}. {task}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        doc_content.append(\"ANALYSIS COMPLETE\")\n",
    "        doc_content.append(f\"Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        \n",
    "        # Write to file\n",
    "        filename = f\"neurosurgical_ai_analysis_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "        \n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                for line in doc_content:\n",
    "                    f.write(line + '\\n')\n",
    "            \n",
    "            # Calculate file size properly\n",
    "            doc_text = '\\n'.join(doc_content)\n",
    "            file_size = len(doc_text)\n",
    "            \n",
    "            print(f\"\\nPublication document generated successfully!\")\n",
    "            print(f\"Filename: {filename}\")\n",
    "            print(f\"Lines written: {len(doc_content)}\")\n",
    "            print(f\"File size: {file_size} characters\")\n",
    "            \n",
    "            return filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error writing document: {e}\")\n",
    "            return None\n",
    "\n",
    "    def run_comprehensive_analysis(self):\n",
    "        \"\"\"Run the complete comprehensive analysis\"\"\"\n",
    "        \n",
    "        print(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Testing 5 CNNs √ó Multiple ML Algorithms √ó 6 Clinical Tasks\")\n",
    "        print(\"Target: Clinical-grade performance (AUC >= 0.80)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Initialize ML algorithms\n",
    "        algorithms = self.get_ml_algorithms()\n",
    "        \n",
    "        print(f\"\\nAVAILABLE ALGORITHMS ({len(algorithms)}):\")\n",
    "        for alg_name, alg_config in algorithms.items():\n",
    "            print(f\"   {alg_name}: {alg_config['description']}\")\n",
    "        \n",
    "        # Test each CNN dataset\n",
    "        for cnn_name, file_path in self.datasets.items():\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ANALYZING {cnn_name} DATASET\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            try:\n",
    "                # Check if file exists before processing\n",
    "                import os\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"ERROR {cnn_name}: File not found - {file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Run validation checks first\n",
    "                validation = self.run_validation_checks(cnn_name, file_path)\n",
    "                self.validation_results[cnn_name] = validation\n",
    "                \n",
    "                if 'error' in validation:\n",
    "                    print(f\"ERROR {cnn_name}: Validation failed - {validation['error']}\")\n",
    "                    continue\n",
    "                \n",
    "                overall_status = validation.get('overall', {}).get('status', 'FAIL')\n",
    "                if overall_status == 'FAIL':\n",
    "                    print(f\"ERROR {cnn_name}: Failed validation checks\")\n",
    "                    continue\n",
    "                \n",
    "                # Load and process data\n",
    "                print(f\"Loading data from: {file_path}\")\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"Dataset shape: {df.shape}\")\n",
    "                \n",
    "                targets_data = self.create_all_targets(df)\n",
    "                \n",
    "                if not targets_data:\n",
    "                    print(f\"ERROR {cnn_name}: No valid targets created\")\n",
    "                    continue\n",
    "                \n",
    "                # Feature selection\n",
    "                features = self.select_features(df)\n",
    "                print(f\"Available features: {len(features)}\")\n",
    "                \n",
    "                cnn_results = {}\n",
    "                \n",
    "                # Test each target category\n",
    "                for category, target_info in targets_data.items():\n",
    "                    category_data = target_info['data']\n",
    "                    \n",
    "                    for i, target_col in enumerate(target_info['targets']):\n",
    "                        task_name = target_info['descriptions'][i]\n",
    "                        \n",
    "                        print(f\"\\n{'-'*40}\")\n",
    "                        print(f\"TASK: {task_name}\")\n",
    "                        print(f\"{'-'*40}\")\n",
    "                        \n",
    "                        # Exclude target-related features to prevent leakage\n",
    "                        safe_features = self._get_safe_features(features, target_col)\n",
    "                        \n",
    "                        X, y, error = self.preprocess_data(category_data, safe_features, target_col)\n",
    "                        \n",
    "                        if X is None:\n",
    "                            print(f\"ERROR {task_name}: {error}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Run all algorithms for this task\n",
    "                        task_results = self.run_prediction_task(X, y, task_name, cnn_name, algorithms)\n",
    "                        \n",
    "                        if task_results:\n",
    "                            task_key = f\"{category}_{target_col}\"\n",
    "                            cnn_results[task_key] = {\n",
    "                                'task_name': task_name,\n",
    "                                'results': task_results,\n",
    "                                'n_samples': len(X),\n",
    "                                'n_features': X.shape[1]\n",
    "                            }\n",
    "                \n",
    "                if cnn_results:\n",
    "                    self.results[cnn_name] = cnn_results\n",
    "                    print(f\"\\nSUCCESS {cnn_name}: {len(cnn_results)} tasks completed successfully\")\n",
    "                else:\n",
    "                    print(f\"ERROR {cnn_name}: No tasks completed successfully\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR {cnn_name}: Complete failure - {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()  # This will help debug the specific error\n",
    "        \n",
    "        # Generate comprehensive report\n",
    "        self.generate_comprehensive_report()\n",
    "        \n",
    "        # Generate publication document\n",
    "        doc_filename = self.generate_publication_document()\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def _get_safe_features(self, features, target_col):\n",
    "        \"\"\"Get features safe from data leakage\"\"\"\n",
    "        # Remove features that might leak information about the target\n",
    "        unsafe_patterns = {\n",
    "            'idh_binary': ['idh'],\n",
    "            'mgmt_binary': ['mgmt'],\n",
    "            'high_grade': [],  # Tumor grade can use all molecular features\n",
    "            'mortality_6mo': [],\n",
    "            'mortality_1yr': [],\n",
    "            'mortality_2yr': []\n",
    "        }\n",
    "        \n",
    "        patterns_to_exclude = unsafe_patterns.get(target_col, [])\n",
    "        \n",
    "        safe_features = []\n",
    "        for feature in features:\n",
    "            is_safe = True\n",
    "            for pattern in patterns_to_exclude:\n",
    "                if pattern.lower() in feature.lower():\n",
    "                    is_safe = False\n",
    "                    break\n",
    "            if is_safe:\n",
    "                safe_features.append(feature)\n",
    "        \n",
    "        return safe_features\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"\\n‚ùå No results to report\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üìä COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # EXECUTIVE SUMMARY\n",
    "        # ============================================================\n",
    "        self._generate_executive_summary()\n",
    "        \n",
    "        # ============================================================\n",
    "        # DETAILED RESULTS TABLE\n",
    "        # ============================================================\n",
    "        self._generate_detailed_results_table()\n",
    "        \n",
    "        # ============================================================\n",
    "        # BEST PERFORMERS ANALYSIS\n",
    "        # ============================================================\n",
    "        self._generate_best_performers_analysis()\n",
    "        \n",
    "        # ============================================================\n",
    "        # VALIDATION SUMMARY\n",
    "        # ============================================================\n",
    "        self._generate_validation_summary()\n",
    "        \n",
    "        # ============================================================\n",
    "        # CLINICAL RECOMMENDATIONS\n",
    "        # ============================================================\n",
    "        self._generate_clinical_recommendations()\n",
    "        \n",
    "        # ============================================================\n",
    "        # PUBLICATION STRATEGY\n",
    "        # ============================================================\n",
    "        self._generate_publication_strategy()\n",
    "\n",
    "    def _generate_executive_summary(self):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        print(\"\\nüéØ EXECUTIVE SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        \n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            print(f\" PERFORMANCE OVERVIEW:\")\n",
    "            print(f\"   Total algorithm-task combinations: {total_tests}\")\n",
    "            print(f\"   Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            print(f\"   Best AUC achieved: {max_auc:.3f}\")\n",
    "            print(f\"   Excellent performance (AUC ‚â• 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            print(f\"   Good+ performance (AUC ‚â• 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            \n",
    "            # Clinical readiness assessment\n",
    "            if excellent_tests > 0:\n",
    "                print(f\"   üöÄ CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                print(f\"   üèÜ PUBLICATION READY: Exceptional results achieved\")\n",
    "            elif max_auc >= 0.80:\n",
    "                print(f\"   üìù PUBLICATION READY: Strong results achieved\")\n",
    "\n",
    "    def _generate_detailed_results_table(self):\n",
    "        \"\"\"Generate detailed results table\"\"\"\n",
    "        print(f\"\\nüìã DETAILED RESULTS TABLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Header\n",
    "        print(f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Acc':<8} {'Sens':<8} {'Spec':<8} {'Status':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"üèÜ EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"‚úÖ STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"üìà GOOD\"\n",
    "                    else:\n",
    "                        status = \"‚ö†Ô∏è MODERATE\"\n",
    "                    \n",
    "                    print(f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<8.3f} {sens:<8.3f} {spec:<8.3f} {status:<15}\")\n",
    "\n",
    "    def _generate_best_performers_analysis(self):\n",
    "        \"\"\"Generate best performers analysis\"\"\"\n",
    "        print(f\"\\nüèÜ BEST PERFORMERS BY TASK\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Find best performer for each task across all CNNs\n",
    "        task_best = {}\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            status = \"üöÄ DEPLOYMENT READY\" if auc >= 0.85 else \"üìà PROMISING\" if auc >= 0.75 else \"‚ö†Ô∏è NEEDS WORK\"\n",
    "            print(f\"{task_name:<30}: {best['cnn']} + {best['algorithm']} (AUC = {auc:.3f}) {status}\")\n",
    "\n",
    "    def _generate_validation_summary(self):\n",
    "        \"\"\"Generate validation summary\"\"\"\n",
    "        print(f\"\\nVALIDATION SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if not self.validation_results:\n",
    "            print(\"No validation results available\")\n",
    "            return\n",
    "        \n",
    "        print(f\"{'CNN':<20} {'Overall':<10} {'Data':<10} {'Balance':<10} {'Features':<10} {'Samples':<10}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for cnn_name, validation in self.validation_results.items():\n",
    "            if 'error' in validation:\n",
    "                print(f\"{cnn_name:<20} {'ERROR':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n",
    "                continue\n",
    "            \n",
    "            overall = validation.get('overall', {}).get('status', 'FAIL')\n",
    "            data_integrity = validation.get('data_integrity', {}).get('status', 'FAIL')\n",
    "            class_balance = validation.get('class_balance', {}).get('status', 'FAIL')\n",
    "            feature_quality = validation.get('feature_quality', {}).get('status', 'FAIL')\n",
    "            sample_size = validation.get('sample_size', {}).get('status', 'FAIL')\n",
    "            \n",
    "            print(f\"{cnn_name:<20} {overall:<10} {data_integrity:<10} {class_balance:<10} {feature_quality:<10} {sample_size:<10}\")\n",
    "\n",
    "    def _generate_clinical_recommendations(self):\n",
    "        \"\"\"Generate clinical recommendations\"\"\"\n",
    "        print(f\"\\nCLINICAL RECOMMENDATIONS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Algorithm performance ranking\n",
    "        algorithm_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if alg_name not in algorithm_stats:\n",
    "                        algorithm_stats[alg_name] = []\n",
    "                    algorithm_stats[alg_name].append(result['auc'])\n",
    "        \n",
    "        print(\"ALGORITHM PERFORMANCE RANKING:\")\n",
    "        if algorithm_stats:\n",
    "            for alg_name, aucs in sorted(algorithm_stats.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                print(f\"   {alg_name}: {mean_auc:.3f} mean AUC, {max_auc:.3f} max AUC ({n_tests} tests)\")\n",
    "        \n",
    "        # CNN performance ranking\n",
    "        cnn_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            aucs = []\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    aucs.append(result['auc'])\n",
    "            if aucs:\n",
    "                cnn_stats[cnn_name] = aucs\n",
    "        \n",
    "        print(f\"\\nCNN ARCHITECTURE RANKING:\")\n",
    "        if cnn_stats:\n",
    "            for cnn_name, aucs in sorted(cnn_stats.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                print(f\"   {cnn_name}: {mean_auc:.3f} mean AUC, {max_auc:.3f} max AUC ({n_tests} tests)\")\n",
    "        \n",
    "        # Implementation recommendations\n",
    "        print(f\"\\nIMPLEMENTATION RECOMMENDATIONS:\")\n",
    "        \n",
    "        best_combinations = []\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.80:\n",
    "                        best_combinations.append({\n",
    "                            'cnn': cnn_name,\n",
    "                            'task': task_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'auc': result['auc']\n",
    "                        })\n",
    "        \n",
    "        best_combinations.sort(key=lambda x: x['auc'], reverse=True)\n",
    "        \n",
    "        if best_combinations:\n",
    "            print(f\"   {len(best_combinations)} CNN-algorithm combinations ready for clinical validation\")\n",
    "            print(f\"   Priority implementation: {best_combinations[0]['task']} using {best_combinations[0]['cnn']} + {best_combinations[0]['algorithm']}\")\n",
    "            print(f\"   Expected performance: {best_combinations[0]['auc']:.1%} discrimination accuracy\")\n",
    "        else:\n",
    "            print(f\"   No combinations reached clinical deployment threshold (AUC >= 0.80)\")\n",
    "            print(f\"   Focus on methodology optimization for best performing approaches\")\n",
    "\n",
    "    def _generate_publication_strategy(self):\n",
    "        \"\"\"Generate publication strategy\"\"\"\n",
    "        \n",
    "        print(f\"\\nPUBLICATION STRATEGY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        excellent_results = []\n",
    "        good_results = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.85:\n",
    "                        excellent_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "                    elif result['auc'] >= 0.75:\n",
    "                        good_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"GOAL: Comprehensive evaluation of CNN architectures and ML algorithms\")\n",
    "    print(\"SCOPE: 5 CNNs √ó Multiple Algorithms √ó 6 Clinical Tasks\")\n",
    "    print(\"OUTPUT: Clinical-ready recommendations for your team and PI\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = NeurosurgicalAIAnalyzer()\n",
    "    \n",
    "    # Run comprehensive analysis\n",
    "    results = analyzer.run_comprehensive_analysis()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"COMPREHENSIVE ANALYSIS COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if results:\n",
    "        n_cnns = len(results)\n",
    "        total_tasks = sum(len(cnn_results) for cnn_results in results.values())\n",
    "        total_tests = sum(\n",
    "            len(task_data['results']) \n",
    "            for cnn_results in results.values() \n",
    "            for task_data in cnn_results.values()\n",
    "        )\n",
    "        \n",
    "        print(f\"ANALYSIS SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ {n_cnns} CNN architectures analyzed\")\n",
    "        print(f\"   ‚Ä¢ {total_tasks} clinical tasks evaluated\") \n",
    "        print(f\"   ‚Ä¢ {total_tests} algorithm-task combinations tested\")\n",
    "        print(f\"   ‚Ä¢ Comprehensive validation and recommendations generated\")\n",
    "        print(f\"   ‚Ä¢ Publication-ready document created\")\n",
    "    else:\n",
    "        print(\"No results generated. Check data file paths and formats.\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# Execute the comprehensive analysis\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48067e",
   "metadata": {},
   "source": [
    "*added txt + csv file and changed file names to be named after cnn datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23221bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             accuracy_score, roc_curve, precision_recall_curve, auc)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# Optional dependencies\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import torch\n",
    "    TABNET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"TabNet not available. Install with: pip install pytorch-tabnet torch\")\n",
    "\n",
    "class NeurosurgicalAIAnalyzer:\n",
    "    \"\"\"Comprehensive AI analysis system for neurosurgical outcome prediction\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Define dataset paths\n",
    "        self.datasets = {\n",
    "            'ConvNext': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_master.csv',\n",
    "            'ViT': '/Users/joi263/Documents/MultimodalTabData/data/vit_base_data/vit_base_cleaned_master.csv',\n",
    "            'ResNet50_Pretrained': '/Users/joi263/Documents/MultimodalTabData/data/pretrained_resnet50_data/pretrained_resnet50_cleaned_master.csv',\n",
    "            'ResNet50_ImageNet': '/Users/joi263/Documents/MultimodalTabData/data/imagenet_resnet50_data/imagenet_resnet50_cleaned_master.csv',\n",
    "            'EfficientNet': '/Users/joi263/Documents/MultimodalTabData/data/efficientnet_data/efficientnet_cleaned_master.csv'\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.validation_results = {}\n",
    "\n",
    "        # Verify file existence\n",
    "        print(\"CHECKING DATA FILE PATHS:\")\n",
    "        print(\"=\"*50)\n",
    "        existing = 0\n",
    "        for name, path in self.datasets.items():\n",
    "            status = \"EXISTS\" if os.path.exists(path) else \"NOT FOUND\"\n",
    "            print(f\"{name:<20}: {status}\")\n",
    "            if os.path.exists(path): existing += 1\n",
    "        print(f\"Found {existing}/{len(self.datasets)} files\")\n",
    "        print(\"=\"*50, \"\\n\")\n",
    "\n",
    "    def get_ml_algorithms(self):\n",
    "        \"\"\"Initialize ML algorithms with tuned parameters\"\"\"\n",
    "        algs = {}\n",
    "        # TabPFN\n",
    "        algs['TabPFN'] = {'model': TabPFNClassifier(device='cpu'), 'needs_scaling': False}\n",
    "        # XGBoost\n",
    "        if XGBOOST_AVAILABLE:\n",
    "            algs['XGBoost'] = {\n",
    "                'model': xgb.XGBClassifier(\n",
    "                    n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "                    subsample=0.8, colsample_bytree=0.8,\n",
    "                    min_child_weight=3, reg_alpha=1, reg_lambda=1,\n",
    "                    random_state=42, eval_metric='logloss', use_label_encoder=False\n",
    "                ),\n",
    "                'needs_scaling': False\n",
    "            }\n",
    "        # TabNet\n",
    "        if TABNET_AVAILABLE:\n",
    "            algs['TabNet'] = {\n",
    "                'model': TabNetClassifier(\n",
    "                    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
    "                    lambda_sparse=1e-4, optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=0.01, weight_decay=1e-5),\n",
    "                    mask_type='entmax', scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    scheduler_params={'step_size': 20, 'gamma': 0.8},\n",
    "                    verbose=0, seed=42\n",
    "                ),\n",
    "                'needs_scaling': True\n",
    "            }\n",
    "        # RandomForest\n",
    "        algs['RandomForest'] = {\n",
    "            'model': RandomForestClassifier(\n",
    "                n_estimators=500, max_depth=8,\n",
    "                min_samples_split=10, min_samples_leaf=5,\n",
    "                max_features='sqrt', oob_score=True,\n",
    "                class_weight='balanced', random_state=42, n_jobs=-1\n",
    "            ),\n",
    "            'needs_scaling': False\n",
    "        }\n",
    "        # LogisticRegression\n",
    "        algs['LogisticRegression'] = {\n",
    "            'model': LogisticRegression(\n",
    "                penalty='elasticnet', l1_ratio=0.5, C=0.1,\n",
    "                solver='saga', max_iter=2000,\n",
    "                class_weight='balanced', random_state=42, n_jobs=-1\n",
    "            ),\n",
    "            'needs_scaling': True\n",
    "        }\n",
    "        # SVM\n",
    "        algs['SVM'] = {\n",
    "            'model': SVC(kernel='rbf', C=1.0, gamma='scale', probability=True,\n",
    "                         class_weight='balanced', random_state=42),\n",
    "            'needs_scaling': True\n",
    "        }\n",
    "        return algs\n",
    "\n",
    "    def create_all_targets(self, df):\n",
    "        \"\"\"Generate binary targets for mortality, tumor grade, IDH, MGMT\"\"\"\n",
    "        targets = {}\n",
    "        # Mortality\n",
    "        surv = df[df['survival'].notna() & df['patient_status'].notna()].copy()\n",
    "        if len(surv):\n",
    "            surv['mortality_6mo'] = ((surv['patient_status']==2)&(surv['survival']<=6)).astype(int)\n",
    "            surv['mortality_1yr'] = ((surv['patient_status']==2)&(surv['survival']<=12)).astype(int)\n",
    "            surv['mortality_2yr'] = ((surv['patient_status']==2)&(surv['survival']<=24)).astype(int)\n",
    "            targets['mortality'] = {'data': surv,\n",
    "                                   'targets':['mortality_6mo','mortality_1yr','mortality_2yr'],\n",
    "                                   'descriptions':['6mo Mortality','1yr Mortality','2yr Mortality']}\n",
    "        # Tumor\n",
    "        tumor = df[df['methylation_class'].notna()].copy()\n",
    "        if len(tumor):\n",
    "            terms = ['glioblastoma','anaplastic','high grade','grade iv','grade 4','gbm']\n",
    "            tumor['high_grade'] = tumor['methylation_class'].str.lower().str.contains('|'.join(terms), na=False).astype(int)\n",
    "            targets['tumor'] = {'data': tumor, 'targets':['high_grade'], 'descriptions':['High vs Low Grade']}\n",
    "        # IDH\n",
    "        idh = self._create_idh_targets(df)\n",
    "        if idh is not None and len(idh):\n",
    "            targets['idh'] = {'data': idh, 'targets':['idh_binary'], 'descriptions':['IDH Mutation']}\n",
    "        # MGMT\n",
    "        mgmt = self._create_mgmt_targets(df)\n",
    "        if mgmt is not None and len(mgmt):\n",
    "            targets['mgmt'] = {'data': mgmt, 'targets':['mgmt_binary'], 'descriptions':['MGMT Methylation']}\n",
    "        return targets\n",
    "\n",
    "    def _create_idh_targets(self, df):\n",
    "        if 'idh_1_r132h' not in df.columns: return None\n",
    "        idh_df = df.copy()\n",
    "        idh_df['idh_binary'] = np.nan\n",
    "        if 'idh1' in df.columns:\n",
    "            text = df['idh1'].astype(str).str.lower()\n",
    "            patt = ['r132h','r132s','arg132','missense','p.arg132']\n",
    "            mask = text.str.contains('|'.join(patt), na=False)\n",
    "            idh_df.loc[mask, 'idh_binary'] = 1\n",
    "        rem = idh_df['idh_binary'].isna() & idh_df['idh_1_r132h'].notna()\n",
    "        idh_df.loc[rem&(idh_df['idh_1_r132h']==2),'idh_binary']=1\n",
    "        idh_df.loc[rem&(idh_df['idh_1_r132h']==1),'idh_binary']=0\n",
    "        idh_df.loc[idh_df['idh_1_r132h']==3,'idh_binary']=np.nan\n",
    "        return idh_df[idh_df['idh_binary'].notna()].copy()\n",
    "\n",
    "    def _create_mgmt_targets(self, df):\n",
    "        if 'mgmt' not in df.columns: return None\n",
    "        mg = df[df['mgmt'].notna()].copy()\n",
    "        mg['mgmt_binary'] = np.nan\n",
    "        mg.loc[mg['mgmt']==1,'mgmt_binary']=1\n",
    "        mg.loc[mg['mgmt']==2,'mgmt_binary']=0\n",
    "        mg.loc[mg['mgmt']==3,'mgmt_binary']=np.nan\n",
    "        return mg[mg['mgmt_binary'].notna()].copy()\n",
    "\n",
    "    def select_features(self, df):\n",
    "        clinical = ['age','sex','race','ethnicity','gtr']\n",
    "        molecular = ['mgmt_pyro','atrx','p53','braf_v600','h3k27m','gfap','tumor','hg_glioma']\n",
    "        image = [c for c in df.columns if c.startswith('feature_')]\n",
    "        allf = clinical + molecular + image\n",
    "        return [f for f in allf if f in df.columns]\n",
    "\n",
    "    def preprocess_data(self, df, features, target):\n",
    "        data = df[features+[target]].dropna(subset=[target]).copy()\n",
    "        if len(data)<15: return None,None,\"Insufficient data\"\n",
    "        # Encode categoricals\n",
    "        cats = data.select_dtypes(include=['object']).columns.tolist()\n",
    "        if target in cats: cats.remove(target)\n",
    "        for c in cats:\n",
    "            if c in features:\n",
    "                le = LabelEncoder(); data[c]=le.fit_transform(data[c].astype(str))\n",
    "        # Fill missing\n",
    "        nums = [f for f in features if f in data.select_dtypes(include=[np.number]).columns]\n",
    "        for c in nums:\n",
    "            if data[c].isna().sum(): data[c]=data[c].fillna(data[c].median())\n",
    "        # Drop features >50% missing\n",
    "        miss = data[features].isna().mean()\n",
    "        keep = miss[miss<=0.5].index.tolist()\n",
    "        if len(keep)<len(features): features=keep; data=data[keep+[target]]\n",
    "        X=data[features].values; y=data[target].values\n",
    "        # Class size\n",
    "        uc,counts = np.unique(y,return_counts=True)\n",
    "        if min(counts)<3: return None,None,\"Class too small\"\n",
    "        # Limit features\n",
    "        if X.shape[1]>100:\n",
    "            sel = SelectKBest(f_classif, k=100)\n",
    "            X=sel.fit_transform(X,y)\n",
    "        return X,y,None\n",
    "\n",
    "    def train_and_evaluate_algorithm(self, X_tr, X_te, y_tr, y_te, name, cfg):\n",
    "        try:\n",
    "            model=cfg['model']; scale=cfg['needs_scaling']\n",
    "            if scale:\n",
    "                scaler=RobustScaler((10,90))\n",
    "                X_tr_s=scaler.fit_transform(X_tr)\n",
    "                X_te_s=scaler.transform(X_te)\n",
    "            else:\n",
    "                X_tr_s,X_te_s=X_tr,X_te\n",
    "            # Fit/predict\n",
    "            if name=='TabNet' and TABNET_AVAILABLE:\n",
    "                model.fit(X_tr_s,y_tr, eval_set=[(X_te_s,y_te)], patience=20, max_epochs=100, eval_metric=['auc'], batch_size=min(256,len(X_tr)//4))\n",
    "                y_prob=model.predict_proba(X_te_s)[:,1]; y_pred=(y_prob>0.5).astype(int)\n",
    "            elif name=='XGBoost' and XGBOOST_AVAILABLE:\n",
    "                try: model.fit(X_tr_s,y_tr, eval_set=[(X_te_s,y_te)], verbose=False)\n",
    "                except TypeError: model.fit(X_tr_s,y_tr)\n",
    "                y_pred=model.predict(X_te_s); y_prob=model.predict_proba(X_te_s)[:,1]\n",
    "            else:\n",
    "                model.fit(X_tr_s,y_tr)\n",
    "                y_pred=model.predict(X_te_s)\n",
    "                y_prob=model.predict_proba(X_te_s)[:,1] if hasattr(model,'predict_proba') else y_pred.astype(float)\n",
    "            # Metrics\n",
    "            acc=accuracy_score(y_te,y_pred)\n",
    "            try: aucv=roc_auc_score(y_te,y_prob)\n",
    "            except: aucv=0.5\n",
    "            cm=confusion_matrix(y_te,y_pred)\n",
    "            if cm.shape==(2,2): tn,fp,fn,tp=cm.ravel(); sens=tp/(tp+fn); spec=tn/(tn+fp); ppv=tp/(tp+fp); npv=tn/(tn+fn)\n",
    "            else: sens=spec=ppv=npv=0\n",
    "            bal=(sens+spec)/2\n",
    "            f1=2*(ppv*sens)/(ppv+sens) if (ppv+sens)>0 else 0\n",
    "            return {'accuracy':acc,'auc':aucv,'sensitivity':sens,'specificity':spec,'ppv':ppv,'npv':npv,'balanced_accuracy':bal,'f1_score':f1,'confusion_matrix':cm,'n_test':len(y_te),'scaling_used':scale}\n",
    "        except Exception as e:\n",
    "            print(f\"{name} failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def run_prediction_task(self, X, y, task, dataset, algs):\n",
    "        print(f\"\\n=== {task} - {dataset} ===\")\n",
    "        try:\n",
    "            X_tr,X_te,y_tr,y_te=train_test_split(X,y,test_size=0.25,random_state=42,stratify=y)\n",
    "        except:\n",
    "            X_tr,X_te,y_tr,y_te=train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "        print(f\"Train/Test: {len(X_tr)}/{len(X_te)} samples\")\n",
    "        results={}\n",
    "        for name,cfg in algs.items():\n",
    "            print(f\"Testing {name}...\")\n",
    "            hold=self.train_and_evaluate_algorithm(X_tr,X_te,y_tr,y_te,name,cfg)\n",
    "            if hold is None: continue\n",
    "            # CV\n",
    "            cv=self.cross_validate_algorithm(X,y,name,cfg)\n",
    "            if cv is None: cv={'cv_auc_mean':hold['auc'],'cv_auc_std':0,'cv_auc_ci_lower':hold['auc'],'cv_auc_ci_upper':hold['auc'],'cv_accuracy_mean':hold['accuracy'],'cv_accuracy_std':0,'cv_folds':1,'cv_stability':'SINGLE'}\n",
    "            combined={**hold,**cv}\n",
    "            results[name]=combined\n",
    "        return results\n",
    "\n",
    "    def cross_validate_algorithm(self, X,y,name,cfg,cv_folds=5):\n",
    "        try:\n",
    "            cv=StratifiedKFold(n_splits=cv_folds,shuffle=True,random_state=42)\n",
    "            aucs=[]; accs=[]\n",
    "            for tr,va in cv.split(X,y):\n",
    "                res=self.train_and_evaluate_algorithm(X[tr],X[va],y[tr],y[va],name,cfg)\n",
    "                aucs.append(res['auc'] if res else 0.5); accs.append(res['accuracy'] if res else 0.5)\n",
    "            m_auc=np.mean(aucs); s_auc=np.std(aucs)\n",
    "            from scipy.stats import t\n",
    "            crit=t.ppf(0.975,len(aucs)-1)\n",
    "            margin=crit*(s_auc/np.sqrt(len(aucs)))\n",
    "            return {'cv_auc_mean':m_auc,'cv_auc_std':s_auc,'cv_auc_ci_lower':max(0,m_auc-margin),'cv_auc_ci_upper':min(1,m_auc+margin),'cv_accuracy_mean':np.mean(accs),'cv_accuracy_std':np.std(accs),'cv_folds':cv_folds,'cv_stability':('HIGH' if s_auc/m_auc<0.05 else 'STABLE' if s_auc/m_auc<0.10 else 'VAR')}\n",
    "        except Exception as e:\n",
    "            print(f\"CV failed for {name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Validation checks omitted for brevity; assume same as before\n",
    "\n",
    "    def _get_safe_features(self, features, target):\n",
    "        unsafe={'idh_binary':['idh'],'mgmt_binary':['mgmt'],'high_grade':[],'mortality_6mo':[],'mortality_1yr':[],'mortality_2yr':[]}\n",
    "        pats=unsafe.get(target,[])\n",
    "        return [f for f in features if not any(p.lower() in f.lower() for p in pats)]\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate full on-console report\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to report\")\n",
    "            return\n",
    "        print(\"COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        self._generate_executive_summary()\n",
    "        self._generate_detailed_results_table()\n",
    "        self._generate_best_performers_analysis()\n",
    "        self._generate_validation_summary()\n",
    "        self._generate_clinical_recommendations()\n",
    "        self._generate_publication_strategy()\n",
    "\n",
    "    def generate_publication_document(self, dataset_name):\n",
    "        \"\"\"Generate text and CSV report for one dataset\"\"\"\n",
    "        if dataset_name not in self.results:\n",
    "            print(f\"No results for {dataset_name}\")\n",
    "            return\n",
    "        # Build text report\n",
    "        lines=[f\"REPORT for {dataset_name}\",\"=\"*50,\"\"]\n",
    "        total=sum(len(t['results']) for t in self.results[dataset_name].values())\n",
    "        lines.append(f\"Total combinations: {total}\")\n",
    "        txt=f\"{dataset_name}_analysis_report.txt\"\n",
    "        with open(txt,'w',encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        print(f\"Text report: {txt}\")\n",
    "        # Build CSV\n",
    "        rows=[]\n",
    "        for t in self.results[dataset_name].values():\n",
    "            for alg,res in t['results'].items():\n",
    "                rows.append({'Dataset':dataset_name,'Task':t['task_name'],'Algorithm':alg,'AUC':res['auc'],'Accuracy':res['accuracy'],'Sensitivity':res['sensitivity'],'Specificity':res['specificity']})\n",
    "        df=pd.DataFrame(rows)\n",
    "        csv=f\"{dataset_name}_analysis_report.csv\"\n",
    "        df.to_csv(csv,index=False)\n",
    "        print(f\"CSV report: {csv}\")\n",
    "\n",
    "    def run_comprehensive_analysis(self):\n",
    "        \"\"\"Run all datasets and generate reports\"\"\"\n",
    "        algs=self.get_ml_algorithms()\n",
    "        for ds,path in self.datasets.items():\n",
    "            if not os.path.exists(path): continue\n",
    "            print(f\"\\n=== Processing {ds} ===\")\n",
    "            val=self.run_validation_checks(ds,path)\n",
    "            self.validation_results[ds]=val\n",
    "            if val.get('overall',{}).get('status')=='FAIL': continue\n",
    "            df=pd.read_csv(path)\n",
    "            targets=self.create_all_targets(df)\n",
    "            feats=self.select_features(df)\n",
    "            ds_results={}\n",
    "            for cat,info in targets.items():\n",
    "                for i,targ in enumerate(info['targets']):\n",
    "                    X,y,err=self.preprocess_data(info['data'],self._get_safe_features(feats,targ),targ)\n",
    "                    if X is None: continue\n",
    "                    res=self.run_prediction_task(X,y,info['descriptions'][i],ds,algs)\n",
    "                    if res: ds_results[f\"{cat}_{targ}\"]={'task_name':info['descriptions'][i],'results':res}\n",
    "            if ds_results: self.results[ds]=ds_results; print(f\"Completed {ds}\")\n",
    "            self.generate_publication_document(ds)\n",
    "        return self.results\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting analysis system...\")\n",
    "    anal=NeurosurgicalAIAnalyzer()\n",
    "    res=anal.run_comprehensive_analysis()\n",
    "    print(\"Analysis complete.\")\n",
    "    return anal\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
