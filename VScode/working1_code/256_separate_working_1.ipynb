{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77990fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE NEUROSURGICAL AI ANALYSIS SYSTEM\n",
      "======================================================================\n",
      "GOAL: Comprehensive evaluation of CNN architectures and ML algorithms\n",
      "SCOPE: 5 CNNs √ó Multiple Algorithms √ó 6 Clinical Tasks\n",
      "OUTPUT: Clinical-ready recommendations for your team and PI\n",
      "======================================================================\n",
      "CHECKING DATA FILE PATHS:\n",
      "==================================================\n",
      "ConvNext            : EXISTS\n",
      "ViT                 : EXISTS\n",
      "ResNet50_Pretrained : EXISTS\n",
      "ResNet50_ImageNet   : EXISTS\n",
      "EfficientNet        : EXISTS\n",
      "==================================================\n",
      "\n",
      "Found 5/5 data files\n",
      "SUCCESS: All data files found!\n",
      "\n",
      "COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\n",
      "======================================================================\n",
      "Testing 5 CNNs √ó Multiple ML Algorithms √ó 6 Clinical Tasks\n",
      "Target: Clinical-grade performance (AUC >= 0.80)\n",
      "======================================================================\n",
      "\n",
      "AVAILABLE ALGORITHMS (6):\n",
      "   TabPFN: Transformer-based Few-Shot Learning\n",
      "   XGBoost: Optimized Gradient Boosting\n",
      "   TabNet: Optimized Attention-based Neural Network\n",
      "   RandomForest: Optimized Ensemble Decision Trees\n",
      "   LogisticRegression: Regularized Linear Model with ElasticNet\n",
      "   SVM: Support Vector Machine with RBF Kernel\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ConvNext DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ConvNext\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_separate_256d.csv\n",
      "Dataset shape: (532, 356)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 13\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.635 (95% CI: 0.474-0.797)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.688\n",
      "   CROSS-VAL: AUC=0.743 (95% CI: 0.605-0.881)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.70588\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84615\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.364, AUC=0.706\n",
      "   CROSS-VAL: AUC=0.855 (95% CI: 0.781-0.928)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.680 (95% CI: 0.556-0.805)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.421-0.731)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.647\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.402-0.751)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.479-0.721)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.600\n",
      "   CROSS-VAL: AUC=0.627 (95% CI: 0.453-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.59167\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.7125\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.74286\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.85714\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.592\n",
      "   CROSS-VAL: AUC=0.760 (95% CI: 0.692-0.828)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.458\n",
      "   CROSS-VAL: AUC=0.588 (95% CI: 0.423-0.753)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.456-0.519)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.409, AUC=0.425\n",
      "   CROSS-VAL: AUC=0.443 (95% CI: 0.304-0.581)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.335-0.860)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.660\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.449-0.890)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.73611\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.97619\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.730-0.989)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.456-0.861)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.608 (95% CI: 0.353-0.864)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.375\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.083-0.917)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.943\n",
      "   CROSS-VAL: AUC=0.921 (95% CI: 0.866-0.976)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.875 (95% CI: 0.813-0.937)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.98495\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9021\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.97565\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.952\n",
      "   CROSS-VAL: AUC=0.933 (95% CI: 0.884-0.983)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.899 (95% CI: 0.835-0.962)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.885 (95% CI: 0.807-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.917\n",
      "   CROSS-VAL: AUC=0.887 (95% CI: 0.810-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.909\n",
      "   CROSS-VAL: AUC=0.808 (95% CI: 0.746-0.870)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.752-0.894)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82197\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61429\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.72571\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.87143\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.87059\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.774 (95% CI: 0.653-0.894)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.760, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.833 (95% CI: 0.746-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.631-0.876)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.727\n",
      "   CROSS-VAL: AUC=0.696 (95% CI: 0.610-0.781)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ConvNext\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.626\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.510-0.627)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.698, AUC=0.685\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.490-0.707)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.58824\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.72851\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.65385\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.66824\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.65176\n",
      "   HOLDOUT: Accuracy=0.566, AUC=0.679\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.603-0.714)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.662\n",
      "   CROSS-VAL: AUC=0.593 (95% CI: 0.494-0.691)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.504 (95% CI: 0.481-0.526)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.390\n",
      "   CROSS-VAL: AUC=0.484 (95% CI: 0.339-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ConvNext: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ViT DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ViT\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/vit_base_data/vit_base_cleaned_patient_features_separate_256d.csv\n",
      "Dataset shape: (532, 356)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 13\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.635 (95% CI: 0.474-0.797)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.688\n",
      "   CROSS-VAL: AUC=0.743 (95% CI: 0.605-0.881)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.70588\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84615\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.364, AUC=0.706\n",
      "   CROSS-VAL: AUC=0.855 (95% CI: 0.781-0.928)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.680 (95% CI: 0.556-0.805)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.421-0.731)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.647\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.402-0.751)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.479-0.721)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.600\n",
      "   CROSS-VAL: AUC=0.627 (95% CI: 0.453-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.59167\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.7125\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.74286\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.85714\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.592\n",
      "   CROSS-VAL: AUC=0.760 (95% CI: 0.692-0.828)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.458\n",
      "   CROSS-VAL: AUC=0.588 (95% CI: 0.423-0.753)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.456-0.519)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.409, AUC=0.425\n",
      "   CROSS-VAL: AUC=0.443 (95% CI: 0.304-0.581)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.335-0.860)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.660\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.449-0.890)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.73611\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.97619\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.730-0.989)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.456-0.861)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.608 (95% CI: 0.353-0.864)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.375\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.083-0.917)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.943\n",
      "   CROSS-VAL: AUC=0.921 (95% CI: 0.866-0.976)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.875 (95% CI: 0.813-0.937)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.98495\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9021\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.97565\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.952\n",
      "   CROSS-VAL: AUC=0.933 (95% CI: 0.884-0.983)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.899 (95% CI: 0.835-0.962)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.885 (95% CI: 0.807-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.917\n",
      "   CROSS-VAL: AUC=0.887 (95% CI: 0.810-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.909\n",
      "   CROSS-VAL: AUC=0.808 (95% CI: 0.746-0.870)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.752-0.894)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82197\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61429\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.72571\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.87143\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.87059\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.774 (95% CI: 0.653-0.894)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.760, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.833 (95% CI: 0.746-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.631-0.876)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.727\n",
      "   CROSS-VAL: AUC=0.696 (95% CI: 0.610-0.781)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ViT\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.626\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.510-0.627)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.698, AUC=0.685\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.490-0.707)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.58824\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.72851\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.65385\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.66824\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.65176\n",
      "   HOLDOUT: Accuracy=0.566, AUC=0.679\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.603-0.714)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.662\n",
      "   CROSS-VAL: AUC=0.593 (95% CI: 0.494-0.691)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.504 (95% CI: 0.481-0.526)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.390\n",
      "   CROSS-VAL: AUC=0.484 (95% CI: 0.339-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ViT: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ResNet50_Pretrained DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ResNet50_Pretrained\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/pretrained_resnet50_data/pretrained_resnet50_cleaned_patient_features_separate_256d.csv\n",
      "Dataset shape: (532, 356)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 13\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.635 (95% CI: 0.474-0.797)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.688\n",
      "   CROSS-VAL: AUC=0.743 (95% CI: 0.605-0.881)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.70588\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84615\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.364, AUC=0.706\n",
      "   CROSS-VAL: AUC=0.855 (95% CI: 0.781-0.928)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.680 (95% CI: 0.556-0.805)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.421-0.731)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.647\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.402-0.751)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.479-0.721)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.600\n",
      "   CROSS-VAL: AUC=0.627 (95% CI: 0.453-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.59167\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.7125\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.74286\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.85714\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.592\n",
      "   CROSS-VAL: AUC=0.760 (95% CI: 0.692-0.828)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.458\n",
      "   CROSS-VAL: AUC=0.588 (95% CI: 0.423-0.753)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.456-0.519)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.409, AUC=0.425\n",
      "   CROSS-VAL: AUC=0.443 (95% CI: 0.304-0.581)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.335-0.860)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.660\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.449-0.890)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.73611\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.97619\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.730-0.989)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.456-0.861)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.608 (95% CI: 0.353-0.864)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.375\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.083-0.917)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.943\n",
      "   CROSS-VAL: AUC=0.921 (95% CI: 0.866-0.976)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.875 (95% CI: 0.813-0.937)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.98495\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9021\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.97565\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.952\n",
      "   CROSS-VAL: AUC=0.933 (95% CI: 0.884-0.983)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.899 (95% CI: 0.835-0.962)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.885 (95% CI: 0.807-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.917\n",
      "   CROSS-VAL: AUC=0.887 (95% CI: 0.810-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.909\n",
      "   CROSS-VAL: AUC=0.808 (95% CI: 0.746-0.870)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.752-0.894)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82197\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61429\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.72571\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.87143\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.87059\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.774 (95% CI: 0.653-0.894)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.760, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.833 (95% CI: 0.746-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.631-0.876)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.727\n",
      "   CROSS-VAL: AUC=0.696 (95% CI: 0.610-0.781)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ResNet50_Pretrained\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.626\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.510-0.627)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.698, AUC=0.685\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.490-0.707)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.58824\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.72851\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.65385\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.66824\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.65176\n",
      "   HOLDOUT: Accuracy=0.566, AUC=0.679\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.603-0.714)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.662\n",
      "   CROSS-VAL: AUC=0.593 (95% CI: 0.494-0.691)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.504 (95% CI: 0.481-0.526)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.390\n",
      "   CROSS-VAL: AUC=0.484 (95% CI: 0.339-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ResNet50_Pretrained: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING ResNet50_ImageNet DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR ResNet50_ImageNet\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/imagenet_resnet50_data/imagenet_resnet50_cleaned_patient_features_separate_256d.csv\n",
      "Dataset shape: (532, 356)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 13\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.635 (95% CI: 0.474-0.797)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.688\n",
      "   CROSS-VAL: AUC=0.743 (95% CI: 0.605-0.881)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.70588\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84615\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.364, AUC=0.706\n",
      "   CROSS-VAL: AUC=0.855 (95% CI: 0.781-0.928)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.680 (95% CI: 0.556-0.805)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.421-0.731)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.647\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.402-0.751)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.479-0.721)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.600\n",
      "   CROSS-VAL: AUC=0.627 (95% CI: 0.453-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.59167\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.7125\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.74286\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.85714\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.592\n",
      "   CROSS-VAL: AUC=0.760 (95% CI: 0.692-0.828)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.458\n",
      "   CROSS-VAL: AUC=0.588 (95% CI: 0.423-0.753)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.456-0.519)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.409, AUC=0.425\n",
      "   CROSS-VAL: AUC=0.443 (95% CI: 0.304-0.581)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.335-0.860)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.660\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.449-0.890)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.73611\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.97619\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.730-0.989)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.456-0.861)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.608 (95% CI: 0.353-0.864)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.375\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.083-0.917)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.943\n",
      "   CROSS-VAL: AUC=0.921 (95% CI: 0.866-0.976)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.875 (95% CI: 0.813-0.937)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.98495\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9021\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.97565\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.952\n",
      "   CROSS-VAL: AUC=0.933 (95% CI: 0.884-0.983)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.899 (95% CI: 0.835-0.962)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.885 (95% CI: 0.807-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.917\n",
      "   CROSS-VAL: AUC=0.887 (95% CI: 0.810-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.909\n",
      "   CROSS-VAL: AUC=0.808 (95% CI: 0.746-0.870)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.752-0.894)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82197\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61429\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.72571\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.87143\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.87059\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.774 (95% CI: 0.653-0.894)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.760, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.833 (95% CI: 0.746-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.631-0.876)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.727\n",
      "   CROSS-VAL: AUC=0.696 (95% CI: 0.610-0.781)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - ResNet50_ImageNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.626\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.510-0.627)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.698, AUC=0.685\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.490-0.707)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.58824\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.72851\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.65385\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.66824\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.65176\n",
      "   HOLDOUT: Accuracy=0.566, AUC=0.679\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.603-0.714)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.662\n",
      "   CROSS-VAL: AUC=0.593 (95% CI: 0.494-0.691)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.504 (95% CI: 0.481-0.526)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.390\n",
      "   CROSS-VAL: AUC=0.484 (95% CI: 0.339-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS ResNet50_ImageNet: 6 tasks completed successfully\n",
      "\n",
      "======================================================================\n",
      "ANALYZING EfficientNet DATASET\n",
      "======================================================================\n",
      "\n",
      "üîç VALIDATION CHECKS FOR EfficientNet\n",
      "==================================================\n",
      "Loading data from: /Users/joi263/Documents/MultimodalTabData/data/efficientnet_data/efficientnet_cleaned_patient_features_separate_256d.csv\n",
      "Dataset shape: (532, 356)\n",
      "============================================================\n",
      "CREATING ALL PREDICTION TARGETS\n",
      "============================================================\n",
      "MORTALITY TARGETS:\n",
      "   Patients: 86\n",
      "   6-month: 19/86 (22.1%)\n",
      "   1-year: 38/86 (44.2%)\n",
      "   2-year: 70/86 (81.4%)\n",
      "\n",
      "TUMOR CLASSIFICATION TARGETS:\n",
      "   Patients: 241\n",
      "   High-grade: 129/241 (53.5%)\n",
      "\n",
      "IDH MUTATION TARGETS:\n",
      "   Patients: 198\n",
      "   IDH Mutant: 174.0/198 (87.9%)\n",
      "\n",
      "MGMT METHYLATION TARGETS:\n",
      "   Patients: 212\n",
      "   MGMT Methylated: 84.0/212 (39.6%)\n",
      "Available features: 13\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 6-Month Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "6-Month Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 21.9% (train), 22.7% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.694\n",
      "   CROSS-VAL: AUC=0.635 (95% CI: 0.474-0.797)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.688\n",
      "   CROSS-VAL: AUC=0.743 (95% CI: 0.605-0.881)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.70588\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84615\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.94231\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.7619\n",
      "   HOLDOUT: Accuracy=0.364, AUC=0.706\n",
      "   CROSS-VAL: AUC=0.855 (95% CI: 0.781-0.928)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.741\n",
      "   CROSS-VAL: AUC=0.680 (95% CI: 0.556-0.805)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.773, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.421-0.731)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.682, AUC=0.647\n",
      "   CROSS-VAL: AUC=0.576 (95% CI: 0.402-0.751)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 1-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "1-Year Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 43.8% (train), 45.5% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.542\n",
      "   CROSS-VAL: AUC=0.600 (95% CI: 0.479-0.721)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.600\n",
      "   CROSS-VAL: AUC=0.627 (95% CI: 0.453-0.800)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.59167\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.7125\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.70833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.74286\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.85714\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.592\n",
      "   CROSS-VAL: AUC=0.760 (95% CI: 0.692-0.828)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.500, AUC=0.458\n",
      "   CROSS-VAL: AUC=0.588 (95% CI: 0.423-0.753)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.487 (95% CI: 0.456-0.519)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.409, AUC=0.425\n",
      "   CROSS-VAL: AUC=0.443 (95% CI: 0.304-0.581)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: 2-Year Mortality\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "2-Year Mortality - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 64 samples\n",
      "   Testing: 22 samples\n",
      "   Positive rate: 81.2% (train), 81.8% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.722\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.335-0.860)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.818, AUC=0.660\n",
      "   CROSS-VAL: AUC=0.670 (95% CI: 0.449-0.890)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.73611\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.69048\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.97619\n",
      "   HOLDOUT: Accuracy=0.727, AUC=0.736\n",
      "   CROSS-VAL: AUC=0.860 (95% CI: 0.730-0.989)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.456-0.861)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.545, AUC=0.708\n",
      "   CROSS-VAL: AUC=0.608 (95% CI: 0.353-0.864)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.591, AUC=0.375\n",
      "   CROSS-VAL: AUC=0.500 (95% CI: 0.083-0.917)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: High-Grade vs Low-Grade\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "High-Grade vs Low-Grade - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 180 samples\n",
      "   Testing: 61 samples\n",
      "   Positive rate: 53.3% (train), 54.1% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.943\n",
      "   CROSS-VAL: AUC=0.921 (95% CI: 0.866-0.976)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.860\n",
      "   CROSS-VAL: AUC=0.875 (95% CI: 0.813-0.937)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.95238\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.98495\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_val_0_auc = 0.88462\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9021\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_auc = 0.91958\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.97565\n",
      "   HOLDOUT: Accuracy=0.820, AUC=0.952\n",
      "   CROSS-VAL: AUC=0.933 (95% CI: 0.884-0.983)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       EXCELLENT clinical performance (robust across CV)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.803, AUC=0.897\n",
      "   CROSS-VAL: AUC=0.899 (95% CI: 0.835-0.962)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.754, AUC=0.899\n",
      "   CROSS-VAL: AUC=0.885 (95% CI: 0.807-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.787, AUC=0.917\n",
      "   CROSS-VAL: AUC=0.887 (95% CI: 0.810-0.964)\n",
      "   STABILITY: STABLE\n",
      "       EXCELLENT clinical performance (some variability)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: IDH Mutation Status\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "IDH Mutation Status - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 148 samples\n",
      "   Testing: 50 samples\n",
      "   Positive rate: 87.8% (train), 88.0% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.909\n",
      "   CROSS-VAL: AUC=0.808 (95% CI: 0.746-0.870)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.823 (95% CI: 0.752-0.894)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (robust across CV)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.82197\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.61429\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.72571\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.87143\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.87059\n",
      "   HOLDOUT: Accuracy=0.880, AUC=0.822\n",
      "   CROSS-VAL: AUC=0.774 (95% CI: 0.653-0.894)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.760, AUC=0.883\n",
      "   CROSS-VAL: AUC=0.833 (95% CI: 0.746-0.921)\n",
      "   STABILITY: STABLE\n",
      "       STRONG clinical performance (some variability)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.830\n",
      "   CROSS-VAL: AUC=0.753 (95% CI: 0.631-0.876)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.720, AUC=0.727\n",
      "   CROSS-VAL: AUC=0.696 (95% CI: 0.610-0.781)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "----------------------------------------\n",
      "TASK: MGMT Promoter Methylation\n",
      "----------------------------------------\n",
      "\n",
      "==================================================\n",
      "MGMT Promoter Methylation - EfficientNet\n",
      "==================================================\n",
      "DATA SPLIT:\n",
      "   Training: 159 samples\n",
      "   Testing: 53 samples\n",
      "   Positive rate: 39.6% (train), 39.6% (test)\n",
      "\n",
      "TESTING TabPFN...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.626\n",
      "   CROSS-VAL: AUC=0.568 (95% CI: 0.510-0.627)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING XGBoost...\n",
      "   HOLDOUT: Accuracy=0.698, AUC=0.685\n",
      "   CROSS-VAL: AUC=0.598 (95% CI: 0.490-0.707)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING TabNet...\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.58824\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.72851\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.65385\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.66824\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.65176\n",
      "   HOLDOUT: Accuracy=0.566, AUC=0.679\n",
      "   CROSS-VAL: AUC=0.658 (95% CI: 0.603-0.714)\n",
      "   STABILITY: STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING RandomForest...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.662\n",
      "   CROSS-VAL: AUC=0.593 (95% CI: 0.494-0.691)\n",
      "   STABILITY: MODERATE VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING LogisticRegression...\n",
      "   HOLDOUT: Accuracy=0.604, AUC=0.500\n",
      "   CROSS-VAL: AUC=0.504 (95% CI: 0.481-0.526)\n",
      "   STABILITY: HIGHLY STABLE\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "TESTING SVM...\n",
      "   HOLDOUT: Accuracy=0.642, AUC=0.390\n",
      "   CROSS-VAL: AUC=0.484 (95% CI: 0.339-0.628)\n",
      "   STABILITY: HIGH VARIABILITY\n",
      "       MODERATE performance (consider more data/optimization)\n",
      "\n",
      "SUCCESS EfficientNet: 6 tasks completed successfully\n",
      "\n",
      "================================================================================\n",
      "üìä COMPREHENSIVE ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "üéØ EXECUTIVE SUMMARY\n",
      "==================================================\n",
      " PERFORMANCE OVERVIEW:\n",
      "   Total algorithm-task combinations: 180\n",
      "   Mean AUC across all tests: 0.696\n",
      "   Best AUC achieved: 0.952\n",
      "   Excellent performance (AUC ‚â• 0.85): 45/180 (25.0%)\n",
      "   Good+ performance (AUC ‚â• 0.75): 55/180 (30.6%)\n",
      "   üöÄ CLINICAL DEPLOYMENT: 45 combinations ready for validation\n",
      "   üèÜ PUBLICATION READY: Exceptional results achieved\n",
      "\n",
      "üìã DETAILED RESULTS TABLE\n",
      "==================================================\n",
      "CNN                  Task                      Algorithm       AUC      Acc      Sens     Spec     Status         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ConvNext             6-Month Mortality         TabPFN          0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         XGBoost         0.688    0.727    0.000    0.941    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         TabNet          0.706    0.364    1.000    0.176    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         RandomForest    0.741    0.591    1.000    0.471    üìà GOOD         \n",
      "ConvNext             6-Month Mortality         LogisticRegression 0.500    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             6-Month Mortality         SVM             0.647    0.682    0.400    0.765    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          TabPFN          0.542    0.591    0.600    0.583    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          XGBoost         0.600    0.545    0.600    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          TabNet          0.592    0.545    1.000    0.167    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          RandomForest    0.458    0.500    0.600    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          LogisticRegression 0.500    0.545    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             1-Year Mortality          SVM             0.425    0.409    0.600    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             2-Year Mortality          TabPFN          0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          XGBoost         0.660    0.818    1.000    0.000    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          TabNet          0.736    0.727    0.722    0.750    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          RandomForest    0.708    0.591    0.500    1.000    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          LogisticRegression 0.708    0.545    0.500    0.750    üìà GOOD         \n",
      "ConvNext             2-Year Mortality          SVM             0.375    0.591    0.556    0.750    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             High-Grade vs Low-Grade   TabPFN          0.943    0.820    0.848    0.786    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   XGBoost         0.860    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   TabNet          0.952    0.820    1.000    0.607    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   RandomForest    0.897    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   LogisticRegression 0.899    0.754    0.909    0.571    üèÜ EXCELLENT    \n",
      "ConvNext             High-Grade vs Low-Grade   SVM             0.917    0.787    0.848    0.714    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       TabPFN          0.909    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       XGBoost         0.883    0.880    0.977    0.167    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       TabNet          0.822    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ConvNext             IDH Mutation Status       RandomForest    0.883    0.760    0.773    0.667    üèÜ EXCELLENT    \n",
      "ConvNext             IDH Mutation Status       LogisticRegression 0.830    0.720    0.750    0.500    ‚úÖ STRONG       \n",
      "ConvNext             IDH Mutation Status       SVM             0.727    0.720    0.727    0.667    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation TabPFN          0.626    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             MGMT Promoter Methylation XGBoost         0.685    0.698    0.524    0.812    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation TabNet          0.679    0.566    0.857    0.375    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation RandomForest    0.662    0.604    0.714    0.531    üìà GOOD         \n",
      "ConvNext             MGMT Promoter Methylation LogisticRegression 0.500    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ConvNext             MGMT Promoter Methylation SVM             0.390    0.642    0.667    0.625    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  6-Month Mortality         TabPFN          0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "ViT                  6-Month Mortality         XGBoost         0.688    0.727    0.000    0.941    üìà GOOD         \n",
      "ViT                  6-Month Mortality         TabNet          0.706    0.364    1.000    0.176    üìà GOOD         \n",
      "ViT                  6-Month Mortality         RandomForest    0.741    0.591    1.000    0.471    üìà GOOD         \n",
      "ViT                  6-Month Mortality         LogisticRegression 0.500    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  6-Month Mortality         SVM             0.647    0.682    0.400    0.765    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          TabPFN          0.542    0.591    0.600    0.583    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          XGBoost         0.600    0.545    0.600    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          TabNet          0.592    0.545    1.000    0.167    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          RandomForest    0.458    0.500    0.600    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          LogisticRegression 0.500    0.545    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  1-Year Mortality          SVM             0.425    0.409    0.600    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  2-Year Mortality          TabPFN          0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ViT                  2-Year Mortality          XGBoost         0.660    0.818    1.000    0.000    üìà GOOD         \n",
      "ViT                  2-Year Mortality          TabNet          0.736    0.727    0.722    0.750    üìà GOOD         \n",
      "ViT                  2-Year Mortality          RandomForest    0.708    0.591    0.500    1.000    üìà GOOD         \n",
      "ViT                  2-Year Mortality          LogisticRegression 0.708    0.545    0.500    0.750    üìà GOOD         \n",
      "ViT                  2-Year Mortality          SVM             0.375    0.591    0.556    0.750    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  High-Grade vs Low-Grade   TabPFN          0.943    0.820    0.848    0.786    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   XGBoost         0.860    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   TabNet          0.952    0.820    1.000    0.607    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   RandomForest    0.897    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   LogisticRegression 0.899    0.754    0.909    0.571    üèÜ EXCELLENT    \n",
      "ViT                  High-Grade vs Low-Grade   SVM             0.917    0.787    0.848    0.714    üèÜ EXCELLENT    \n",
      "ViT                  IDH Mutation Status       TabPFN          0.909    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ViT                  IDH Mutation Status       XGBoost         0.883    0.880    0.977    0.167    üèÜ EXCELLENT    \n",
      "ViT                  IDH Mutation Status       TabNet          0.822    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ViT                  IDH Mutation Status       RandomForest    0.883    0.760    0.773    0.667    üèÜ EXCELLENT    \n",
      "ViT                  IDH Mutation Status       LogisticRegression 0.830    0.720    0.750    0.500    ‚úÖ STRONG       \n",
      "ViT                  IDH Mutation Status       SVM             0.727    0.720    0.727    0.667    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation TabPFN          0.626    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation XGBoost         0.685    0.698    0.524    0.812    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation TabNet          0.679    0.566    0.857    0.375    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation RandomForest    0.662    0.604    0.714    0.531    üìà GOOD         \n",
      "ViT                  MGMT Promoter Methylation LogisticRegression 0.500    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ViT                  MGMT Promoter Methylation SVM             0.390    0.642    0.667    0.625    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         TabPFN          0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "ResNet50_Pretrained  6-Month Mortality         XGBoost         0.688    0.727    0.000    0.941    üìà GOOD         \n",
      "ResNet50_Pretrained  6-Month Mortality         TabNet          0.706    0.364    1.000    0.176    üìà GOOD         \n",
      "ResNet50_Pretrained  6-Month Mortality         RandomForest    0.741    0.591    1.000    0.471    üìà GOOD         \n",
      "ResNet50_Pretrained  6-Month Mortality         LogisticRegression 0.500    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  6-Month Mortality         SVM             0.647    0.682    0.400    0.765    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          TabPFN          0.542    0.591    0.600    0.583    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          XGBoost         0.600    0.545    0.600    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          TabNet          0.592    0.545    1.000    0.167    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          RandomForest    0.458    0.500    0.600    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          LogisticRegression 0.500    0.545    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  1-Year Mortality          SVM             0.425    0.409    0.600    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  2-Year Mortality          TabPFN          0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          XGBoost         0.660    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          TabNet          0.736    0.727    0.722    0.750    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          RandomForest    0.708    0.591    0.500    1.000    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          LogisticRegression 0.708    0.545    0.500    0.750    üìà GOOD         \n",
      "ResNet50_Pretrained  2-Year Mortality          SVM             0.375    0.591    0.556    0.750    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   TabPFN          0.943    0.820    0.848    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   XGBoost         0.860    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   TabNet          0.952    0.820    1.000    0.607    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   RandomForest    0.897    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   LogisticRegression 0.899    0.754    0.909    0.571    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  High-Grade vs Low-Grade   SVM             0.917    0.787    0.848    0.714    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  IDH Mutation Status       TabPFN          0.909    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  IDH Mutation Status       XGBoost         0.883    0.880    0.977    0.167    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  IDH Mutation Status       TabNet          0.822    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       RandomForest    0.883    0.760    0.773    0.667    üèÜ EXCELLENT    \n",
      "ResNet50_Pretrained  IDH Mutation Status       LogisticRegression 0.830    0.720    0.750    0.500    ‚úÖ STRONG       \n",
      "ResNet50_Pretrained  IDH Mutation Status       SVM             0.727    0.720    0.727    0.667    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation TabPFN          0.626    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation XGBoost         0.685    0.698    0.524    0.812    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation TabNet          0.679    0.566    0.857    0.375    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation RandomForest    0.662    0.604    0.714    0.531    üìà GOOD         \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation LogisticRegression 0.500    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_Pretrained  MGMT Promoter Methylation SVM             0.390    0.642    0.667    0.625    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         TabPFN          0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "ResNet50_ImageNet    6-Month Mortality         XGBoost         0.688    0.727    0.000    0.941    üìà GOOD         \n",
      "ResNet50_ImageNet    6-Month Mortality         TabNet          0.706    0.364    1.000    0.176    üìà GOOD         \n",
      "ResNet50_ImageNet    6-Month Mortality         RandomForest    0.741    0.591    1.000    0.471    üìà GOOD         \n",
      "ResNet50_ImageNet    6-Month Mortality         LogisticRegression 0.500    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    6-Month Mortality         SVM             0.647    0.682    0.400    0.765    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          TabPFN          0.542    0.591    0.600    0.583    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          XGBoost         0.600    0.545    0.600    0.500    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          TabNet          0.592    0.545    1.000    0.167    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          RandomForest    0.458    0.500    0.600    0.417    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          LogisticRegression 0.500    0.545    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    1-Year Mortality          SVM             0.425    0.409    0.600    0.250    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    2-Year Mortality          TabPFN          0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          XGBoost         0.660    0.818    1.000    0.000    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          TabNet          0.736    0.727    0.722    0.750    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          RandomForest    0.708    0.591    0.500    1.000    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          LogisticRegression 0.708    0.545    0.500    0.750    üìà GOOD         \n",
      "ResNet50_ImageNet    2-Year Mortality          SVM             0.375    0.591    0.556    0.750    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   TabPFN          0.943    0.820    0.848    0.786    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   XGBoost         0.860    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   TabNet          0.952    0.820    1.000    0.607    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   RandomForest    0.897    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   LogisticRegression 0.899    0.754    0.909    0.571    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    High-Grade vs Low-Grade   SVM             0.917    0.787    0.848    0.714    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    IDH Mutation Status       TabPFN          0.909    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    IDH Mutation Status       XGBoost         0.883    0.880    0.977    0.167    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    IDH Mutation Status       TabNet          0.822    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       RandomForest    0.883    0.760    0.773    0.667    üèÜ EXCELLENT    \n",
      "ResNet50_ImageNet    IDH Mutation Status       LogisticRegression 0.830    0.720    0.750    0.500    ‚úÖ STRONG       \n",
      "ResNet50_ImageNet    IDH Mutation Status       SVM             0.727    0.720    0.727    0.667    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation TabPFN          0.626    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation XGBoost         0.685    0.698    0.524    0.812    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation TabNet          0.679    0.566    0.857    0.375    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation RandomForest    0.662    0.604    0.714    0.531    üìà GOOD         \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation LogisticRegression 0.500    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "ResNet50_ImageNet    MGMT Promoter Methylation SVM             0.390    0.642    0.667    0.625    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         6-Month Mortality         TabPFN          0.694    0.773    0.000    1.000    üìà GOOD         \n",
      "EfficientNet         6-Month Mortality         XGBoost         0.688    0.727    0.000    0.941    üìà GOOD         \n",
      "EfficientNet         6-Month Mortality         TabNet          0.706    0.364    1.000    0.176    üìà GOOD         \n",
      "EfficientNet         6-Month Mortality         RandomForest    0.741    0.591    1.000    0.471    üìà GOOD         \n",
      "EfficientNet         6-Month Mortality         LogisticRegression 0.500    0.773    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         6-Month Mortality         SVM             0.647    0.682    0.400    0.765    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          TabPFN          0.542    0.591    0.600    0.583    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          XGBoost         0.600    0.545    0.600    0.500    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          TabNet          0.592    0.545    1.000    0.167    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          RandomForest    0.458    0.500    0.600    0.417    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          LogisticRegression 0.500    0.545    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         1-Year Mortality          SVM             0.425    0.409    0.600    0.250    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         2-Year Mortality          TabPFN          0.722    0.818    1.000    0.000    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          XGBoost         0.660    0.818    1.000    0.000    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          TabNet          0.736    0.727    0.722    0.750    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          RandomForest    0.708    0.591    0.500    1.000    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          LogisticRegression 0.708    0.545    0.500    0.750    üìà GOOD         \n",
      "EfficientNet         2-Year Mortality          SVM             0.375    0.591    0.556    0.750    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         High-Grade vs Low-Grade   TabPFN          0.943    0.820    0.848    0.786    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   XGBoost         0.860    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   TabNet          0.952    0.820    1.000    0.607    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   RandomForest    0.897    0.803    0.848    0.750    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   LogisticRegression 0.899    0.754    0.909    0.571    üèÜ EXCELLENT    \n",
      "EfficientNet         High-Grade vs Low-Grade   SVM             0.917    0.787    0.848    0.714    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       TabPFN          0.909    0.880    1.000    0.000    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       XGBoost         0.883    0.880    0.977    0.167    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       TabNet          0.822    0.880    1.000    0.000    ‚úÖ STRONG       \n",
      "EfficientNet         IDH Mutation Status       RandomForest    0.883    0.760    0.773    0.667    üèÜ EXCELLENT    \n",
      "EfficientNet         IDH Mutation Status       LogisticRegression 0.830    0.720    0.750    0.500    ‚úÖ STRONG       \n",
      "EfficientNet         IDH Mutation Status       SVM             0.727    0.720    0.727    0.667    üìà GOOD         \n",
      "EfficientNet         MGMT Promoter Methylation TabPFN          0.626    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation XGBoost         0.685    0.698    0.524    0.812    üìà GOOD         \n",
      "EfficientNet         MGMT Promoter Methylation TabNet          0.679    0.566    0.857    0.375    üìà GOOD         \n",
      "EfficientNet         MGMT Promoter Methylation RandomForest    0.662    0.604    0.714    0.531    üìà GOOD         \n",
      "EfficientNet         MGMT Promoter Methylation LogisticRegression 0.500    0.604    0.000    1.000    ‚ö†Ô∏è MODERATE    \n",
      "EfficientNet         MGMT Promoter Methylation SVM             0.390    0.642    0.667    0.625    ‚ö†Ô∏è MODERATE    \n",
      "\n",
      "üèÜ BEST PERFORMERS BY TASK\n",
      "==================================================\n",
      "6-Month Mortality             : ConvNext + RandomForest (AUC = 0.741) ‚ö†Ô∏è NEEDS WORK\n",
      "1-Year Mortality              : ConvNext + XGBoost (AUC = 0.600) ‚ö†Ô∏è NEEDS WORK\n",
      "2-Year Mortality              : ConvNext + TabNet (AUC = 0.736) ‚ö†Ô∏è NEEDS WORK\n",
      "High-Grade vs Low-Grade       : ConvNext + TabNet (AUC = 0.952) üöÄ DEPLOYMENT READY\n",
      "IDH Mutation Status           : ConvNext + TabPFN (AUC = 0.909) üöÄ DEPLOYMENT READY\n",
      "MGMT Promoter Methylation     : ConvNext + XGBoost (AUC = 0.685) ‚ö†Ô∏è NEEDS WORK\n",
      "\n",
      "VALIDATION SUMMARY\n",
      "==================================================\n",
      "CNN                  Overall    Data       Balance    Features   Samples   \n",
      "---------------------------------------------------------------------------\n",
      "ConvNext             PASS       WARN       PASS       PASS       PASS      \n",
      "ViT                  PASS       WARN       PASS       PASS       PASS      \n",
      "ResNet50_Pretrained  PASS       WARN       PASS       PASS       PASS      \n",
      "ResNet50_ImageNet    PASS       WARN       PASS       PASS       PASS      \n",
      "EfficientNet         PASS       WARN       PASS       PASS       PASS      \n",
      "\n",
      "CLINICAL RECOMMENDATIONS\n",
      "==================================================\n",
      "ALGORITHM PERFORMANCE RANKING:\n",
      "   TabNet: 0.748 mean AUC, 0.952 max AUC (30 tests)\n",
      "   TabPFN: 0.739 mean AUC, 0.943 max AUC (30 tests)\n",
      "   XGBoost: 0.729 mean AUC, 0.883 max AUC (30 tests)\n",
      "   RandomForest: 0.725 mean AUC, 0.897 max AUC (30 tests)\n",
      "   LogisticRegression: 0.656 mean AUC, 0.899 max AUC (30 tests)\n",
      "   SVM: 0.580 mean AUC, 0.917 max AUC (30 tests)\n",
      "\n",
      "CNN ARCHITECTURE RANKING:\n",
      "   ConvNext: 0.696 mean AUC, 0.952 max AUC (36 tests)\n",
      "   ViT: 0.696 mean AUC, 0.952 max AUC (36 tests)\n",
      "   ResNet50_Pretrained: 0.696 mean AUC, 0.952 max AUC (36 tests)\n",
      "   ResNet50_ImageNet: 0.696 mean AUC, 0.952 max AUC (36 tests)\n",
      "   EfficientNet: 0.696 mean AUC, 0.952 max AUC (36 tests)\n",
      "\n",
      "IMPLEMENTATION RECOMMENDATIONS:\n",
      "   55 CNN-algorithm combinations ready for clinical validation\n",
      "   Priority implementation: High-Grade vs Low-Grade using ConvNext + TabNet\n",
      "   Expected performance: 95.2% discrimination accuracy\n",
      "\n",
      "PUBLICATION STRATEGY\n",
      "==================================================\n",
      "\n",
      "Publication document generated successfully!\n",
      "Filename: neurosurgical_ai_analysis_report_20250724_122014.txt\n",
      "Lines written: 421\n",
      "File size: 29244 characters\n",
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "ANALYSIS SUMMARY:\n",
      "   ‚Ä¢ 5 CNN architectures analyzed\n",
      "   ‚Ä¢ 30 clinical tasks evaluated\n",
      "   ‚Ä¢ 180 algorithm-task combinations tested\n",
      "   ‚Ä¢ Comprehensive validation and recommendations generated\n",
      "   ‚Ä¢ Publication-ready document created\n"
     ]
    }
   ],
   "source": [
    "def _generate_executive_summary(self):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        print(\"\\nEXECUTIVE SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        \n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            print(f\"PERFORMANCE OVERVIEW:\")\n",
    "            print(f\"   Total algorithm-task combinations: {total_tests}\")\n",
    "            print(f\"   Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            print(f\"   Best AUC achieved: {max_auc:.3f}\")\n",
    "            print(f\"   Excellent performance (AUC >= 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            print(f\"   Good+ performance (AUC >= 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            \n",
    "            # Clinical readiness assessment\n",
    "            if excellent_tests > 0:\n",
    "                print(f\"   CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                print(f\"   PUBLICATION READY: Exceptional results achieved\")\n",
    "            elif max_auc >= 0.80:\n",
    "                print(f\"   PUBLICATION READY: Strong results achieved\")\n",
    "\n",
    "def _generate_detailed_results_table(self):\n",
    "        \"\"\"Generate detailed results table\"\"\"\n",
    "        print(f\"\\nDETAILED RESULTS TABLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Header\n",
    "        print(f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Acc':<8} {'Sens':<8} {'Spec':<8} {'Status':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"GOOD\"\n",
    "                    else:\n",
    "                        status = \"MODERATE\"\n",
    "                    \n",
    "                    print(f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<8.3f} {sens:<8.3f} {spec:<8.3f} {status:<15}\")\n",
    "\n",
    "def _generate_best_performers_analysis(self):\n",
    "        \"\"\"Generate best performers analysis\"\"\"\n",
    "        print(f\"\\nBEST PERFORMERS BY TASK\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Find best performer for each task across all CNNs\n",
    "        task_best = {}\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            status = \"DEPLOYMENT READY\" if auc >= 0.85 else \"PROMISING\" if auc >= 0.75 else \"NEEDS WORK\"\n",
    "            print(f\"{task_name:<30}: {best['cnn']} + {best['algorithm']} (AUC = {auc:.3f}) {status}\")\n",
    "\n",
    "def _generate_validation_summary(self):\n",
    "        \"\"\"Generate validation summary\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                           accuracy_score, roc_curve, precision_recall_curve, auc)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for optional dependencies\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import torch\n",
    "    TABNET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TABNET_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è TabNet not available. Install with: pip install pytorch-tabnet torch\")\n",
    "\n",
    "class NeurosurgicalAIAnalyzer:\n",
    "    \"\"\"Comprehensive AI analysis system for neurosurgical outcome prediction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Updated paths to match your actual file names\n",
    "        self.datasets = {\n",
    "            'ConvNext': '/Users/joi263/Documents/MultimodalTabData/data/convnext_data/convnext_cleaned_patient_features_separate_256d.csv',\n",
    "            'ViT': '/Users/joi263/Documents/MultimodalTabData/data/vit_base_data/vit_base_cleaned_patient_features_separate_256d.csv',\n",
    "            'ResNet50_Pretrained': '/Users/joi263/Documents/MultimodalTabData/data/pretrained_resnet50_data/pretrained_resnet50_cleaned_patient_features_separate_256d.csv',\n",
    "            'ResNet50_ImageNet': '/Users/joi263/Documents/MultimodalTabData/data/imagenet_resnet50_data/imagenet_resnet50_cleaned_patient_features_separate_256d.csv',\n",
    "            'EfficientNet': '/Users/joi263/Documents/MultimodalTabData/data/efficientnet_data/efficientnet_cleaned_patient_features_separate_256d.csv'\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.validation_results = {}\n",
    "        \n",
    "        # Print file paths for verification\n",
    "        print(\"CHECKING DATA FILE PATHS:\")\n",
    "        print(\"=\"*50)\n",
    "        import os\n",
    "        for cnn_name, file_path in self.datasets.items():\n",
    "            exists = os.path.exists(file_path)\n",
    "            status = \"EXISTS\" if exists else \"NOT FOUND\"\n",
    "            print(f\"{cnn_name:<20}: {status}\")\n",
    "            if not exists:\n",
    "                print(f\"  Expected: {file_path}\")\n",
    "        print(\"=\"*50)\n",
    "        print()\n",
    "        \n",
    "        # Count how many files exist\n",
    "        existing_files = sum(1 for path in self.datasets.values() if os.path.exists(path))\n",
    "        print(f\"Found {existing_files}/{len(self.datasets)} data files\")\n",
    "        \n",
    "        if existing_files == 0:\n",
    "            print(\"ERROR: No data files found!\")\n",
    "            print(\"Please verify the file paths match your actual file locations.\")\n",
    "        elif existing_files < len(self.datasets):\n",
    "            print(f\"WARNING: Only {existing_files} out of {len(self.datasets)} files found.\")\n",
    "            print(\"Analysis will proceed with available datasets.\")\n",
    "        else:\n",
    "            print(\"SUCCESS: All data files found!\")\n",
    "        print()\n",
    "        \n",
    "    def get_ml_algorithms(self):\n",
    "        \"\"\"Initialize all available ML algorithms with optimized parameters\"\"\"\n",
    "        algorithms = {}\n",
    "        \n",
    "        # 1. TabPFN (always available) - Optimized for small biomedical datasets\n",
    "        algorithms['TabPFN'] = {\n",
    "            'model': TabPFNClassifier(device='cpu'),  # Only use valid parameters\n",
    "            'needs_scaling': False,\n",
    "            'description': 'Transformer-based Few-Shot Learning'\n",
    "        }\n",
    "        \n",
    "        # 2. XGBoost (if available) - Tuned for biomedical data\n",
    "        if XGBOOST_AVAILABLE:\n",
    "            algorithms['XGBoost'] = {\n",
    "                'model': xgb.XGBClassifier(\n",
    "                    n_estimators=300,  # Increased for better performance\n",
    "                    max_depth=4,       # Reduced to prevent overfitting on small datasets\n",
    "                    learning_rate=0.05, # Lower for better generalization\n",
    "                    subsample=0.8,     # Add regularization\n",
    "                    colsample_bytree=0.8,\n",
    "                    min_child_weight=3, # Prevent overfitting\n",
    "                    reg_alpha=1,       # L1 regularization\n",
    "                    reg_lambda=1,      # L2 regularization\n",
    "                    random_state=42,\n",
    "                    eval_metric='logloss',\n",
    "                    use_label_encoder=False  # Suppress warnings\n",
    "                ),\n",
    "                'needs_scaling': False,\n",
    "                'description': 'Optimized Gradient Boosting'\n",
    "            }\n",
    "        \n",
    "        # 3. TabNet (if available) - Tuned for tabular biomedical data\n",
    "        if TABNET_AVAILABLE:\n",
    "            algorithms['TabNet'] = {\n",
    "                'model': TabNetClassifier(\n",
    "                    n_d=64, n_a=64,    # Increased capacity\n",
    "                    n_steps=5,         # More decision steps\n",
    "                    gamma=1.5,         # Stronger feature selection\n",
    "                    lambda_sparse=1e-4, # Lighter sparsity penalty\n",
    "                    optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=0.01, weight_decay=1e-5),\n",
    "                    mask_type=\"entmax\",\n",
    "                    scheduler_params={\"step_size\": 20, \"gamma\": 0.8},\n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    verbose=0,\n",
    "                    seed=42\n",
    "                ),\n",
    "                'needs_scaling': True,  # TabNet benefits from scaling\n",
    "                'description': 'Optimized Attention-based Neural Network'\n",
    "            }\n",
    "        \n",
    "        # 4. Random Forest (always available) - Tuned for biomedical features\n",
    "        algorithms['RandomForest'] = {\n",
    "            'model': RandomForestClassifier(\n",
    "                n_estimators=500,   # Increased for stability\n",
    "                max_depth=8,        # Moderate depth to prevent overfitting\n",
    "                min_samples_split=10, # Higher to prevent overfitting\n",
    "                min_samples_leaf=5,   # Higher to ensure leaf reliability\n",
    "                max_features='sqrt',  # Good default for classification\n",
    "                bootstrap=True,\n",
    "                oob_score=True,     # Out-of-bag validation\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1           # Use all cores\n",
    "            ),\n",
    "            'needs_scaling': False,\n",
    "            'description': 'Optimized Ensemble Decision Trees'\n",
    "        }\n",
    "        \n",
    "        # 5. Logistic Regression (always available) - Tuned with regularization\n",
    "        algorithms['LogisticRegression'] = {\n",
    "            'model': LogisticRegression(\n",
    "                penalty='elasticnet',  # Combines L1 and L2 regularization\n",
    "                l1_ratio=0.5,         # Balance between L1 and L2\n",
    "                C=0.1,                # Strong regularization for small datasets\n",
    "                solver='saga',        # Supports elasticnet\n",
    "                max_iter=2000,        # More iterations for convergence\n",
    "                random_state=42,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'needs_scaling': True,  # CRITICAL for logistic regression\n",
    "            'description': 'Regularized Linear Model with ElasticNet'\n",
    "        }\n",
    "        \n",
    "        # 6. Support Vector Machine - Added as bonus strong performer\n",
    "        algorithms['SVM'] = {\n",
    "            'model': SVC(\n",
    "                kernel='rbf',\n",
    "                C=1.0,                # Balanced regularization\n",
    "                gamma='scale',        # Adaptive gamma\n",
    "                probability=True,     # Enable probability estimates\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            'needs_scaling': True,    # CRITICAL for SVM\n",
    "            'description': 'Support Vector Machine with RBF Kernel'\n",
    "        }\n",
    "        \n",
    "        return algorithms\n",
    "\n",
    "    def create_all_targets(self, df):\n",
    "        \"\"\"Create all prediction targets: mortality, tumor classification, IDH, MGMT\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"CREATING ALL PREDICTION TARGETS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        targets_data = {}\n",
    "        \n",
    "        # ============================================================\n",
    "        # MORTALITY TARGETS\n",
    "        # ============================================================\n",
    "        print(\"MORTALITY TARGETS:\")\n",
    "        survival_data = df[df['survival'].notna() & df['patient_status'].notna()].copy()\n",
    "        \n",
    "        if len(survival_data) > 0:\n",
    "            survival_data['mortality_6mo'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 6)).astype(int)\n",
    "            survival_data['mortality_1yr'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 12)).astype(int)\n",
    "            survival_data['mortality_2yr'] = ((survival_data['patient_status'] == 2) & \n",
    "                                              (survival_data['survival'] <= 24)).astype(int)\n",
    "            \n",
    "            targets_data['mortality'] = {\n",
    "                'data': survival_data,\n",
    "                'targets': ['mortality_6mo', 'mortality_1yr', 'mortality_2yr'],\n",
    "                'descriptions': ['6-Month Mortality', '1-Year Mortality', '2-Year Mortality']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(survival_data)}\")\n",
    "            print(f\"   6-month: {survival_data['mortality_6mo'].sum()}/{len(survival_data)} ({survival_data['mortality_6mo'].mean()*100:.1f}%)\")\n",
    "            print(f\"   1-year: {survival_data['mortality_1yr'].sum()}/{len(survival_data)} ({survival_data['mortality_1yr'].mean()*100:.1f}%)\")\n",
    "            print(f\"   2-year: {survival_data['mortality_2yr'].sum()}/{len(survival_data)} ({survival_data['mortality_2yr'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # TUMOR CLASSIFICATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nTUMOR CLASSIFICATION TARGETS:\")\n",
    "        tumor_data = df[df['methylation_class'].notna()].copy()\n",
    "        \n",
    "        if len(tumor_data) > 0:\n",
    "            # Binary high-grade vs low-grade\n",
    "            high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "            tumor_data['high_grade'] = tumor_data['methylation_class'].str.lower().str.contains(\n",
    "                '|'.join(high_grade_terms), na=False\n",
    "            ).astype(int)\n",
    "            \n",
    "            targets_data['tumor'] = {\n",
    "                'data': tumor_data,\n",
    "                'targets': ['high_grade'],\n",
    "                'descriptions': ['High-Grade vs Low-Grade']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(tumor_data)}\")\n",
    "            print(f\"   High-grade: {tumor_data['high_grade'].sum()}/{len(tumor_data)} ({tumor_data['high_grade'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # IDH MUTATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nIDH MUTATION TARGETS:\")\n",
    "        idh_data = self._create_idh_targets(df)\n",
    "        \n",
    "        if idh_data is not None and len(idh_data) > 0:\n",
    "            targets_data['idh'] = {\n",
    "                'data': idh_data,\n",
    "                'targets': ['idh_binary'],\n",
    "                'descriptions': ['IDH Mutation Status']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(idh_data)}\")\n",
    "            print(f\"   IDH Mutant: {idh_data['idh_binary'].sum()}/{len(idh_data)} ({idh_data['idh_binary'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # MGMT METHYLATION TARGETS\n",
    "        # ============================================================\n",
    "        print(\"\\nMGMT METHYLATION TARGETS:\")\n",
    "        mgmt_data = self._create_mgmt_targets(df)\n",
    "        \n",
    "        if mgmt_data is not None and len(mgmt_data) > 0:\n",
    "            targets_data['mgmt'] = {\n",
    "                'data': mgmt_data,\n",
    "                'targets': ['mgmt_binary'],\n",
    "                'descriptions': ['MGMT Promoter Methylation']\n",
    "            }\n",
    "            \n",
    "            print(f\"   Patients: {len(mgmt_data)}\")\n",
    "            print(f\"   MGMT Methylated: {mgmt_data['mgmt_binary'].sum()}/{len(mgmt_data)} ({mgmt_data['mgmt_binary'].mean()*100:.1f}%)\")\n",
    "        \n",
    "        return targets_data\n",
    "\n",
    "    def _create_idh_targets(self, df):\n",
    "        \"\"\"Create IDH mutation targets with proper decoding\"\"\"\n",
    "        if 'idh_1_r132h' not in df.columns:\n",
    "            return None\n",
    "            \n",
    "        idh_data = df.copy()\n",
    "        idh_data['idh_binary'] = np.nan\n",
    "        \n",
    "        # Cross-reference with text data if available\n",
    "        if 'idh1' in df.columns:\n",
    "            text_idh = df['idh1'].astype(str).str.lower()\n",
    "            mutant_patterns = ['r132h', 'r132s', 'arg132his', 'arg132ser', 'missense', 'p.arg132']\n",
    "            is_mutant_text = text_idh.str.contains('|'.join(mutant_patterns), na=False)\n",
    "            idh_data.loc[is_mutant_text, 'idh_binary'] = 1  # Mutant\n",
    "        \n",
    "        # Apply numerical encoding (2 = mutant based on cross-reference analysis)\n",
    "        remaining_mask = idh_data['idh_binary'].isna() & idh_data['idh_1_r132h'].notna()\n",
    "        idh_data.loc[remaining_mask & (idh_data['idh_1_r132h'] == 2), 'idh_binary'] = 1  # Mutant\n",
    "        idh_data.loc[remaining_mask & (idh_data['idh_1_r132h'] == 1), 'idh_binary'] = 0  # Wildtype\n",
    "        \n",
    "        # Exclude unknown cases\n",
    "        idh_data.loc[idh_data['idh_1_r132h'] == 3, 'idh_binary'] = np.nan\n",
    "        \n",
    "        return idh_data[idh_data['idh_binary'].notna()].copy()\n",
    "\n",
    "    def _create_mgmt_targets(self, df):\n",
    "        \"\"\"Create MGMT methylation targets with correct encoding\"\"\"\n",
    "        if 'mgmt' not in df.columns:\n",
    "            return None\n",
    "            \n",
    "        mgmt_data = df[df['mgmt'].notna()].copy()\n",
    "        \n",
    "        if len(mgmt_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Correct encoding based on data dictionary:\n",
    "        # 1 = Positive (methylated), 2 = Negative (unmethylated), 3 = Non-informative\n",
    "        mgmt_data['mgmt_binary'] = np.nan\n",
    "        \n",
    "        # Set methylated cases (value = 1)\n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 1, 'mgmt_binary'] = 1  # Methylated\n",
    "        \n",
    "        # Set unmethylated cases (value = 2) \n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 2, 'mgmt_binary'] = 0  # Unmethylated\n",
    "        \n",
    "        # Exclude non-informative cases (value = 3)\n",
    "        mgmt_data.loc[mgmt_data['mgmt'] == 3, 'mgmt_binary'] = np.nan\n",
    "        \n",
    "        # Return only cases with definitive results\n",
    "        return mgmt_data[mgmt_data['mgmt_binary'].notna()].copy()\n",
    "\n",
    "    def select_features(self, df):\n",
    "        \"\"\"Select comprehensive feature set\"\"\"\n",
    "        # Clinical features\n",
    "        clinical_features = ['age', 'sex', 'race', 'ethnicity', 'gtr']\n",
    "        \n",
    "        # Molecular features (exclude target variables to prevent leakage)\n",
    "        molecular_features = ['mgmt_pyro', 'atrx', 'p53', 'braf_v600', 'h3k27m', 'gfap', 'tumor', 'hg_glioma']\n",
    "        \n",
    "        # CNN-extracted imaging features\n",
    "        image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "        \n",
    "        # Combine all features\n",
    "        all_features = clinical_features + molecular_features + image_features\n",
    "        available_features = [f for f in all_features if f in df.columns]\n",
    "        \n",
    "        return available_features\n",
    "\n",
    "    def preprocess_data(self, df, features, target_col):\n",
    "        \"\"\"Advanced preprocessing for multiple ML algorithms\"\"\"\n",
    "        data = df[features + [target_col]].copy()\n",
    "        data = data[data[target_col].notna()]\n",
    "        \n",
    "        if len(data) < 15:  # Minimum viable sample size\n",
    "            return None, None, f\"Insufficient data: {len(data)} samples\"\n",
    "        \n",
    "        # Handle categorical features\n",
    "        categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "        if target_col in categorical_features:\n",
    "            categorical_features.remove(target_col)\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            if col in features:\n",
    "                le = LabelEncoder()\n",
    "                data[col] = data[col].astype(str)\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "        \n",
    "        # Handle missing values\n",
    "        numerical_features = [f for f in features if f in data.select_dtypes(include=[np.number]).columns]\n",
    "        \n",
    "        for col in numerical_features:\n",
    "            if data[col].isnull().sum() > 0:\n",
    "                if col.startswith('feature_'):\n",
    "                    data[col] = data[col].fillna(data[col].mean())\n",
    "                else:\n",
    "                    data[col] = data[col].fillna(data[col].median())\n",
    "        \n",
    "        # Remove features with >50% missing\n",
    "        missing_pct = data[features].isnull().mean()\n",
    "        good_features = missing_pct[missing_pct <= 0.5].index.tolist()\n",
    "        \n",
    "        if len(good_features) < len(features):\n",
    "            features = good_features\n",
    "            data = data[features + [target_col]]\n",
    "        \n",
    "        # Feature selection for computational efficiency\n",
    "        X = data[features].values\n",
    "        y = data[target_col].values\n",
    "        \n",
    "        # Check class balance\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        min_class_size = min(class_counts)\n",
    "        \n",
    "        if min_class_size < 3:\n",
    "            return None, None, f\"Class too small: minimum class has {min_class_size} samples\"\n",
    "        \n",
    "        # Feature selection (limit to 100 for computational efficiency)\n",
    "        if X.shape[1] > 100:\n",
    "            selector = SelectKBest(score_func=f_classif, k=100)\n",
    "            X = selector.fit_transform(X, y)\n",
    "        \n",
    "        return X, y, None\n",
    "\n",
    "    def train_and_evaluate_algorithm(self, X_train, X_test, y_train, y_test, algorithm_name, algorithm_config):\n",
    "        \"\"\"Train and evaluate a single algorithm with optimized preprocessing\"\"\"\n",
    "        try:\n",
    "            model = algorithm_config['model']\n",
    "            needs_scaling = algorithm_config['needs_scaling']\n",
    "            \n",
    "            # Apply robust scaling if needed\n",
    "            if needs_scaling:\n",
    "                # Use RobustScaler for biomedical data (handles outliers better than StandardScaler)\n",
    "                from sklearn.preprocessing import RobustScaler\n",
    "                scaler = RobustScaler(quantile_range=(10.0, 90.0))  # Less sensitive to outliers\n",
    "                X_train_processed = scaler.fit_transform(X_train)\n",
    "                X_test_processed = scaler.transform(X_test)\n",
    "                \n",
    "                # Handle potential scaling issues\n",
    "                if np.any(np.isnan(X_train_processed)) or np.any(np.isnan(X_test_processed)):\n",
    "                    # Fallback to StandardScaler if RobustScaler fails\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_processed = scaler.fit_transform(X_train)\n",
    "                    X_test_processed = scaler.transform(X_test)\n",
    "            else:\n",
    "                X_train_processed = X_train\n",
    "                X_test_processed = X_test\n",
    "            \n",
    "            # Special handling for different algorithms\n",
    "            if algorithm_name == 'TabNet' and TABNET_AVAILABLE:\n",
    "                # TabNet needs special training procedure\n",
    "                model.fit(\n",
    "                    X_train_processed, y_train,\n",
    "                    eval_set=[(X_test_processed, y_test)],\n",
    "                    patience=20,        # Increased patience for better convergence\n",
    "                    max_epochs=100,     # More epochs for biomedical data\n",
    "                    eval_metric=['auc'],\n",
    "                    batch_size=min(256, len(X_train)//4)  # Adaptive batch size\n",
    "                )\n",
    "                y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "                \n",
    "            elif algorithm_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "                # XGBoost with standard training (early stopping varies by version)\n",
    "                try:\n",
    "                    # Try with early stopping if supported\n",
    "                    eval_set = [(X_test_processed, y_test)]\n",
    "                    model.fit(\n",
    "                        X_train_processed, y_train,\n",
    "                        eval_set=eval_set,\n",
    "                        verbose=False\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    # Fallback to standard training if early stopping not supported\n",
    "                    model.fit(X_train_processed, y_train)\n",
    "                \n",
    "                y_pred = model.predict(X_test_processed)\n",
    "                y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                \n",
    "            else:\n",
    "                # Standard scikit-learn interface\n",
    "                model.fit(X_train_processed, y_train)\n",
    "                y_pred = model.predict(X_test_processed)\n",
    "                \n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "                else:\n",
    "                    y_pred_proba = y_pred.astype(float)\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Robust AUC calculation\n",
    "            try:\n",
    "                auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            except ValueError:\n",
    "                # Handle edge cases (e.g., all one class in test set)\n",
    "                auc = 0.5\n",
    "            \n",
    "            # Confusion matrix and clinical metrics\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Clinical metrics for binary classification\n",
    "            if cm.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "            else:\n",
    "                sensitivity = specificity = ppv = npv = 0\n",
    "            \n",
    "            # Additional metrics for model comparison\n",
    "            balanced_accuracy = (sensitivity + specificity) / 2\n",
    "            f1_score = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'balanced_accuracy': balanced_accuracy,\n",
    "                'auc': auc,\n",
    "                'sensitivity': sensitivity,\n",
    "                'specificity': specificity,\n",
    "                'ppv': ppv,\n",
    "                'npv': npv,\n",
    "                'f1_score': f1_score,\n",
    "                'confusion_matrix': cm,\n",
    "                'n_test': len(y_test),\n",
    "                'scaling_used': needs_scaling\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå {algorithm_name} failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def run_prediction_task(self, X, y, task_name, cnn_name, algorithms):\n",
    "        \"\"\"Run prediction task with cross-validation and single holdout validation\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{task_name} - {cnn_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Single holdout split for detailed analysis\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.25, random_state=42, stratify=y\n",
    "            )\n",
    "        except:\n",
    "            # If stratification fails, try without it\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.25, random_state=42\n",
    "            )\n",
    "        \n",
    "        print(f\"DATA SPLIT:\")\n",
    "        print(f\"   Training: {len(X_train)} samples\")\n",
    "        print(f\"   Testing: {len(X_test)} samples\")\n",
    "        print(f\"   Positive rate: {y_train.mean()*100:.1f}% (train), {y_test.mean()*100:.1f}% (test)\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Test each algorithm with both holdout and cross-validation\n",
    "        for alg_name, alg_config in algorithms.items():\n",
    "            print(f\"\\nTESTING {alg_name}...\")\n",
    "            \n",
    "            # Single holdout result (for detailed metrics)\n",
    "            holdout_result = self.train_and_evaluate_algorithm(X_train, X_test, y_train, y_test, alg_name, alg_config)\n",
    "            \n",
    "            if holdout_result is None:\n",
    "                print(f\"   ERROR {alg_name}: FAILED\")\n",
    "                continue\n",
    "            \n",
    "            # Cross-validation for robustness\n",
    "            cv_result = self.cross_validate_algorithm(X, y, alg_name, alg_config)\n",
    "            \n",
    "            if cv_result is None:\n",
    "                print(f\"   WARNING {alg_name}: Cross-validation failed, using holdout only\")\n",
    "                cv_result = {\n",
    "                    'cv_auc_mean': holdout_result['auc'],\n",
    "                    'cv_auc_std': 0.0,\n",
    "                    'cv_auc_ci_lower': holdout_result['auc'],\n",
    "                    'cv_auc_ci_upper': holdout_result['auc'],\n",
    "                    'cv_accuracy_mean': holdout_result['accuracy'],\n",
    "                    'cv_accuracy_std': 0.0,\n",
    "                    'cv_folds': 1,\n",
    "                    'cv_stability': 'SINGLE_SPLIT'\n",
    "                }\n",
    "            \n",
    "            # Combine holdout and CV results\n",
    "            combined_result = {**holdout_result, **cv_result}\n",
    "            results[alg_name] = combined_result\n",
    "            \n",
    "            # Enhanced reporting with confidence intervals\n",
    "            auc_mean = cv_result['cv_auc_mean']\n",
    "            auc_std = cv_result['cv_auc_std']\n",
    "            auc_ci_lower = cv_result['cv_auc_ci_lower']\n",
    "            auc_ci_upper = cv_result['cv_auc_ci_upper']\n",
    "            stability = cv_result['cv_stability']\n",
    "            \n",
    "            print(f\"   HOLDOUT: Accuracy={holdout_result['accuracy']:.3f}, AUC={holdout_result['auc']:.3f}\")\n",
    "            print(f\"   CROSS-VAL: AUC={auc_mean:.3f} (95% CI: {auc_ci_lower:.3f}-{auc_ci_upper:.3f})\")\n",
    "            print(f\"   STABILITY: {stability}\")\n",
    "            \n",
    "            # Clinical interpretation with confidence intervals\n",
    "            if auc_ci_lower >= 0.85:\n",
    "                print(f\"       EXCELLENT clinical performance (robust across CV)\")\n",
    "            elif auc_mean >= 0.85 and auc_ci_lower >= 0.75:\n",
    "                print(f\"       EXCELLENT clinical performance (some variability)\")\n",
    "            elif auc_ci_lower >= 0.75:\n",
    "                print(f\"       STRONG clinical performance (robust across CV)\")\n",
    "            elif auc_mean >= 0.75 and auc_ci_lower >= 0.65:\n",
    "                print(f\"       STRONG clinical performance (some variability)\")\n",
    "            elif auc_ci_lower >= 0.65:\n",
    "                print(f\"       GOOD performance (robust across CV)\")\n",
    "            else:\n",
    "                print(f\"       MODERATE performance (consider more data/optimization)\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def cross_validate_algorithm(self, X, y, algorithm_name, algorithm_config, cv_folds=5):\n",
    "        \"\"\"Perform stratified cross-validation with confidence intervals\"\"\"\n",
    "        try:\n",
    "            # Create stratified k-fold\n",
    "            cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "            \n",
    "            # Storage for CV results\n",
    "            cv_aucs = []\n",
    "            cv_accuracies = []\n",
    "            cv_sensitivities = []\n",
    "            cv_specificities = []\n",
    "            \n",
    "            fold_num = 0\n",
    "            for train_idx, val_idx in cv.split(X, y):\n",
    "                fold_num += 1\n",
    "                X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "                y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "                \n",
    "                # Train and evaluate on this fold\n",
    "                fold_result = self.train_and_evaluate_algorithm(\n",
    "                    X_train_cv, X_val_cv, y_train_cv, y_val_cv, \n",
    "                    algorithm_name, algorithm_config\n",
    "                )\n",
    "                \n",
    "                if fold_result is not None:\n",
    "                    cv_aucs.append(fold_result['auc'])\n",
    "                    cv_accuracies.append(fold_result['accuracy'])\n",
    "                    cv_sensitivities.append(fold_result['sensitivity'])\n",
    "                    cv_specificities.append(fold_result['specificity'])\n",
    "                else:\n",
    "                    # If a fold fails, record it but continue\n",
    "                    cv_aucs.append(0.5)  # Random performance\n",
    "                    cv_accuracies.append(0.5)\n",
    "                    cv_sensitivities.append(0.5)\n",
    "                    cv_specificities.append(0.5)\n",
    "            \n",
    "            # Calculate CV statistics\n",
    "            cv_aucs = np.array(cv_aucs)\n",
    "            cv_accuracies = np.array(cv_accuracies)\n",
    "            \n",
    "            # Mean and standard deviation\n",
    "            auc_mean = np.mean(cv_aucs)\n",
    "            auc_std = np.std(cv_aucs)\n",
    "            acc_mean = np.mean(cv_accuracies)\n",
    "            acc_std = np.std(cv_accuracies)\n",
    "            \n",
    "            # 95% Confidence intervals (using t-distribution for small samples)\n",
    "            from scipy import stats\n",
    "            t_critical = stats.t.ppf(0.975, df=len(cv_aucs)-1)  # 95% CI\n",
    "            auc_margin = t_critical * (auc_std / np.sqrt(len(cv_aucs)))\n",
    "            \n",
    "            auc_ci_lower = max(0.0, auc_mean - auc_margin)\n",
    "            auc_ci_upper = min(1.0, auc_mean + auc_margin)\n",
    "            \n",
    "            # Stability assessment\n",
    "            cv_of_variation = auc_std / auc_mean if auc_mean > 0 else 1.0\n",
    "            \n",
    "            if cv_of_variation < 0.05:\n",
    "                stability = \"HIGHLY STABLE\"\n",
    "            elif cv_of_variation < 0.10:\n",
    "                stability = \"STABLE\"\n",
    "            elif cv_of_variation < 0.15:\n",
    "                stability = \"MODERATE VARIABILITY\"\n",
    "            else:\n",
    "                stability = \"HIGH VARIABILITY\"\n",
    "            \n",
    "            return {\n",
    "                'cv_auc_mean': auc_mean,\n",
    "                'cv_auc_std': auc_std,\n",
    "                'cv_auc_ci_lower': auc_ci_lower,\n",
    "                'cv_auc_ci_upper': auc_ci_upper,\n",
    "                'cv_accuracy_mean': acc_mean,\n",
    "                'cv_accuracy_std': acc_std,\n",
    "                'cv_sensitivity_mean': np.mean(cv_sensitivities),\n",
    "                'cv_specificity_mean': np.mean(cv_specificities),\n",
    "                'cv_folds': cv_folds,\n",
    "                'cv_stability': stability,\n",
    "                'cv_coefficient_variation': cv_of_variation,\n",
    "                'cv_individual_aucs': cv_aucs.tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Cross-validation failed for {algorithm_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _check_feature_quality(self, df):\n",
    "        \"\"\"Check feature quality and completeness\"\"\"\n",
    "        try:\n",
    "            image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "            clinical_features = ['age', 'sex', 'race', 'ethnicity']\n",
    "            \n",
    "            image_quality = len(image_features) >= 50  # Sufficient image features\n",
    "            clinical_completeness = sum(col in df.columns for col in clinical_features) >= 2\n",
    "            \n",
    "            score = (image_quality + clinical_completeness) / 2\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.5 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Image features: {len(image_features)}, Clinical completeness: {clinical_completeness}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Feature quality check failed'}\n",
    "\n",
    "    def run_validation_checks(self, cnn_name, file_path):\n",
    "        \"\"\"Run comprehensive validation checks\"\"\"\n",
    "        print(f\"\\nüîç VALIDATION CHECKS FOR {cnn_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            validation = {\n",
    "                'data_integrity': self._check_data_integrity(df),\n",
    "                'class_balance': self._check_class_balance(df),\n",
    "                'feature_quality': self._check_feature_quality(df),\n",
    "                'sample_size': self._check_sample_size(df)\n",
    "            }\n",
    "            \n",
    "            # Overall assessment\n",
    "            passed_checks = sum(1 for check in validation.values() if check['status'] == 'PASS')\n",
    "            total_checks = len(validation)\n",
    "            \n",
    "            validation['overall'] = {\n",
    "                'status': 'PASS' if passed_checks >= 3 else 'WARN',\n",
    "                'score': passed_checks / total_checks,\n",
    "                'summary': f\"{passed_checks}/{total_checks} validation checks passed\"\n",
    "            }\n",
    "            \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "    def _check_data_integrity(self, df):\n",
    "        \"\"\"Check basic data integrity\"\"\"\n",
    "        try:\n",
    "            has_survival = df['survival'].notna().sum() > 10\n",
    "            has_molecular = any(col in df.columns for col in ['mgmt', 'idh_1_r132h', 'methylation_class'])\n",
    "            has_images = any(col.startswith('feature_') for col in df.columns)\n",
    "            \n",
    "            score = sum([has_survival, has_molecular, has_images]) / 3\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.67 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Survival: {has_survival}, Molecular: {has_molecular}, Images: {has_images}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Data integrity check failed'}\n",
    "\n",
    "    def _check_class_balance(self, df):\n",
    "        \"\"\"Check class balance across targets\"\"\"\n",
    "        try:\n",
    "            balances = []\n",
    "            \n",
    "            # Check mortality balance\n",
    "            if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                survival_data = df[df['survival'].notna() & df['patient_status'].notna()]\n",
    "                if len(survival_data) > 0:\n",
    "                    mortality_1yr = ((survival_data['patient_status'] == 2) & \n",
    "                                   (survival_data['survival'] <= 12)).mean()\n",
    "                    balances.append(min(mortality_1yr, 1-mortality_1yr))\n",
    "            \n",
    "            # Check tumor grade balance\n",
    "            if 'methylation_class' in df.columns:\n",
    "                tumor_data = df[df['methylation_class'].notna()]\n",
    "                if len(tumor_data) > 0:\n",
    "                    high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "                    high_grade_rate = tumor_data['methylation_class'].str.lower().str.contains(\n",
    "                        '|'.join(high_grade_terms), na=False\n",
    "                    ).mean()\n",
    "                    balances.append(min(high_grade_rate, 1-high_grade_rate))\n",
    "            \n",
    "            avg_balance = np.mean(balances) if balances else 0\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if avg_balance >= 0.15 else 'WARN',\n",
    "                'score': avg_balance,\n",
    "                'details': f\"Average minority class rate: {avg_balance:.3f}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Class balance check failed'}\n",
    "\n",
    "    def _check_confounding_factors(self, df):\n",
    "        \"\"\"Check for potential confounding factors in clinical predictions\"\"\"\n",
    "        try:\n",
    "            confounding_issues = []\n",
    "            severity_scores = []\n",
    "            \n",
    "            # Check for age-outcome confounding\n",
    "            age_confounding = self._check_age_confounding(df)\n",
    "            if age_confounding['severity'] > 0:\n",
    "                confounding_issues.append(age_confounding)\n",
    "                severity_scores.append(age_confounding['severity'])\n",
    "            \n",
    "            # Check for center/batch effects (if institutional data available)\n",
    "            batch_confounding = self._check_batch_effects(df)\n",
    "            if batch_confounding['severity'] > 0:\n",
    "                confounding_issues.append(batch_confounding)\n",
    "                severity_scores.append(batch_confounding['severity'])\n",
    "            \n",
    "            # Check for molecular marker interdependence\n",
    "            molecular_confounding = self._check_molecular_confounding(df)\n",
    "            if molecular_confounding['severity'] > 0:\n",
    "                confounding_issues.append(molecular_confounding)\n",
    "                severity_scores.append(molecular_confounding['severity'])\n",
    "            \n",
    "            # Check for survival bias in molecular markers\n",
    "            survival_bias = self._check_survival_bias(df)\n",
    "            if survival_bias['severity'] > 0:\n",
    "                confounding_issues.append(survival_bias) \n",
    "                severity_scores.append(survival_bias['severity'])\n",
    "            \n",
    "            # Overall assessment\n",
    "            if not severity_scores:\n",
    "                status = 'PASS'\n",
    "                score = 1.0\n",
    "                details = \"No major confounding factors detected\"\n",
    "            else:\n",
    "                max_severity = max(severity_scores)\n",
    "                if max_severity >= 0.8:\n",
    "                    status = 'FAIL'\n",
    "                    score = 0.2\n",
    "                    details = f\"Critical confounding detected: {len(confounding_issues)} issues\"\n",
    "                elif max_severity >= 0.5:\n",
    "                    status = 'WARN'\n",
    "                    score = 0.6\n",
    "                    details = f\"Moderate confounding detected: {len(confounding_issues)} issues\"\n",
    "                else:\n",
    "                    status = 'PASS'\n",
    "                    score = 0.8\n",
    "                    details = f\"Minor confounding detected: {len(confounding_issues)} issues\"\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'score': score,\n",
    "                'details': details,\n",
    "                'confounding_issues': confounding_issues,\n",
    "                'n_issues': len(confounding_issues)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'WARN',\n",
    "                'score': 0.5,\n",
    "                'details': f'Confounding check incomplete: {str(e)}',\n",
    "                'confounding_issues': [],\n",
    "                'n_issues': 0\n",
    "            }\n",
    "\n",
    "    def _check_age_confounding(self, df):\n",
    "        \"\"\"Check if age is confounded with outcomes\"\"\"\n",
    "        try:\n",
    "            if 'age' not in df.columns:\n",
    "                return {'type': 'age', 'severity': 0, 'description': 'Age data not available'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            # Check age-mortality confounding\n",
    "            if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                survival_data = df[df['survival'].notna() & df['patient_status'].notna() & df['age'].notna()]\n",
    "                if len(survival_data) > 10:\n",
    "                    deceased = survival_data[survival_data['patient_status'] == 2]['age']\n",
    "                    alive = survival_data[survival_data['patient_status'] != 2]['age']\n",
    "                    \n",
    "                    if len(deceased) > 5 and len(alive) > 5:\n",
    "                        age_diff = abs(deceased.mean() - alive.mean())\n",
    "                        pooled_std = np.sqrt(((deceased.std()**2 + alive.std()**2) / 2))\n",
    "                        effect_size = age_diff / pooled_std if pooled_std > 0 else 0\n",
    "                        \n",
    "                        if effect_size > 0.8:  # Large effect\n",
    "                            severity = 0.9\n",
    "                            issues.append(f\"Large age difference between deceased ({deceased.mean():.1f}) and alive ({alive.mean():.1f})\")\n",
    "                        elif effect_size > 0.5:  # Medium effect\n",
    "                            severity = 0.6\n",
    "                            issues.append(f\"Moderate age difference between outcomes\")\n",
    "                        \n",
    "                        max_severity = max(max_severity, severity if 'severity' in locals() else 0)\n",
    "            \n",
    "            # Check age-tumor grade confounding  \n",
    "            if 'methylation_class' in df.columns:\n",
    "                tumor_data = df[df['methylation_class'].notna() & df['age'].notna()]\n",
    "                if len(tumor_data) > 10:\n",
    "                    high_grade_terms = ['glioblastoma', 'anaplastic', 'high grade', 'grade iv', 'grade 4', 'gbm']\n",
    "                    high_grade_mask = tumor_data['methylation_class'].str.lower().str.contains('|'.join(high_grade_terms), na=False)\n",
    "                    \n",
    "                    high_grade_ages = tumor_data[high_grade_mask]['age']\n",
    "                    low_grade_ages = tumor_data[~high_grade_mask]['age']\n",
    "                    \n",
    "                    if len(high_grade_ages) > 5 and len(low_grade_ages) > 5:\n",
    "                        age_diff = abs(high_grade_ages.mean() - low_grade_ages.mean())\n",
    "                        pooled_std = np.sqrt(((high_grade_ages.std()**2 + low_grade_ages.std()**2) / 2))\n",
    "                        effect_size = age_diff / pooled_std if pooled_std > 0 else 0\n",
    "                        \n",
    "                        if effect_size > 0.8:\n",
    "                            severity = 0.7  # Slightly less critical than mortality\n",
    "                            issues.append(f\"Age strongly associated with tumor grade\")\n",
    "                            max_severity = max(max_severity, severity)\n",
    "            \n",
    "            return {\n",
    "                'type': 'age_confounding',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant age confounding detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'age_confounding', 'severity': 0, 'description': 'Age confounding check failed'}\n",
    "\n",
    "    def _check_batch_effects(self, df):\n",
    "        \"\"\"Check for potential batch/center effects\"\"\"\n",
    "        try:\n",
    "            # Look for institutional or batch identifiers\n",
    "            batch_columns = [col for col in df.columns if any(term in col.lower() \n",
    "                           for term in ['institution', 'center', 'batch', 'site', 'hospital'])]\n",
    "            \n",
    "            if not batch_columns:\n",
    "                return {'type': 'batch_effects', 'severity': 0, 'description': 'No batch identifiers found'}\n",
    "            \n",
    "            # Check if outcomes vary significantly by batch\n",
    "            severity = 0\n",
    "            issues = []\n",
    "            \n",
    "            for batch_col in batch_columns:\n",
    "                unique_batches = df[batch_col].nunique()\n",
    "                if unique_batches > 1 and unique_batches < len(df) * 0.5:  # Reasonable number of batches\n",
    "                    # Check mortality rates by batch\n",
    "                    if 'survival' in df.columns and 'patient_status' in df.columns:\n",
    "                        batch_mortality = df.groupby(batch_col).apply(\n",
    "                            lambda x: ((x['patient_status'] == 2) & (x['survival'] <= 12)).mean()\n",
    "                        )\n",
    "                        if batch_mortality.std() > 0.15:  # >15% variation in mortality rates\n",
    "                            severity = max(severity, 0.6)\n",
    "                            issues.append(f\"Mortality rates vary by {batch_col}\")\n",
    "            \n",
    "            return {\n",
    "                'type': 'batch_effects',\n",
    "                'severity': severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant batch effects detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'batch_effects', 'severity': 0, 'description': 'Batch effects check failed'}\n",
    "\n",
    "    def _check_molecular_confounding(self, df):\n",
    "        \"\"\"Check for confounding between molecular markers\"\"\"\n",
    "        try:\n",
    "            molecular_cols = ['mgmt', 'idh_1_r132h', 'atrx', 'p53']\n",
    "            available_molecular = [col for col in molecular_cols if col in df.columns]\n",
    "            \n",
    "            if len(available_molecular) < 2:\n",
    "                return {'type': 'molecular_confounding', 'severity': 0, 'description': 'Insufficient molecular data'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            # Check IDH-MGMT association (known biological confounding)\n",
    "            if 'idh_1_r132h' in df.columns and 'mgmt' in df.columns:\n",
    "                idh_mgmt_data = df[(df['idh_1_r132h'].isin([1, 2])) & (df['mgmt'].isin([1, 2]))]\n",
    "                \n",
    "                if len(idh_mgmt_data) > 20:\n",
    "                    # Create contingency table\n",
    "                    idh_mutant = (idh_mgmt_data['idh_1_r132h'] == 2)  # Assuming 2 = mutant\n",
    "                    mgmt_methylated = (idh_mgmt_data['mgmt'] == 1)  # 1 = methylated per data dictionary\n",
    "                    \n",
    "                    # Calculate association strength (Cram√©r's V)\n",
    "                    from scipy.stats import chi2_contingency\n",
    "                    try:\n",
    "                        contingency = pd.crosstab(idh_mutant, mgmt_methylated)\n",
    "                        chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "                        n = contingency.sum().sum()\n",
    "                        cramers_v = np.sqrt(chi2 / (n * (min(contingency.shape) - 1)))\n",
    "                        \n",
    "                        if cramers_v > 0.5 and p_value < 0.05:\n",
    "                            max_severity = 0.8\n",
    "                            issues.append(\"Strong IDH-MGMT association detected (biological confounding)\")\n",
    "                        elif cramers_v > 0.3 and p_value < 0.05:\n",
    "                            max_severity = 0.5\n",
    "                            issues.append(\"Moderate IDH-MGMT association detected\")\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            return {\n",
    "                'type': 'molecular_confounding',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant molecular confounding detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'molecular_confounding', 'severity': 0, 'description': 'Molecular confounding check failed'}\n",
    "\n",
    "    def _check_survival_bias(self, df):\n",
    "        \"\"\"Check for survival bias in molecular marker availability\"\"\"\n",
    "        try:\n",
    "            if not all(col in df.columns for col in ['survival', 'patient_status']):\n",
    "                return {'type': 'survival_bias', 'severity': 0, 'description': 'Survival data not available'}\n",
    "            \n",
    "            issues = []\n",
    "            max_severity = 0\n",
    "            \n",
    "            molecular_cols = ['mgmt', 'idh_1_r132h', 'atrx', 'p53']\n",
    "            \n",
    "            for mol_col in molecular_cols:\n",
    "                if mol_col in df.columns:\n",
    "                    # Compare survival times between patients with/without molecular data\n",
    "                    has_molecular = df[df[mol_col].notna() & df['survival'].notna()]\n",
    "                    no_molecular = df[df[mol_col].isna() & df['survival'].notna()]\n",
    "                    \n",
    "                    if len(has_molecular) > 10 and len(no_molecular) > 10:\n",
    "                        survival_diff = abs(has_molecular['survival'].mean() - no_molecular['survival'].mean())\n",
    "                        pooled_std = np.sqrt((has_molecular['survival'].std()**2 + no_molecular['survival'].std()**2) / 2)\n",
    "                        \n",
    "                        if pooled_std > 0:\n",
    "                            effect_size = survival_diff / pooled_std\n",
    "                            \n",
    "                            if effect_size > 0.5:  # Medium to large effect\n",
    "                                severity = 0.6\n",
    "                                issues.append(f\"Survival bias detected for {mol_col} availability\")\n",
    "                                max_severity = max(max_severity, severity)\n",
    "            \n",
    "            return {\n",
    "                'type': 'survival_bias',\n",
    "                'severity': max_severity,\n",
    "                'description': '; '.join(issues) if issues else 'No significant survival bias detected'\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            return {'type': 'survival_bias', 'severity': 0, 'description': 'Survival bias check failed'}\n",
    "        \"\"\"Check feature quality and completeness\"\"\"\n",
    "        try:\n",
    "            image_features = [col for col in df.columns if col.startswith('feature_')]\n",
    "            clinical_features = ['age', 'sex', 'race', 'ethnicity']\n",
    "            \n",
    "            image_quality = len(image_features) >= 50  # Sufficient image features\n",
    "            clinical_completeness = sum(col in df.columns for col in clinical_features) >= 2\n",
    "            \n",
    "            score = (image_quality + clinical_completeness) / 2\n",
    "            \n",
    "            return {\n",
    "                'status': 'PASS' if score >= 0.5 else 'WARN',\n",
    "                'score': score,\n",
    "                'details': f\"Image features: {len(image_features)}, Clinical completeness: {clinical_completeness}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Feature quality check failed'}\n",
    "\n",
    "    def _check_sample_size(self, df):\n",
    "        \"\"\"Check sample size adequacy\"\"\"\n",
    "        try:\n",
    "            total_samples = len(df)\n",
    "            \n",
    "            # Check samples for different tasks\n",
    "            survival_samples = df[df['survival'].notna() & df['patient_status'].notna()].shape[0]\n",
    "            tumor_samples = df[df['methylation_class'].notna()].shape[0]\n",
    "            \n",
    "            min_samples = min(survival_samples, tumor_samples) if tumor_samples > 0 else survival_samples\n",
    "            \n",
    "            if min_samples >= 50:\n",
    "                status = 'PASS'\n",
    "                score = 1.0\n",
    "            elif min_samples >= 30:\n",
    "                status = 'WARN'\n",
    "                score = 0.7\n",
    "            else:\n",
    "                status = 'FAIL'\n",
    "                score = 0.3\n",
    "            \n",
    "            return {\n",
    "                'status': status,\n",
    "                'score': score,\n",
    "                'details': f\"Min task samples: {min_samples}, Total: {total_samples}\"\n",
    "            }\n",
    "        except:\n",
    "            return {'status': 'FAIL', 'score': 0, 'details': 'Sample size check failed'}\n",
    "\n",
    "    def generate_publication_document(self):\n",
    "        \"\"\"Generate a comprehensive publication-ready document\"\"\"\n",
    "        \n",
    "        if not self.results:\n",
    "            print(\"No results available for document generation\")\n",
    "            return\n",
    "        \n",
    "        # Create comprehensive document content\n",
    "        doc_content = []\n",
    "        \n",
    "        # Title and Header\n",
    "        doc_content.append(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"EXECUTIVE SUMMARY\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            doc_content.append(f\"Total algorithm-task combinations tested: {total_tests}\")\n",
    "            doc_content.append(f\"Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            doc_content.append(f\"Best AUC achieved: {max_auc:.3f}\")\n",
    "            doc_content.append(f\"Excellent performance (AUC >= 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            doc_content.append(f\"Good+ performance (AUC >= 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            if excellent_tests > 0:\n",
    "                doc_content.append(f\"CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                doc_content.append(\"PUBLICATION STATUS: Exceptional results achieved - ready for top-tier journals\")\n",
    "            elif max_auc >= 0.80:\n",
    "                doc_content.append(\"PUBLICATION STATUS: Strong results achieved - ready for clinical journals\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Detailed Results Table\n",
    "        doc_content.append(\"COMPREHENSIVE RESULTS TABLE\")\n",
    "        doc_content.append(\"-\" * 80)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Create detailed table\n",
    "        header = f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Accuracy':<9} {'Sensitivity':<11} {'Specificity':<11} {'Status':<15}\"\n",
    "        doc_content.append(header)\n",
    "        doc_content.append(\"-\" * len(header))\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC without emojis\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"GOOD\"\n",
    "                    else:\n",
    "                        status = \"MODERATE\"\n",
    "                    \n",
    "                    row = f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<9.3f} {sens:<11.3f} {spec:<11.3f} {status:<15}\"\n",
    "                    doc_content.append(row)\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Best Performers Analysis\n",
    "        doc_content.append(\"BEST PERFORMERS BY CLINICAL TASK\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Find best performer for each task\n",
    "        task_best = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            acc = best['result']['accuracy']\n",
    "            sens = best['result']['sensitivity']\n",
    "            spec = best['result']['specificity']\n",
    "            \n",
    "            status = \"DEPLOYMENT READY\" if auc >= 0.85 else \"PROMISING\" if auc >= 0.75 else \"NEEDS OPTIMIZATION\"\n",
    "            \n",
    "            doc_content.append(f\"Task: {task_name}\")\n",
    "            doc_content.append(f\"  Best Combination: {best['cnn']} + {best['algorithm']}\")\n",
    "            doc_content.append(f\"  Performance: AUC = {auc:.3f}, Accuracy = {acc:.3f}\")\n",
    "            doc_content.append(f\"  Clinical Metrics: Sensitivity = {sens:.3f}, Specificity = {spec:.3f}\")\n",
    "            doc_content.append(f\"  Status: {status}\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Algorithm Performance Ranking\n",
    "        doc_content.append(\"ALGORITHM PERFORMANCE RANKING\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        algorithm_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if alg_name not in algorithm_stats:\n",
    "                        algorithm_stats[alg_name] = []\n",
    "                    algorithm_stats[alg_name].append(result['auc'])\n",
    "        \n",
    "        if algorithm_stats:\n",
    "            sorted_algorithms = sorted(algorithm_stats.items(), key=lambda x: np.mean(x[1]), reverse=True)\n",
    "            \n",
    "            for i, (alg_name, aucs) in enumerate(sorted_algorithms, 1):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                std_auc = np.std(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                \n",
    "                doc_content.append(f\"{i}. {alg_name}\")\n",
    "                doc_content.append(f\"   Mean AUC: {mean_auc:.3f} (¬±{std_auc:.3f})\")\n",
    "                doc_content.append(f\"   Best AUC: {max_auc:.3f}\")\n",
    "                doc_content.append(f\"   Tests: {n_tests}\")\n",
    "                doc_content.append(\"\")\n",
    "        \n",
    "        # CNN Architecture Ranking\n",
    "        doc_content.append(\"CNN ARCHITECTURE RANKING\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        cnn_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            aucs = []\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    aucs.append(result['auc'])\n",
    "            if aucs:\n",
    "                cnn_stats[cnn_name] = aucs\n",
    "        \n",
    "        if cnn_stats:\n",
    "            sorted_cnns = sorted(cnn_stats.items(), key=lambda x: np.mean(x[1]), reverse=True)\n",
    "            \n",
    "            for i, (cnn_name, aucs) in enumerate(sorted_cnns, 1):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                std_auc = np.std(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                \n",
    "                doc_content.append(f\"{i}. {cnn_name}\")\n",
    "                doc_content.append(f\"   Mean AUC: {mean_auc:.3f} (¬±{std_auc:.3f})\")\n",
    "                doc_content.append(f\"   Best AUC: {max_auc:.3f}\")\n",
    "                doc_content.append(f\"   Tests: {n_tests}\")\n",
    "                doc_content.append(\"\")\n",
    "        \n",
    "        # Clinical Recommendations\n",
    "        doc_content.append(\"CLINICAL IMPLEMENTATION RECOMMENDATIONS\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Find deployment-ready combinations\n",
    "        deployment_ready = []\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.80:  # Clinical deployment threshold\n",
    "                        deployment_ready.append({\n",
    "                            'task': task_name,\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'auc': result['auc'],\n",
    "                            'accuracy': result['accuracy']\n",
    "                        })\n",
    "        \n",
    "        deployment_ready.sort(key=lambda x: x['auc'], reverse=True)\n",
    "        \n",
    "        if deployment_ready:\n",
    "            doc_content.append(f\"DEPLOYMENT-READY COMBINATIONS (AUC >= 0.80): {len(deployment_ready)}\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            for i, combo in enumerate(deployment_ready[:10], 1):  # Top 10\n",
    "                doc_content.append(f\"{i}. {combo['task']}\")\n",
    "                doc_content.append(f\"   Model: {combo['cnn']} + {combo['algorithm']}\")\n",
    "                doc_content.append(f\"   Performance: {combo['auc']:.1%} AUC, {combo['accuracy']:.1%} Accuracy\")\n",
    "                doc_content.append(\"\")\n",
    "                \n",
    "            doc_content.append(\"PRIORITY IMPLEMENTATION:\")\n",
    "            top_combo = deployment_ready[0]\n",
    "            doc_content.append(f\"Task: {top_combo['task']}\")\n",
    "            doc_content.append(f\"Architecture: {top_combo['cnn']} + {top_combo['algorithm']}\")\n",
    "            doc_content.append(f\"Expected Clinical Performance: {top_combo['auc']:.1%} discrimination accuracy\")\n",
    "            doc_content.append(\"\")\n",
    "        else:\n",
    "            doc_content.append(\"No combinations reached clinical deployment threshold (AUC >= 0.80)\")\n",
    "            doc_content.append(\"Focus on methodology optimization for best performing approaches\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Publication Strategy\n",
    "        doc_content.append(\"PUBLICATION STRATEGY\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Count publication-ready results\n",
    "        tier1_results = []  # AUC >= 0.85\n",
    "        tier2_results = []  # AUC >= 0.75\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.85:\n",
    "                        tier1_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "                    elif result['auc'] >= 0.75:\n",
    "                        tier2_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "        \n",
    "        doc_content.append(\"PUBLICATION READINESS ASSESSMENT:\")\n",
    "        doc_content.append(f\"Tier 1 Results (AUC >= 0.85): {len(tier1_results)} - Suitable for top-tier journals\")\n",
    "        doc_content.append(f\"Tier 2 Results (AUC >= 0.75): {len(tier2_results)} - Suitable for clinical journals\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        if tier1_results:\n",
    "            doc_content.append(\"TOP-TIER JOURNAL STRATEGY:\")\n",
    "            doc_content.append(\"Target Journals: Nature Medicine, Lancet Digital Health, Nature Biomedical Engineering\")\n",
    "            best_result = max(tier1_results, key=lambda x: x[3])\n",
    "            doc_content.append(f\"Lead Finding: {best_result[0]} ({best_result[1]} + {best_result[2]}, AUC = {best_result[3]:.3f})\")\n",
    "            doc_content.append(\"Narrative: 'Deep Learning Achieves Clinical-Grade Performance in Neurosurgical Prediction'\")\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "        if tier2_results:\n",
    "            doc_content.append(\"CLINICAL JOURNAL STRATEGY:\")\n",
    "            doc_content.append(\"Target Journals: Neuro-Oncology, Journal of Neurosurgery, Academic Radiology\")\n",
    "            doc_content.append(\"Focus: Clinical validation studies and comparative effectiveness research\")\n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        doc_content.append(\"MANUSCRIPT DEVELOPMENT PRIORITIES:\")\n",
    "        doc_content.append(\"1. Primary Research Paper: Best performing clinical task for high-impact publication\")\n",
    "        doc_content.append(\"2. Methodology Paper: Comprehensive multi-architecture comparison study\")\n",
    "        doc_content.append(\"3. Clinical Implementation Paper: Validation study and cost-effectiveness analysis\")\n",
    "        doc_content.append(\"4. Technical Paper: Algorithm optimization and feature engineering methods\")\n",
    "        doc_content.append(\"\")\n",
    "        \n",
    "        # Validation Summary\n",
    "        if self.validation_results:\n",
    "            doc_content.append(\"DATA VALIDATION SUMMARY\")\n",
    "            doc_content.append(\"-\" * 40)\n",
    "            doc_content.append(\"\")\n",
    "            \n",
    "            validation_header = f\"{'CNN Architecture':<20} {'Overall Status':<15} {'Data Quality':<12} {'Class Balance':<12} {'Sample Size':<12}\"\n",
    "            doc_content.append(validation_header)\n",
    "            doc_content.append(\"-\" * len(validation_header))\n",
    "            \n",
    "            for cnn_name, validation in self.validation_results.items():\n",
    "                if 'error' in validation:\n",
    "                    doc_content.append(f\"{cnn_name:<20} {'ERROR':<15} {'N/A':<12} {'N/A':<12} {'N/A':<12}\")\n",
    "                else:\n",
    "                    overall = validation.get('overall', {}).get('status', 'FAIL')\n",
    "                    data_quality = validation.get('data_integrity', {}).get('status', 'FAIL')\n",
    "                    class_balance = validation.get('class_balance', {}).get('status', 'FAIL')\n",
    "                    sample_size = validation.get('sample_size', {}).get('status', 'FAIL')\n",
    "                    \n",
    "                    doc_content.append(f\"{cnn_name:<20} {overall:<15} {data_quality:<12} {class_balance:<12} {sample_size:<12}\")\n",
    "            \n",
    "            doc_content.append(\"\")\n",
    "        \n",
    "        # Technical Specifications\n",
    "        doc_content.append(\"TECHNICAL SPECIFICATIONS\")\n",
    "        doc_content.append(\"-\" * 40)\n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"Machine Learning Algorithms Tested:\")\n",
    "        \n",
    "        algorithms = self.get_ml_algorithms()\n",
    "        for i, (alg_name, alg_config) in enumerate(algorithms.items(), 1):\n",
    "            doc_content.append(f\"{i}. {alg_name}: {alg_config['description']}\")\n",
    "            doc_content.append(f\"   Preprocessing: {'Robust Scaling Applied' if alg_config['needs_scaling'] else 'No Scaling Required'}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"CNN Architectures Evaluated:\")\n",
    "        for i, cnn_name in enumerate(self.datasets.keys(), 1):\n",
    "            doc_content.append(f\"{i}. {cnn_name}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"Clinical Tasks Assessed:\")\n",
    "        tasks = set()\n",
    "        for cnn_results in self.results.values():\n",
    "            for task_data in cnn_results.values():\n",
    "                tasks.add(task_data['task_name'])\n",
    "        \n",
    "        for i, task in enumerate(sorted(tasks), 1):\n",
    "            doc_content.append(f\"{i}. {task}\")\n",
    "        \n",
    "        doc_content.append(\"\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        doc_content.append(\"ANALYSIS COMPLETE\")\n",
    "        doc_content.append(f\"Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        doc_content.append(\"=\" * 80)\n",
    "        \n",
    "        # Write to file\n",
    "        filename = f\"neurosurgical_ai_analysis_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "        \n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                for line in doc_content:\n",
    "                    f.write(line + '\\n')\n",
    "            \n",
    "            # Calculate file size properly\n",
    "            doc_text = '\\n'.join(doc_content)\n",
    "            file_size = len(doc_text)\n",
    "            \n",
    "            print(f\"\\nPublication document generated successfully!\")\n",
    "            print(f\"Filename: {filename}\")\n",
    "            print(f\"Lines written: {len(doc_content)}\")\n",
    "            print(f\"File size: {file_size} characters\")\n",
    "            \n",
    "            return filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error writing document: {e}\")\n",
    "            return None\n",
    "\n",
    "    def run_comprehensive_analysis(self):\n",
    "        \"\"\"Run the complete comprehensive analysis\"\"\"\n",
    "        \n",
    "        print(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Testing 5 CNNs √ó Multiple ML Algorithms √ó 6 Clinical Tasks\")\n",
    "        print(\"Target: Clinical-grade performance (AUC >= 0.80)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Initialize ML algorithms\n",
    "        algorithms = self.get_ml_algorithms()\n",
    "        \n",
    "        print(f\"\\nAVAILABLE ALGORITHMS ({len(algorithms)}):\")\n",
    "        for alg_name, alg_config in algorithms.items():\n",
    "            print(f\"   {alg_name}: {alg_config['description']}\")\n",
    "        \n",
    "        # Test each CNN dataset\n",
    "        for cnn_name, file_path in self.datasets.items():\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"ANALYZING {cnn_name} DATASET\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            try:\n",
    "                # Check if file exists before processing\n",
    "                import os\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"ERROR {cnn_name}: File not found - {file_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Run validation checks first\n",
    "                validation = self.run_validation_checks(cnn_name, file_path)\n",
    "                self.validation_results[cnn_name] = validation\n",
    "                \n",
    "                if 'error' in validation:\n",
    "                    print(f\"ERROR {cnn_name}: Validation failed - {validation['error']}\")\n",
    "                    continue\n",
    "                \n",
    "                overall_status = validation.get('overall', {}).get('status', 'FAIL')\n",
    "                if overall_status == 'FAIL':\n",
    "                    print(f\"ERROR {cnn_name}: Failed validation checks\")\n",
    "                    continue\n",
    "                \n",
    "                # Load and process data\n",
    "                print(f\"Loading data from: {file_path}\")\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"Dataset shape: {df.shape}\")\n",
    "                \n",
    "                targets_data = self.create_all_targets(df)\n",
    "                \n",
    "                if not targets_data:\n",
    "                    print(f\"ERROR {cnn_name}: No valid targets created\")\n",
    "                    continue\n",
    "                \n",
    "                # Feature selection\n",
    "                features = self.select_features(df)\n",
    "                print(f\"Available features: {len(features)}\")\n",
    "                \n",
    "                cnn_results = {}\n",
    "                \n",
    "                # Test each target category\n",
    "                for category, target_info in targets_data.items():\n",
    "                    category_data = target_info['data']\n",
    "                    \n",
    "                    for i, target_col in enumerate(target_info['targets']):\n",
    "                        task_name = target_info['descriptions'][i]\n",
    "                        \n",
    "                        print(f\"\\n{'-'*40}\")\n",
    "                        print(f\"TASK: {task_name}\")\n",
    "                        print(f\"{'-'*40}\")\n",
    "                        \n",
    "                        # Exclude target-related features to prevent leakage\n",
    "                        safe_features = self._get_safe_features(features, target_col)\n",
    "                        \n",
    "                        X, y, error = self.preprocess_data(category_data, safe_features, target_col)\n",
    "                        \n",
    "                        if X is None:\n",
    "                            print(f\"ERROR {task_name}: {error}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Run all algorithms for this task\n",
    "                        task_results = self.run_prediction_task(X, y, task_name, cnn_name, algorithms)\n",
    "                        \n",
    "                        if task_results:\n",
    "                            task_key = f\"{category}_{target_col}\"\n",
    "                            cnn_results[task_key] = {\n",
    "                                'task_name': task_name,\n",
    "                                'results': task_results,\n",
    "                                'n_samples': len(X),\n",
    "                                'n_features': X.shape[1]\n",
    "                            }\n",
    "                \n",
    "                if cnn_results:\n",
    "                    self.results[cnn_name] = cnn_results\n",
    "                    print(f\"\\nSUCCESS {cnn_name}: {len(cnn_results)} tasks completed successfully\")\n",
    "                else:\n",
    "                    print(f\"ERROR {cnn_name}: No tasks completed successfully\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR {cnn_name}: Complete failure - {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()  # This will help debug the specific error\n",
    "        \n",
    "        # Generate comprehensive report\n",
    "        self.generate_comprehensive_report()\n",
    "        \n",
    "        # Generate publication document\n",
    "        doc_filename = self.generate_publication_document()\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def _get_safe_features(self, features, target_col):\n",
    "        \"\"\"Get features safe from data leakage\"\"\"\n",
    "        # Remove features that might leak information about the target\n",
    "        unsafe_patterns = {\n",
    "            'idh_binary': ['idh'],\n",
    "            'mgmt_binary': ['mgmt'],\n",
    "            'high_grade': [],  # Tumor grade can use all molecular features\n",
    "            'mortality_6mo': [],\n",
    "            'mortality_1yr': [],\n",
    "            'mortality_2yr': []\n",
    "        }\n",
    "        \n",
    "        patterns_to_exclude = unsafe_patterns.get(target_col, [])\n",
    "        \n",
    "        safe_features = []\n",
    "        for feature in features:\n",
    "            is_safe = True\n",
    "            for pattern in patterns_to_exclude:\n",
    "                if pattern.lower() in feature.lower():\n",
    "                    is_safe = False\n",
    "                    break\n",
    "            if is_safe:\n",
    "                safe_features.append(feature)\n",
    "        \n",
    "        return safe_features\n",
    "\n",
    "    def generate_comprehensive_report(self):\n",
    "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"\\n‚ùå No results to report\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"üìä COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # EXECUTIVE SUMMARY\n",
    "        # ============================================================\n",
    "        self._generate_executive_summary()\n",
    "        \n",
    "        # ============================================================\n",
    "        # DETAILED RESULTS TABLE\n",
    "        # ============================================================\n",
    "        self._generate_detailed_results_table()\n",
    "        \n",
    "        # ============================================================\n",
    "        # BEST PERFORMERS ANALYSIS\n",
    "        # ============================================================\n",
    "        self._generate_best_performers_analysis()\n",
    "        \n",
    "        # ============================================================\n",
    "        # VALIDATION SUMMARY\n",
    "        # ============================================================\n",
    "        self._generate_validation_summary()\n",
    "        \n",
    "        # ============================================================\n",
    "        # CLINICAL RECOMMENDATIONS\n",
    "        # ============================================================\n",
    "        self._generate_clinical_recommendations()\n",
    "        \n",
    "        # ============================================================\n",
    "        # PUBLICATION STRATEGY\n",
    "        # ============================================================\n",
    "        self._generate_publication_strategy()\n",
    "\n",
    "    def _generate_executive_summary(self):\n",
    "        \"\"\"Generate executive summary\"\"\"\n",
    "        print(\"\\nüéØ EXECUTIVE SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        total_tests = 0\n",
    "        excellent_tests = 0\n",
    "        good_tests = 0\n",
    "        \n",
    "        all_aucs = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    total_tests += 1\n",
    "                    auc = result['auc']\n",
    "                    all_aucs.append(auc)\n",
    "                    \n",
    "                    if auc >= 0.85:\n",
    "                        excellent_tests += 1\n",
    "                    elif auc >= 0.75:\n",
    "                        good_tests += 1\n",
    "        \n",
    "        if all_aucs:\n",
    "            mean_auc = np.mean(all_aucs)\n",
    "            max_auc = np.max(all_aucs)\n",
    "            \n",
    "            print(f\" PERFORMANCE OVERVIEW:\")\n",
    "            print(f\"   Total algorithm-task combinations: {total_tests}\")\n",
    "            print(f\"   Mean AUC across all tests: {mean_auc:.3f}\")\n",
    "            print(f\"   Best AUC achieved: {max_auc:.3f}\")\n",
    "            print(f\"   Excellent performance (AUC ‚â• 0.85): {excellent_tests}/{total_tests} ({excellent_tests/total_tests*100:.1f}%)\")\n",
    "            print(f\"   Good+ performance (AUC ‚â• 0.75): {good_tests+excellent_tests}/{total_tests} ({(good_tests+excellent_tests)/total_tests*100:.1f}%)\")\n",
    "            \n",
    "            # Clinical readiness assessment\n",
    "            if excellent_tests > 0:\n",
    "                print(f\"   üöÄ CLINICAL DEPLOYMENT: {excellent_tests} combinations ready for validation\")\n",
    "            if max_auc >= 0.90:\n",
    "                print(f\"   üèÜ PUBLICATION READY: Exceptional results achieved\")\n",
    "            elif max_auc >= 0.80:\n",
    "                print(f\"   üìù PUBLICATION READY: Strong results achieved\")\n",
    "\n",
    "    def _generate_detailed_results_table(self):\n",
    "        \"\"\"Generate detailed results table\"\"\"\n",
    "        print(f\"\\nüìã DETAILED RESULTS TABLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Header\n",
    "        print(f\"{'CNN':<20} {'Task':<25} {'Algorithm':<15} {'AUC':<8} {'Acc':<8} {'Sens':<8} {'Spec':<8} {'Status':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    auc = result['auc']\n",
    "                    acc = result['accuracy']\n",
    "                    sens = result['sensitivity']\n",
    "                    spec = result['specificity']\n",
    "                    \n",
    "                    # Status based on AUC\n",
    "                    if auc >= 0.85:\n",
    "                        status = \"üèÜ EXCELLENT\"\n",
    "                    elif auc >= 0.75:\n",
    "                        status = \"‚úÖ STRONG\"\n",
    "                    elif auc >= 0.65:\n",
    "                        status = \"üìà GOOD\"\n",
    "                    else:\n",
    "                        status = \"‚ö†Ô∏è MODERATE\"\n",
    "                    \n",
    "                    print(f\"{cnn_name:<20} {task_name:<25} {alg_name:<15} {auc:<8.3f} {acc:<8.3f} {sens:<8.3f} {spec:<8.3f} {status:<15}\")\n",
    "\n",
    "    def _generate_best_performers_analysis(self):\n",
    "        \"\"\"Generate best performers analysis\"\"\"\n",
    "        print(f\"\\nüèÜ BEST PERFORMERS BY TASK\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Find best performer for each task across all CNNs\n",
    "        task_best = {}\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                \n",
    "                if task_name not in task_best:\n",
    "                    task_best[task_name] = {'auc': 0, 'cnn': '', 'algorithm': '', 'result': None}\n",
    "                \n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] > task_best[task_name]['auc']:\n",
    "                        task_best[task_name] = {\n",
    "                            'auc': result['auc'],\n",
    "                            'cnn': cnn_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'result': result\n",
    "                        }\n",
    "        \n",
    "        for task_name, best in task_best.items():\n",
    "            auc = best['auc']\n",
    "            status = \"üöÄ DEPLOYMENT READY\" if auc >= 0.85 else \"üìà PROMISING\" if auc >= 0.75 else \"‚ö†Ô∏è NEEDS WORK\"\n",
    "            print(f\"{task_name:<30}: {best['cnn']} + {best['algorithm']} (AUC = {auc:.3f}) {status}\")\n",
    "\n",
    "    def _generate_validation_summary(self):\n",
    "        \"\"\"Generate validation summary\"\"\"\n",
    "        print(f\"\\nVALIDATION SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if not self.validation_results:\n",
    "            print(\"No validation results available\")\n",
    "            return\n",
    "        \n",
    "        print(f\"{'CNN':<20} {'Overall':<10} {'Data':<10} {'Balance':<10} {'Features':<10} {'Samples':<10}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for cnn_name, validation in self.validation_results.items():\n",
    "            if 'error' in validation:\n",
    "                print(f\"{cnn_name:<20} {'ERROR':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n",
    "                continue\n",
    "            \n",
    "            overall = validation.get('overall', {}).get('status', 'FAIL')\n",
    "            data_integrity = validation.get('data_integrity', {}).get('status', 'FAIL')\n",
    "            class_balance = validation.get('class_balance', {}).get('status', 'FAIL')\n",
    "            feature_quality = validation.get('feature_quality', {}).get('status', 'FAIL')\n",
    "            sample_size = validation.get('sample_size', {}).get('status', 'FAIL')\n",
    "            \n",
    "            print(f\"{cnn_name:<20} {overall:<10} {data_integrity:<10} {class_balance:<10} {feature_quality:<10} {sample_size:<10}\")\n",
    "\n",
    "    def _generate_clinical_recommendations(self):\n",
    "        \"\"\"Generate clinical recommendations\"\"\"\n",
    "        print(f\"\\nCLINICAL RECOMMENDATIONS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Algorithm performance ranking\n",
    "        algorithm_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if alg_name not in algorithm_stats:\n",
    "                        algorithm_stats[alg_name] = []\n",
    "                    algorithm_stats[alg_name].append(result['auc'])\n",
    "        \n",
    "        print(\"ALGORITHM PERFORMANCE RANKING:\")\n",
    "        if algorithm_stats:\n",
    "            for alg_name, aucs in sorted(algorithm_stats.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                print(f\"   {alg_name}: {mean_auc:.3f} mean AUC, {max_auc:.3f} max AUC ({n_tests} tests)\")\n",
    "        \n",
    "        # CNN performance ranking\n",
    "        cnn_stats = {}\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            aucs = []\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    aucs.append(result['auc'])\n",
    "            if aucs:\n",
    "                cnn_stats[cnn_name] = aucs\n",
    "        \n",
    "        print(f\"\\nCNN ARCHITECTURE RANKING:\")\n",
    "        if cnn_stats:\n",
    "            for cnn_name, aucs in sorted(cnn_stats.items(), key=lambda x: np.mean(x[1]), reverse=True):\n",
    "                mean_auc = np.mean(aucs)\n",
    "                max_auc = np.max(aucs)\n",
    "                n_tests = len(aucs)\n",
    "                print(f\"   {cnn_name}: {mean_auc:.3f} mean AUC, {max_auc:.3f} max AUC ({n_tests} tests)\")\n",
    "        \n",
    "        # Implementation recommendations\n",
    "        print(f\"\\nIMPLEMENTATION RECOMMENDATIONS:\")\n",
    "        \n",
    "        best_combinations = []\n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.80:\n",
    "                        best_combinations.append({\n",
    "                            'cnn': cnn_name,\n",
    "                            'task': task_name,\n",
    "                            'algorithm': alg_name,\n",
    "                            'auc': result['auc']\n",
    "                        })\n",
    "        \n",
    "        best_combinations.sort(key=lambda x: x['auc'], reverse=True)\n",
    "        \n",
    "        if best_combinations:\n",
    "            print(f\"   {len(best_combinations)} CNN-algorithm combinations ready for clinical validation\")\n",
    "            print(f\"   Priority implementation: {best_combinations[0]['task']} using {best_combinations[0]['cnn']} + {best_combinations[0]['algorithm']}\")\n",
    "            print(f\"   Expected performance: {best_combinations[0]['auc']:.1%} discrimination accuracy\")\n",
    "        else:\n",
    "            print(f\"   No combinations reached clinical deployment threshold (AUC >= 0.80)\")\n",
    "            print(f\"   Focus on methodology optimization for best performing approaches\")\n",
    "\n",
    "    def _generate_publication_strategy(self):\n",
    "        \"\"\"Generate publication strategy\"\"\"\n",
    "        \n",
    "        print(f\"\\nPUBLICATION STRATEGY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        excellent_results = []\n",
    "        good_results = []\n",
    "        \n",
    "        for cnn_name, cnn_results in self.results.items():\n",
    "            for task_key, task_data in cnn_results.items():\n",
    "                task_name = task_data['task_name']\n",
    "                for alg_name, result in task_data['results'].items():\n",
    "                    if result['auc'] >= 0.85:\n",
    "                        excellent_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "                    elif result['auc'] >= 0.75:\n",
    "                        good_results.append((task_name, cnn_name, alg_name, result['auc']))\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    print(\"COMPREHENSIVE NEUROSURGICAL AI ANALYSIS SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"GOAL: Comprehensive evaluation of CNN architectures and ML algorithms\")\n",
    "    print(\"SCOPE: 5 CNNs √ó Multiple Algorithms √ó 6 Clinical Tasks\")\n",
    "    print(\"OUTPUT: Clinical-ready recommendations for your team and PI\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = NeurosurgicalAIAnalyzer()\n",
    "    \n",
    "    # Run comprehensive analysis\n",
    "    results = analyzer.run_comprehensive_analysis()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"COMPREHENSIVE ANALYSIS COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if results:\n",
    "        n_cnns = len(results)\n",
    "        total_tasks = sum(len(cnn_results) for cnn_results in results.values())\n",
    "        total_tests = sum(\n",
    "            len(task_data['results']) \n",
    "            for cnn_results in results.values() \n",
    "            for task_data in cnn_results.values()\n",
    "        )\n",
    "        \n",
    "        print(f\"ANALYSIS SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ {n_cnns} CNN architectures analyzed\")\n",
    "        print(f\"   ‚Ä¢ {total_tasks} clinical tasks evaluated\") \n",
    "        print(f\"   ‚Ä¢ {total_tests} algorithm-task combinations tested\")\n",
    "        print(f\"   ‚Ä¢ Comprehensive validation and recommendations generated\")\n",
    "        print(f\"   ‚Ä¢ Publication-ready document created\")\n",
    "    else:\n",
    "        print(\"No results generated. Check data file paths and formats.\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# Execute the comprehensive analysis\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
