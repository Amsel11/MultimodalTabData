{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dec5e8",
   "metadata": {},
   "source": [
    "1. cleaning up compiled data from Nico \n",
    "- starting w/ one file for now = convnext.csv\n",
    "- clean up columns w/ less than 10 data points and rows w/o data in \"permanent\" column\n",
    "- \"permanent\" column = final diagnoses\n",
    "- want to delete 128+ columns so Nico can add more image features \n",
    "(max # of columns readable by models we will use later = 500)\n",
    "- want to separate the data via diagnoses to see what diagnoses works w/ what data\n",
    "\n",
    "*preliminary data cleaning via chatgpt shows:\n",
    "OG: 522 rows x 407 columns\n",
    "cleaned: 510 rows x 241 columns\n",
    "dropped columns: 166\n",
    "dropped rows: 12\n",
    "dx groups created: 220\n",
    "\n",
    "*too many different dx\n",
    "check top 10 most common dx\n",
    "generate table of dx counts listing all 222 dx groups w/ row counts \n",
    "- easier to filter/sort by row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d75690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4db128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/joi263/Documents/MultimodalTabData/data\n",
      "✅ Cleaned data saved (grouped by diagnosis): /Users/joi263/Documents/MultimodalTabData/data/convnext_cleaned_master.csv\n",
      "✅ Dropped info saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_dropped_info.csv\n",
      "{'original_shape': (522, 407), 'cleaned_shape': (510, 241), 'columns_dropped': 166, 'rows_dropped': 12}\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. Check current working directory (just to confirm)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# ✅ 2. Helper function: Standardize ALL text entries\n",
    "def standardize_text(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(\"\\xa0\", \" \")          # replace non-breaking spaces\n",
    "        value = re.sub(r\"\\s+\", \" \", value).strip()  # collapse multiple spaces & trim\n",
    "        value = value.lower()                       # lowercase everything\n",
    "        value = re.sub(r\"^[-–]+\", \"\", value).strip() # remove leading dashes or en-dashes\n",
    "    return value\n",
    "\n",
    "# ✅ 3. Cleaning & Standardizing Function\n",
    "def clean_and_standardize_all(df, filename_prefix, save_path=\"./\"):\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # --- Standardize text in all object columns ---\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].apply(standardize_text)\n",
    "\n",
    "   # --- Drop rows with no permanent diagnosis (NaN or empty) ---\n",
    "    rows_before = df.shape[0]\n",
    "    df_cleaned = df[df[\"permanent\"].notna() & (df[\"permanent\"].str.strip() != \"\")]\n",
    "\n",
    "    # --- Track dropped rows ---\n",
    "    rows_missing_dx = df[~df.index.isin(df_cleaned.index)].copy()\n",
    "    rows_missing_dx[\"drop_reason\"] = \"No permanent diagnosis\"\n",
    "\n",
    "   # --- Drop columns with <10 non-null entries ---\n",
    "    cols_to_drop = [col for col in df_cleaned.columns if df_cleaned[col].notna().sum() < 10]\n",
    "    dropped_cols_info = pd.DataFrame({\n",
    "        \"column\": cols_to_drop,\n",
    "        \"non_null_count\": [df_cleaned[c].notna().sum() for c in cols_to_drop],\n",
    "        \"drop_reason\": \"Fewer than 10 non-null entries\"\n",
    "    })\n",
    "    df_cleaned = df_cleaned.drop(columns=cols_to_drop)\n",
    "\n",
    "    # --- ✅ Sort/group by permanent diagnosis ---\n",
    "    df_cleaned = df_cleaned.sort_values(by=\"permanent\").reset_index(drop=True)\n",
    "\n",
    "    # --- Save Cleaned Master CSV ---\n",
    "    cleaned_file = os.path.join(save_path, f\"{filename_prefix}_cleaned_master.csv\")\n",
    "    df_cleaned.to_csv(cleaned_file, index=False)\n",
    "    print(f\"✅ Cleaned data saved (grouped by diagnosis): {cleaned_file}\")\n",
    "\n",
    "    # --- Save dropped info CSV ---\n",
    "    dropped_cols_info[\"row_index\"] = \"N/A\"\n",
    "    rows_missing_dx[\"column\"] = \"N/A\"\n",
    "    rows_missing_dx[\"non_null_count\"] = \"N/A\"\n",
    "    dropped_info_combined = pd.concat([dropped_cols_info, rows_missing_dx], ignore_index=True)\n",
    "    dropped_file = os.path.join(save_path, f\"{filename_prefix}_dropped_info.csv\")\n",
    "    dropped_info_combined.to_csv(dropped_file, index=False)\n",
    "    print(f\"✅ Dropped info saved: {dropped_file}\")\n",
    "\n",
    "    return {\n",
    "        \"original_shape\": original_shape,\n",
    "        \"cleaned_shape\": df_cleaned.shape,\n",
    "        \"columns_dropped\": len(cols_to_drop),\n",
    "        \"rows_dropped\": rows_before - df_cleaned.shape[0]\n",
    "    }\n",
    "\n",
    "# ✅ 4. Example Run for ConvNeXt (change filename_prefix for others)\n",
    "data_path = \"/Users/joi263/Documents/MultimodalTabData/data/OG_data_csv/convnext.csv\"\n",
    "save_path = \"/Users/joi263/Documents/MultimodalTabData/data\"\n",
    "\n",
    "df_convnext = pd.read_csv(data_path)\n",
    "summary = clean_and_standardize_all(df_convnext, \"convnext\", save_path=save_path)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc48ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ The cleaned master CSV has 218 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned master CSV\n",
    "df_cleaned = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_cleaned_master2.csv\")\n",
    "\n",
    "# Check the number of columns\n",
    "num_columns = df_cleaned.shape[1]\n",
    "print(f\"✅ The cleaned master CSV has {num_columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d064c10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "'e' expected after '\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:805\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[0;31mError\u001b[0m: 'e' expected after '\"'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/joi263/Documents/MultimodalTabData/data/convnext_cleaned_master.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:252\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\n\u001b[1;32m    249\u001b[0m     Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] \u001b[38;5;241m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[1;32m    250\u001b[0m ]:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:1140\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     next_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m     rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:834\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    825\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    826\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError could possibly be due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    827\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsing errors in the skipped footer rows \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall rows).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m         )\n\u001b[1;32m    832\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reason\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alert_malformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/neurosurgery/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:781\u001b[0m, in \u001b[0;36mPythonParser._alert_malformed\u001b[0;34m(self, msg, row_num)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[0;32m--> 781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mWARN:\n\u001b[1;32m    783\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    785\u001b[0m         ParserWarning,\n\u001b[1;32m    786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    787\u001b[0m     )\n",
      "\u001b[0;31mParserError\u001b[0m: 'e' expected after '\"'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_cleaned_master.csv\", sep=None, engine=\"python\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d31f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diagnosis counts saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_diagnosis_counts.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permanent</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Glioblastoma, CNS WHO grade 4</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Glioblastoma WHO Grade IV</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Pituitary adenoma</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Meningioma</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Metastatic carcinoma</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Recurrent/residual glioblastoma, CNS WHO grade 4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Metastatic melanoma</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Diffuse large B-cell lymphoma</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            permanent  row_count\n",
       "86                      Glioblastoma, CNS WHO grade 4         70\n",
       "84                          Glioblastoma WHO Grade IV         40\n",
       "180                                 Pituitary adenoma         26\n",
       "80                                       Glioblastoma         20\n",
       "131                                        Meningioma         19\n",
       "141                              Metastatic carcinoma         16\n",
       "126                                          Lymphoma          7\n",
       "201  Recurrent/residual glioblastoma, CNS WHO grade 4          6\n",
       "147                               Metastatic melanoma          6\n",
       "55                      Diffuse large B-cell lymphoma          6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_diagnosis_counts(df, filename_prefix, save_path=\"./\"):\n",
    "    diagnosis_counts = (\n",
    "        df.groupby(\"permanent\")\n",
    "        .size()\n",
    "        .reset_index(name=\"row_count\")\n",
    "        .sort_values(by=\"row_count\", ascending=False)\n",
    "    )\n",
    "    counts_file = os.path.join(save_path, f\"{filename_prefix}_diagnosis_counts.csv\")\n",
    "    diagnosis_counts.to_csv(counts_file, index=False)\n",
    "    print(f\"✅ Diagnosis counts saved: {counts_file}\")\n",
    "    return diagnosis_counts\n",
    "\n",
    "# ✅ Example Run (after cleaning)\n",
    "df_cleaned = pd.read_csv(\"/Users/joi263/Documents/MultimodalTabData/data/convnext_cleaned_master.csv\")\n",
    "diagnosis_counts = generate_diagnosis_counts(df_cleaned, \"convnext\", save_path=\"/Users/joi263/Documents/MultimodalTabData/data\")\n",
    "diagnosis_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b42f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature completeness per diagnosis saved: /Users/joi263/Documents/MultimodalTabData/data/convnext_feature_completeness_per_diagnosis.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mg/q8p4w_ws4w3g3t768mdwkz940000gn/T/ipykernel_78590/3442575868.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.notna().sum() / len(group) * 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>feature</th>\n",
       "      <th>percent_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>case_number</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>institution_x</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>organ</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>p19q_report</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>mgmt_pyro</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>oncomine_focus</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>genomic_tests_complete</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7260</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>ala_case</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7700</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>frozen</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>- Adenocarcinoma consistent with metastases fr...</td>\n",
       "      <td>time_frozen_diagnosis</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              diagnosis  \\\n",
       "0     - Adenocarcinoma consistent with metastases fr...   \n",
       "220   - Adenocarcinoma consistent with metastases fr...   \n",
       "440   - Adenocarcinoma consistent with metastases fr...   \n",
       "660   - Adenocarcinoma consistent with metastases fr...   \n",
       "1320  - Adenocarcinoma consistent with metastases fr...   \n",
       "2860  - Adenocarcinoma consistent with metastases fr...   \n",
       "7040  - Adenocarcinoma consistent with metastases fr...   \n",
       "7260  - Adenocarcinoma consistent with metastases fr...   \n",
       "7700  - Adenocarcinoma consistent with metastases fr...   \n",
       "8140  - Adenocarcinoma consistent with metastases fr...   \n",
       "\n",
       "                     feature  percent_complete  \n",
       "0                case_number             100.0  \n",
       "220            institution_x             100.0  \n",
       "440                    organ             100.0  \n",
       "660              p19q_report             100.0  \n",
       "1320               mgmt_pyro             100.0  \n",
       "2860          oncomine_focus             100.0  \n",
       "7040  genomic_tests_complete             100.0  \n",
       "7260                ala_case             100.0  \n",
       "7700                  frozen             100.0  \n",
       "8140   time_frozen_diagnosis             100.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_feature_completeness_per_dx(df, filename_prefix, save_path=\"./\"):\n",
    "    # Calculate completeness per feature for each diagnosis group\n",
    "    feature_completeness_per_dx = (\n",
    "        df.groupby(\"permanent\")\n",
    "        .apply(lambda group: group.notna().sum() / len(group) * 100)\n",
    "    )\n",
    "\n",
    "    # Convert index (permanent) into a proper column without duplication\n",
    "    feature_completeness_per_dx = feature_completeness_per_dx.copy()\n",
    "    feature_completeness_per_dx[\"diagnosis\"] = feature_completeness_per_dx.index\n",
    "    feature_completeness_per_dx = feature_completeness_per_dx.reset_index(drop=True)\n",
    "\n",
    "    # Melt to long format for easy sorting\n",
    "    feature_completeness_per_dx = feature_completeness_per_dx.melt(\n",
    "        id_vars=[\"diagnosis\"], var_name=\"feature\", value_name=\"percent_complete\"\n",
    "    ).sort_values([\"diagnosis\", \"percent_complete\"], ascending=[True, False])\n",
    "\n",
    "    # Save to CSV\n",
    "    completeness_file = os.path.join(save_path, f\"{filename_prefix}_feature_completeness_per_diagnosis.csv\")\n",
    "    feature_completeness_per_dx.to_csv(completeness_file, index=False)\n",
    "    print(f\"✅ Feature completeness per diagnosis saved: {completeness_file}\")\n",
    "\n",
    "    return feature_completeness_per_dx\n",
    "\n",
    "# ✅ Example Run (after cleaning)\n",
    "feature_completeness = generate_feature_completeness_per_dx(\n",
    "    df_cleaned,\n",
    "    \"convnext\",\n",
    "    save_path=\"/Users/joi263/Documents/MultimodalTabData/data\"\n",
    ")\n",
    "feature_completeness.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurosurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
